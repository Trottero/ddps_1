<?xml version="1.0" encoding="iso-8859-1" standalone="no"?>
<!-- Generated by the JDiff Javadoc doclet -->
<!-- (http://www.jdiff.org) -->
<!-- on Mon Mar 30 15:30:43 PDT 2015 -->

<api
  xmlns:xsi='http://www.w3.org/2001/XMLSchema-instance'
  xsi:noNamespaceSchemaLocation='api.xsd'
  name="hadoop-hdfs 2.6.0"
  jdversion="1.0.9">

<!--  Command line arguments =  -doclet org.apache.hadoop.classification.tools.ExcludePrivateAnnotationsJDiffDoclet -docletpath /Users/llu/hadoop-common/hadoop-hdfs-project/hadoop-hdfs/target/hadoop-annotations.jar:/Users/llu/hadoop-common/hadoop-hdfs-project/hadoop-hdfs/target/jdiff.jar -verbose -classpath /Users/llu/hadoop-common/hadoop-hdfs-project/hadoop-hdfs/target/classes:/Users/llu/hadoop-common/hadoop-common-project/hadoop-annotations/target/hadoop-annotations-2.6.0.jar:/Library/Java/JavaVirtualMachines/jdk1.7.0_67.jdk/Contents/Home/lib/tools.jar:/Users/llu/hadoop-common/hadoop-common-project/hadoop-auth/target/hadoop-auth-2.6.0.jar:/Users/llu/.m2/repository/org/slf4j/slf4j-api/1.7.5/slf4j-api-1.7.5.jar:/Users/llu/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/Users/llu/.m2/repository/org/apache/httpcomponents/httpcore/4.2.5/httpcore-4.2.5.jar:/Users/llu/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/Users/llu/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/Users/llu/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/Users/llu/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/Users/llu/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/Users/llu/.m2/repository/org/apache/curator/curator-framework/2.6.0/curator-framework-2.6.0.jar:/Users/llu/hadoop-common/hadoop-common-project/hadoop-common/target/hadoop-common-2.6.0.jar:/Users/llu/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/Users/llu/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/Users/llu/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/Users/llu/.m2/repository/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar:/Users/llu/.m2/repository/com/sun/jersey/jersey-json/1.9/jersey-json-1.9.jar:/Users/llu/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/Users/llu/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/Users/llu/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/Users/llu/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/Users/llu/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/Users/llu/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/Users/llu/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.13/jackson-xc-1.9.13.jar:/Users/llu/.m2/repository/tomcat/jasper-compiler/5.5.23/jasper-compiler-5.5.23.jar:/Users/llu/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/Users/llu/.m2/repository/net/java/dev/jets3t/jets3t/0.9.0/jets3t-0.9.0.jar:/Users/llu/.m2/repository/com/jamesmurty/utils/java-xmlbuilder/0.4/java-xmlbuilder-0.4.jar:/Users/llu/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/Users/llu/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/Users/llu/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/Users/llu/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/Users/llu/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/Users/llu/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/Users/llu/.m2/repository/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar:/Users/llu/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/Users/llu/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/Users/llu/.m2/repository/org/apache/curator/curator-client/2.6.0/curator-client-2.6.0.jar:/Users/llu/.m2/repository/org/apache/curator/curator-recipes/2.6.0/curator-recipes-2.6.0.jar:/Users/llu/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/Users/llu/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/Users/llu/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/Users/llu/.m2/repository/jline/jline/0.9.94/jline-0.9.94.jar:/Users/llu/.m2/repository/com/google/guava/guava/11.0.2/guava-11.0.2.jar:/Users/llu/.m2/repository/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar:/Users/llu/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/Users/llu/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/Users/llu/.m2/repository/com/sun/jersey/jersey-server/1.9/jersey-server-1.9.jar:/Users/llu/.m2/repository/asm/asm/3.2/asm-3.2.jar:/Users/llu/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/Users/llu/.m2/repository/commons-codec/commons-codec/1.4/commons-codec-1.4.jar:/Users/llu/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/Users/llu/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/Users/llu/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/Users/llu/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/Users/llu/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/Users/llu/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/Users/llu/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/Users/llu/.m2/repository/javax/servlet/servlet-api/2.5/servlet-api-2.5.jar:/Users/llu/.m2/repository/org/slf4j/slf4j-log4j12/1.7.5/slf4j-log4j12-1.7.5.jar:/Users/llu/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/Users/llu/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/Users/llu/.m2/repository/tomcat/jasper-runtime/5.5.23/jasper-runtime-5.5.23.jar:/Users/llu/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/Users/llu/.m2/repository/io/netty/netty/3.6.2.Final/netty-3.6.2.Final.jar:/Users/llu/.m2/repository/xerces/xercesImpl/2.9.1/xercesImpl-2.9.1.jar:/Users/llu/.m2/repository/xml-apis/xml-apis/1.3.04/xml-apis-1.3.04.jar:/Users/llu/.m2/repository/org/htrace/htrace-core/3.0.4/htrace-core-3.0.4.jar -sourcepath /Users/llu/hadoop-common/hadoop-hdfs-project/hadoop-hdfs/src/main/java -apidir /Users/llu/hadoop-common/hadoop-hdfs-project/hadoop-hdfs/target/site/jdiff/xml -apiname hadoop-core 2.6.0 -->
<package name="org.apache.hadoop.fs">
  <!-- start class org.apache.hadoop.fs.BlockStorageLocation -->
  <class name="BlockStorageLocation" extends="org.apache.hadoop.fs.BlockLocation"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="BlockStorageLocation" type="org.apache.hadoop.fs.BlockLocation, org.apache.hadoop.fs.VolumeId[]"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
    </constructor>
    <method name="getVolumeIds" return="org.apache.hadoop.fs.VolumeId[]"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets the list of {@link VolumeId} corresponding to the block's replicas.
 
 @return volumeIds list of VolumeId for the block's replicas]]>
      </doc>
    </method>
    <doc>
    <![CDATA[Wrapper for {@link BlockLocation} that also adds {@link VolumeId} volume
 location information for each replica.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.fs.BlockStorageLocation -->
  <!-- start class org.apache.hadoop.fs.CacheFlag -->
  <class name="CacheFlag" extends="java.lang.Enum"
    abstract="false"
    static="false" final="true" visibility="public"
    deprecated="not deprecated">
    <method name="values" return="org.apache.hadoop.fs.CacheFlag[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="valueOf" return="org.apache.hadoop.fs.CacheFlag"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="name" type="java.lang.String"/>
    </method>
    <doc>
    <![CDATA[Specifies semantics for CacheDirective operations. Multiple flags can
 be combined in an EnumSet.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.fs.CacheFlag -->
  <!-- start class org.apache.hadoop.fs.HdfsVolumeId -->
  <class name="HdfsVolumeId" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <implements name="org.apache.hadoop.fs.VolumeId"/>
    <constructor name="HdfsVolumeId" type="byte[]"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="compareTo" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="arg0" type="org.apache.hadoop.fs.VolumeId"/>
    </method>
    <method name="hashCode" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="equals" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="obj" type="java.lang.Object"/>
    </method>
    <method name="toString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[HDFS-specific volume identifier which implements {@link VolumeId}. Can be
 used to differentiate between the data directories on a single datanode. This
 identifier is only unique on a per-datanode basis.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.fs.HdfsVolumeId -->
  <!-- start interface org.apache.hadoop.fs.VolumeId -->
  <interface name="VolumeId"    abstract="true"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <implements name="java.lang.Comparable"/>
    <method name="compareTo" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="arg0" type="org.apache.hadoop.fs.VolumeId"/>
    </method>
    <method name="hashCode" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="equals" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="obj" type="java.lang.Object"/>
    </method>
    <doc>
    <![CDATA[Opaque interface that identifies a disk location. Subclasses
 should implement {@link Comparable} and override both equals and hashCode.]]>
    </doc>
  </interface>
  <!-- end interface org.apache.hadoop.fs.VolumeId -->
  <!-- start class org.apache.hadoop.fs.XAttr.Builder -->
  <class name="XAttr.Builder" extends="java.lang.Object"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="XAttr.Builder"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="setNameSpace" return="org.apache.hadoop.fs.XAttr.Builder"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="ns" type="org.apache.hadoop.fs.XAttr.NameSpace"/>
    </method>
    <method name="setName" return="org.apache.hadoop.fs.XAttr.Builder"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="name" type="java.lang.String"/>
    </method>
    <method name="setValue" return="org.apache.hadoop.fs.XAttr.Builder"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="value" type="byte[]"/>
    </method>
    <method name="build" return="org.apache.hadoop.fs.XAttr"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
  </class>
  <!-- end class org.apache.hadoop.fs.XAttr.Builder -->
  <!-- start class org.apache.hadoop.fs.XAttr.NameSpace -->
  <class name="XAttr.NameSpace" extends="java.lang.Enum"
    abstract="false"
    static="true" final="true" visibility="public"
    deprecated="not deprecated">
    <method name="values" return="org.apache.hadoop.fs.XAttr.NameSpace[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="valueOf" return="org.apache.hadoop.fs.XAttr.NameSpace"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="name" type="java.lang.String"/>
    </method>
  </class>
  <!-- end class org.apache.hadoop.fs.XAttr.NameSpace -->
</package>
<package name="org.apache.hadoop.hdfs">
  <!-- start interface org.apache.hadoop.hdfs.BlockReader -->
  <interface name="BlockReader"    abstract="true"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <implements name="org.apache.hadoop.fs.ByteBufferReadable"/>
    <method name="read" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="buf" type="byte[]"/>
      <param name="off" type="int"/>
      <param name="len" type="int"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="skip" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="n" type="long"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Skip the given number of bytes]]>
      </doc>
    </method>
    <method name="available" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Returns an estimate of the number of bytes that can be read
 (or skipped over) from this input stream without performing
 network I/O.
 This may return more than what is actually present in the block.]]>
      </doc>
    </method>
    <method name="close"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Close the block reader.

 @throws IOException]]>
      </doc>
    </method>
    <method name="readFully"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="buf" type="byte[]"/>
      <param name="readOffset" type="int"/>
      <param name="amtToRead" type="int"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Read exactly the given amount of data, throwing an exception
 if EOF is reached before that amount]]>
      </doc>
    </method>
    <method name="readAll" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="buf" type="byte[]"/>
      <param name="offset" type="int"/>
      <param name="len" type="int"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Similar to {@link #readFully(byte[], int, int)} except that it will
 not throw an exception on EOF. However, it differs from the simple
 {@link #read(byte[], int, int)} call in that it is guaranteed to
 read the data if it is available. In other words, if this call
 does not throw an exception, then either the buffer has been
 filled or the next call will return EOF.]]>
      </doc>
    </method>
    <method name="isLocal" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return              true only if this is a local read.]]>
      </doc>
    </method>
    <method name="isShortCircuit" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return              true only if this is a short-circuit read.
                      All short-circuit reads are also local.]]>
      </doc>
    </method>
    <method name="getClientMmap" return="org.apache.hadoop.hdfs.shortcircuit.ClientMmap"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="opts" type="java.util.EnumSet"/>
      <doc>
      <![CDATA[Get a ClientMmap object for this BlockReader.

 @param opts          The read options to use.
 @return              The ClientMmap object, or null if mmap is not
                      supported.]]>
      </doc>
    </method>
    <doc>
    <![CDATA[A BlockReader is responsible for reading a single block
 from a single datanode.]]>
    </doc>
  </interface>
  <!-- end interface org.apache.hadoop.hdfs.BlockReader -->
  <!-- start class org.apache.hadoop.hdfs.BlockReaderFactory.BlockReaderPeer -->
  <class name="BlockReaderFactory.BlockReaderPeer" extends="java.lang.Object"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
  </class>
  <!-- end class org.apache.hadoop.hdfs.BlockReaderFactory.BlockReaderPeer -->
  <!-- start class org.apache.hadoop.hdfs.CorruptFileBlockIterator -->
  <class name="CorruptFileBlockIterator" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <implements name="org.apache.hadoop.fs.RemoteIterator"/>
    <constructor name="CorruptFileBlockIterator" type="org.apache.hadoop.hdfs.DFSClient, org.apache.hadoop.fs.Path"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
    </constructor>
    <method name="getCallsMade" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return the number of calls made to the DFSClient.
 This is for debugging and testing purposes.]]>
      </doc>
    </method>
    <method name="hasNext" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="next" return="org.apache.hadoop.fs.Path"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <doc>
    <![CDATA[Provides an iterator interface for listCorruptFileBlocks.
 This class is used by DistributedFileSystem and Hdfs.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.CorruptFileBlockIterator -->
  <!-- start class org.apache.hadoop.hdfs.DFSClient.Conf -->
  <class name="DFSClient.Conf" extends="java.lang.Object"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="DFSClient.Conf" type="org.apache.hadoop.conf.Configuration"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="isUseLegacyBlockReaderLocal" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getDomainSocketPath" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="isShortCircuitLocalReads" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="isDomainSocketDataTraffic" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[DFSClient configuration]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.DFSClient.Conf -->
  <!-- start class org.apache.hadoop.hdfs.DFSClient.DFSDataInputStream -->
  <class name="DFSClient.DFSDataInputStream" extends="org.apache.hadoop.hdfs.client.HdfsDataInputStream"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="use {@link HdfsDataInputStream} instead.">
    <constructor name="DFSClient.DFSDataInputStream" type="org.apache.hadoop.hdfs.DFSInputStream"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
    </constructor>
    <doc>
    <![CDATA[@deprecated use {@link HdfsDataInputStream} instead.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.DFSClient.DFSDataInputStream -->
  <!-- start class org.apache.hadoop.hdfs.DFSHedgedReadMetrics -->
  <class name="DFSHedgedReadMetrics" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="DFSHedgedReadMetrics"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="incHedgedReadOps"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="incHedgedReadOpsInCurThread"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="incHedgedReadWins"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getHedgedReadOps" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getHedgedReadOpsInCurThread" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getHedgedReadWins" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <field name="hedgedReadOps" type="java.util.concurrent.atomic.AtomicLong"
      transient="false" volatile="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="hedgedReadOpsWin" type="java.util.concurrent.atomic.AtomicLong"
      transient="false" volatile="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="hedgedReadOpsInCurThread" type="java.util.concurrent.atomic.AtomicLong"
      transient="false" volatile="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <doc>
    <![CDATA[The client-side metrics for hedged read feature.
 This class has a number of metrics variables that are publicly accessible,
 we can grab them from client side, like HBase.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.DFSHedgedReadMetrics -->
  <!-- start class org.apache.hadoop.hdfs.DFSInotifyEventInputStream -->
  <class name="DFSInotifyEventInputStream" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="poll" return="org.apache.hadoop.hdfs.inotify.Event"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
      <exception name="MissingEventsException" type="org.apache.hadoop.hdfs.inotify.MissingEventsException"/>
      <doc>
      <![CDATA[Returns the next event in the stream or null if no new events are currently
 available.

 @throws IOException because of network error or edit log
 corruption. Also possible if JournalNodes are unresponsive in the
 QJM setting (even one unresponsive JournalNode is enough in rare cases),
 so catching this exception and retrying at least a few times is
 recommended.
 @throws MissingEventsException if we cannot return the next event in the
 stream because the data for the event (and possibly some subsequent events)
 has been deleted (generally because this stream is a very large number of
 events behind the current state of the NameNode). It is safe to continue
 reading from the stream after this exception is thrown -- the next
 available event will be returned.]]>
      </doc>
    </method>
    <method name="getEventsBehindEstimate" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Return a estimate of how many events behind the NameNode's current state
 this stream is. Clients should periodically call this method and check if
 its result is steadily increasing, which indicates that they are falling
 behind (i.e. events are being generated faster than the client is reading
 them). If a client falls too far behind events may be deleted before the
 client can read them.
 <p/>
 A return value of -1 indicates that an estimate could not be produced, and
 should be ignored. The value returned by this method is really only useful
 when compared to previous or subsequent returned values.]]>
      </doc>
    </method>
    <method name="poll" return="org.apache.hadoop.hdfs.inotify.Event"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="time" type="long"/>
      <param name="tu" type="java.util.concurrent.TimeUnit"/>
      <exception name="IOException" type="java.io.IOException"/>
      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
      <exception name="MissingEventsException" type="org.apache.hadoop.hdfs.inotify.MissingEventsException"/>
      <doc>
      <![CDATA[Returns the next event in the stream, waiting up to the specified amount of
 time for a new event. Returns null if a new event is not available at the
 end of the specified amount of time. The time before the method returns may
 exceed the specified amount of time by up to the time required for an RPC
 to the NameNode.

 @param time number of units of the given TimeUnit to wait
 @param tu the desired TimeUnit
 @throws IOException see {@link DFSInotifyEventInputStream#poll()}
 @throws MissingEventsException
 see {@link DFSInotifyEventInputStream#poll()}
 @throws InterruptedException if the calling thread is interrupted]]>
      </doc>
    </method>
    <method name="take" return="org.apache.hadoop.hdfs.inotify.Event"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
      <exception name="MissingEventsException" type="org.apache.hadoop.hdfs.inotify.MissingEventsException"/>
      <doc>
      <![CDATA[Returns the next event in the stream, waiting indefinitely if a new event
 is not immediately available.

 @throws IOException see {@link DFSInotifyEventInputStream#poll()}
 @throws MissingEventsException see
 {@link DFSInotifyEventInputStream#poll()}
 @throws InterruptedException if the calling thread is interrupted]]>
      </doc>
    </method>
    <field name="LOG" type="org.slf4j.Logger"
      transient="false" volatile="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
    </field>
    <doc>
    <![CDATA[Stream for reading inotify events. DFSInotifyEventInputStreams should not
 be shared among multiple threads.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.DFSInotifyEventInputStream -->
  <!-- start class org.apache.hadoop.hdfs.DFSInputStream.ReadStatistics -->
  <class name="DFSInputStream.ReadStatistics" extends="java.lang.Object"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="DFSInputStream.ReadStatistics"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <constructor name="DFSInputStream.ReadStatistics" type="org.apache.hadoop.hdfs.DFSInputStream.ReadStatistics"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getTotalBytesRead" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return The total bytes read.  This will always be at least as
 high as the other numbers, since it includes all of them.]]>
      </doc>
    </method>
    <method name="getTotalLocalBytesRead" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return The total local bytes read.  This will always be at least
 as high as totalShortCircuitBytesRead, since all short-circuit
 reads are also local.]]>
      </doc>
    </method>
    <method name="getTotalShortCircuitBytesRead" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return The total short-circuit local bytes read.]]>
      </doc>
    </method>
    <method name="getTotalZeroCopyBytesRead" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return The total number of zero-copy bytes read.]]>
      </doc>
    </method>
    <method name="getRemoteBytesRead" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return The total number of bytes read which were not local.]]>
      </doc>
    </method>
  </class>
  <!-- end class org.apache.hadoop.hdfs.DFSInputStream.ReadStatistics -->
  <!-- start class org.apache.hadoop.hdfs.DFSUtil.ConfiguredNNAddress -->
  <class name="DFSUtil.ConfiguredNNAddress" extends="java.lang.Object"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="getNameserviceId" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getNamenodeId" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getAddress" return="java.net.InetSocketAddress"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="toString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[Represent one of the NameNodes configured in the cluster.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.DFSUtil.ConfiguredNNAddress -->
  <!-- start class org.apache.hadoop.hdfs.ExtendedBlockId -->
  <class name="ExtendedBlockId" extends="java.lang.Object"
    abstract="false"
    static="false" final="true" visibility="public"
    deprecated="not deprecated">
    <constructor name="ExtendedBlockId" type="long, java.lang.String"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="fromExtendedBlock" return="org.apache.hadoop.hdfs.ExtendedBlockId"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="block" type="org.apache.hadoop.hdfs.protocol.ExtendedBlock"/>
    </method>
    <method name="getBlockId" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getBlockPoolId" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="equals" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="o" type="java.lang.Object"/>
    </method>
    <method name="hashCode" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="toString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[An immutable key which identifies a block.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.ExtendedBlockId -->
  <!-- start class org.apache.hadoop.hdfs.HAUtil -->
  <class name="HAUtil" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="isHAEnabled" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
      <param name="nsId" type="java.lang.String"/>
      <doc>
      <![CDATA[Returns true if HA for namenode is configured for the given nameservice
 
 @param conf Configuration
 @param nsId nameservice, or null if no federated NS is configured
 @return true if HA is configured in the configuration; else false.]]>
      </doc>
    </method>
    <method name="usesSharedEditsDir" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
      <doc>
      <![CDATA[Returns true if HA is using a shared edits directory.

 @param conf Configuration
 @return true if HA config is using a shared edits dir, false otherwise.]]>
      </doc>
    </method>
    <method name="getNameNodeId" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
      <param name="nsId" type="java.lang.String"/>
      <doc>
      <![CDATA[Get the namenode Id by matching the {@code addressKey}
 with the the address of the local node.
 
 If {@link DFSConfigKeys#DFS_HA_NAMENODE_ID_KEY} is not specifically
 configured, this method determines the namenode Id by matching the local
 node's address with the configured addresses. When a match is found, it
 returns the namenode Id from the corresponding configuration key.
 
 @param conf Configuration
 @return namenode Id on success, null on failure.
 @throws HadoopIllegalArgumentException on error]]>
      </doc>
    </method>
    <method name="getNameNodeIdFromAddress" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
      <param name="address" type="java.net.InetSocketAddress"/>
      <param name="keys" type="java.lang.String[]"/>
      <doc>
      <![CDATA[Similar to
 {@link DFSUtil#getNameServiceIdFromAddress(Configuration, 
 InetSocketAddress, String...)}]]>
      </doc>
    </method>
    <method name="getNameNodeIdOfOtherNode" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
      <param name="nsId" type="java.lang.String"/>
      <doc>
      <![CDATA[Get the NN ID of the other node in an HA setup.
 
 @param conf the configuration of this node
 @return the NN ID of the other node in this nameservice]]>
      </doc>
    </method>
    <method name="getConfForOtherNode" return="org.apache.hadoop.conf.Configuration"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="myConf" type="org.apache.hadoop.conf.Configuration"/>
      <doc>
      <![CDATA[Given the configuration for this node, return a Configuration object for
 the other node in an HA setup.
 
 @param myConf the configuration of this node
 @return the configuration of the other node in an HA setup]]>
      </doc>
    </method>
    <method name="shouldAllowStandbyReads" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
      <doc>
      <![CDATA[This is used only by tests at the moment.
 @return true if the NN should allow read operations while in standby mode.]]>
      </doc>
    </method>
    <method name="setAllowStandbyReads"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
      <param name="val" type="boolean"/>
    </method>
    <method name="isLogicalUri" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
      <param name="nameNodeUri" type="java.net.URI"/>
      <doc>
      <![CDATA[@return true if the given nameNodeUri appears to be a logical URI.]]>
      </doc>
    </method>
    <method name="isClientFailoverConfigured" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
      <param name="nameNodeUri" type="java.net.URI"/>
      <doc>
      <![CDATA[Check whether the client has a failover proxy provider configured
 for the namenode/nameservice.

 @param conf Configuration
 @param nameNodeUri The URI of namenode
 @return true if failover is configured.]]>
      </doc>
    </method>
    <method name="useLogicalUri" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
      <param name="nameNodeUri" type="java.net.URI"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Check whether logical URI is needed for the namenode and
 the corresponding failover proxy provider in the config.

 @param conf Configuration
 @param nameNodeUri The URI of namenode
 @return true if logical URI is needed. false, if not needed.
 @throws IOException most likely due to misconfiguration.]]>
      </doc>
    </method>
    <method name="getServiceUriFromToken" return="java.net.URI"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="scheme" type="java.lang.String"/>
      <param name="token" type="org.apache.hadoop.security.token.Token"/>
      <doc>
      <![CDATA[Parse the file system URI out of the provided token.]]>
      </doc>
    </method>
    <method name="buildTokenServiceForLogicalUri" return="org.apache.hadoop.io.Text"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="uri" type="java.net.URI"/>
      <param name="scheme" type="java.lang.String"/>
      <doc>
      <![CDATA[Get the service name used in the delegation token for the given logical
 HA service.
 @param uri the logical URI of the cluster
 @param scheme the scheme of the corresponding FileSystem
 @return the service name]]>
      </doc>
    </method>
    <method name="isTokenForLogicalUri" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="token" type="org.apache.hadoop.security.token.Token"/>
      <doc>
      <![CDATA[@return true if this token corresponds to a logical nameservice
 rather than a specific namenode.]]>
      </doc>
    </method>
    <method name="buildTokenServicePrefixForLogicalUri" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="scheme" type="java.lang.String"/>
    </method>
    <method name="cloneDelegationTokenForLogicalUri"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="ugi" type="org.apache.hadoop.security.UserGroupInformation"/>
      <param name="haUri" type="java.net.URI"/>
      <param name="nnAddrs" type="java.util.Collection"/>
      <doc>
      <![CDATA[Locate a delegation token associated with the given HA cluster URI, and if
 one is found, clone it to also represent the underlying namenode address.
 @param ugi the UGI to modify
 @param haUri the logical URI for the cluster
 @param nnAddrs collection of NNs in the cluster to which the token
 applies]]>
      </doc>
    </method>
    <method name="getAddressOfActive" return="java.net.InetSocketAddress"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="fs" type="org.apache.hadoop.fs.FileSystem"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Get the internet address of the currently-active NN. This should rarely be
 used, since callers of this method who connect directly to the NN using the
 resulting InetSocketAddress will not be able to connect to the active NN if
 a failover were to occur after this method has been called.
 
 @param fs the file system to get the active address of.
 @return the internet address of the currently-active NN.
 @throws IOException if an error occurs while resolving the active NN.]]>
      </doc>
    </method>
    <method name="getProxiesForAllNameNodesInNameservice" return="java.util.List"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
      <param name="nsId" type="java.lang.String"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Get an RPC proxy for each NN in an HA nameservice. Used when a given RPC
 call should be made on every NN in an HA nameservice, not just the active.
 
 @param conf configuration
 @param nsId the nameservice to get all of the proxies for.
 @return a list of RPC proxies for each NN in the nameservice.
 @throws IOException in the event of error.]]>
      </doc>
    </method>
    <method name="getProxiesForAllNameNodesInNameservice" return="java.util.List"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
      <param name="nsId" type="java.lang.String"/>
      <param name="xface" type="java.lang.Class"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Get an RPC proxy for each NN in an HA nameservice. Used when a given RPC
 call should be made on every NN in an HA nameservice, not just the active.

 @param conf configuration
 @param nsId the nameservice to get all of the proxies for.
 @param xface the protocol class.
 @return a list of RPC proxies for each NN in the nameservice.
 @throws IOException in the event of error.]]>
      </doc>
    </method>
    <method name="isAtLeastOneActive" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="namenodes" type="java.util.List"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Used to ensure that at least one of the given HA NNs is currently in the
 active state..
 
 @param namenodes list of RPC proxies for each NN to check.
 @return true if at least one NN is active, false if all are in the standby state.
 @throws IOException in the event of error.]]>
      </doc>
    </method>
  </class>
  <!-- end class org.apache.hadoop.hdfs.HAUtil -->
  <!-- start class org.apache.hadoop.hdfs.NameNodeProxies -->
  <class name="NameNodeProxies" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="NameNodeProxies"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="createProxy" return="org.apache.hadoop.hdfs.NameNodeProxies.ProxyAndInfo"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
      <param name="nameNodeUri" type="java.net.URI"/>
      <param name="xface" type="java.lang.Class"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Creates the namenode proxy with the passed protocol. This will handle
 creation of either HA- or non-HA-enabled proxy objects, depending upon
 if the provided URI is a configured logical URI.
 
 @param conf the configuration containing the required IPC
        properties, client failover configurations, etc.
 @param nameNodeUri the URI pointing either to a specific NameNode
        or to a logical nameservice.
 @param xface the IPC interface which should be created
 @return an object containing both the proxy and the associated
         delegation token service it corresponds to
 @throws IOException if there is an error creating the proxy]]>
      </doc>
    </method>
    <method name="createProxy" return="org.apache.hadoop.hdfs.NameNodeProxies.ProxyAndInfo"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
      <param name="nameNodeUri" type="java.net.URI"/>
      <param name="xface" type="java.lang.Class"/>
      <param name="fallbackToSimpleAuth" type="java.util.concurrent.atomic.AtomicBoolean"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Creates the namenode proxy with the passed protocol. This will handle
 creation of either HA- or non-HA-enabled proxy objects, depending upon
 if the provided URI is a configured logical URI.

 @param conf the configuration containing the required IPC
        properties, client failover configurations, etc.
 @param nameNodeUri the URI pointing either to a specific NameNode
        or to a logical nameservice.
 @param xface the IPC interface which should be created
 @param fallbackToSimpleAuth set to true or false during calls to indicate if
   a secure client falls back to simple auth
 @return an object containing both the proxy and the associated
         delegation token service it corresponds to
 @throws IOException if there is an error creating the proxy]]>
      </doc>
    </method>
    <method name="createProxyWithLossyRetryHandler" return="org.apache.hadoop.hdfs.NameNodeProxies.ProxyAndInfo"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="config" type="org.apache.hadoop.conf.Configuration"/>
      <param name="nameNodeUri" type="java.net.URI"/>
      <param name="xface" type="java.lang.Class"/>
      <param name="numResponseToDrop" type="int"/>
      <param name="fallbackToSimpleAuth" type="java.util.concurrent.atomic.AtomicBoolean"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Generate a dummy namenode proxy instance that utilizes our hacked
 {@link LossyRetryInvocationHandler}. Proxy instance generated using this
 method will proactively drop RPC responses. Currently this method only
 support HA setup. null will be returned if the given configuration is not 
 for HA.
 
 @param config the configuration containing the required IPC
        properties, client failover configurations, etc.
 @param nameNodeUri the URI pointing either to a specific NameNode
        or to a logical nameservice.
 @param xface the IPC interface which should be created
 @param numResponseToDrop The number of responses to drop for each RPC call
 @param fallbackToSimpleAuth set to true or false during calls to indicate if
   a secure client falls back to simple auth
 @return an object containing both the proxy and the associated
         delegation token service it corresponds to. Will return null of the
         given configuration does not support HA.
 @throws IOException if there is an error creating the proxy]]>
      </doc>
    </method>
    <method name="createNonHAProxy" return="org.apache.hadoop.hdfs.NameNodeProxies.ProxyAndInfo"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
      <param name="nnAddr" type="java.net.InetSocketAddress"/>
      <param name="xface" type="java.lang.Class"/>
      <param name="ugi" type="org.apache.hadoop.security.UserGroupInformation"/>
      <param name="withRetries" type="boolean"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Creates an explicitly non-HA-enabled proxy object. Most of the time you
 don't want to use this, and should instead use {@link NameNodeProxies#createProxy}.
 
 @param conf the configuration object
 @param nnAddr address of the remote NN to connect to
 @param xface the IPC interface which should be created
 @param ugi the user who is making the calls on the proxy object
 @param withRetries certain interfaces have a non-standard retry policy
 @return an object containing both the proxy and the associated
         delegation token service it corresponds to
 @throws IOException]]>
      </doc>
    </method>
    <method name="createNonHAProxy" return="org.apache.hadoop.hdfs.NameNodeProxies.ProxyAndInfo"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
      <param name="nnAddr" type="java.net.InetSocketAddress"/>
      <param name="xface" type="java.lang.Class"/>
      <param name="ugi" type="org.apache.hadoop.security.UserGroupInformation"/>
      <param name="withRetries" type="boolean"/>
      <param name="fallbackToSimpleAuth" type="java.util.concurrent.atomic.AtomicBoolean"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Creates an explicitly non-HA-enabled proxy object. Most of the time you
 don't want to use this, and should instead use {@link NameNodeProxies#createProxy}.

 @param conf the configuration object
 @param nnAddr address of the remote NN to connect to
 @param xface the IPC interface which should be created
 @param ugi the user who is making the calls on the proxy object
 @param withRetries certain interfaces have a non-standard retry policy
 @param fallbackToSimpleAuth - set to true or false during this method to
   indicate if a secure client falls back to simple auth
 @return an object containing both the proxy and the associated
         delegation token service it corresponds to
 @throws IOException]]>
      </doc>
    </method>
    <method name="getFailoverProxyProviderClass" return="java.lang.Class"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
      <param name="nameNodeUri" type="java.net.URI"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Gets the configured Failover proxy provider's class]]>
      </doc>
    </method>
    <method name="createFailoverProxyProvider" return="org.apache.hadoop.hdfs.server.namenode.ha.AbstractNNFailoverProxyProvider"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
      <param name="nameNodeUri" type="java.net.URI"/>
      <param name="xface" type="java.lang.Class"/>
      <param name="checkPort" type="boolean"/>
      <param name="fallbackToSimpleAuth" type="java.util.concurrent.atomic.AtomicBoolean"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Creates the Failover proxy provider instance]]>
      </doc>
    </method>
    <doc>
    <![CDATA[Create proxy objects to communicate with a remote NN. All remote access to an
 NN should be funneled through this class. Most of the time you'll want to use
 {@link NameNodeProxies#createProxy(Configuration, URI, Class)}, which will
 create either an HA- or non-HA-enabled client proxy as appropriate.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.NameNodeProxies -->
  <!-- start class org.apache.hadoop.hdfs.NameNodeProxies.ProxyAndInfo -->
  <class name="NameNodeProxies.ProxyAndInfo" extends="java.lang.Object"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="NameNodeProxies.ProxyAndInfo" type="PROXYTYPE, org.apache.hadoop.io.Text, java.net.InetSocketAddress"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getProxy" return="PROXYTYPE"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getDelegationTokenService" return="org.apache.hadoop.io.Text"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getAddress" return="java.net.InetSocketAddress"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[Wrapper for a client proxy as well as its associated service ID.
 This is simply used as a tuple-like return type for
 {@link NameNodeProxies#createProxy} and
 {@link NameNodeProxies#createNonHAProxy}.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.NameNodeProxies.ProxyAndInfo -->
  <!-- start interface org.apache.hadoop.hdfs.RemotePeerFactory -->
  <interface name="RemotePeerFactory"    abstract="true"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="newConnectedPeer" return="org.apache.hadoop.hdfs.net.Peer"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="addr" type="java.net.InetSocketAddress"/>
      <param name="blockToken" type="org.apache.hadoop.security.token.Token"/>
      <param name="datanodeId" type="org.apache.hadoop.hdfs.protocol.DatanodeID"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[@param addr          The address to connect to.
 @param blockToken    Token used during optional SASL negotiation
 @param datanodeId    ID of destination DataNode
 @return              A new Peer connected to the address.

 @throws IOException  If there was an error connecting or creating 
                      the remote socket, encrypted stream, etc.]]>
      </doc>
    </method>
  </interface>
  <!-- end interface org.apache.hadoop.hdfs.RemotePeerFactory -->
  <!-- start class org.apache.hadoop.hdfs.StorageType -->
  <class name="StorageType" extends="java.lang.Enum"
    abstract="false"
    static="false" final="true" visibility="public"
    deprecated="not deprecated">
    <method name="values" return="org.apache.hadoop.hdfs.StorageType[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="valueOf" return="org.apache.hadoop.hdfs.StorageType"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="name" type="java.lang.String"/>
    </method>
    <method name="isTransient" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="isMovable" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="asList" return="java.util.List"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getMovableTypes" return="java.util.List"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <field name="DEFAULT" type="org.apache.hadoop.hdfs.StorageType"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="EMPTY_ARRAY" type="org.apache.hadoop.hdfs.StorageType[]"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <doc>
    <![CDATA[Defines the types of supported storage media. The default storage
 medium is assumed to be DISK.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.StorageType -->
  <!-- start class org.apache.hadoop.hdfs.UnknownCipherSuiteException -->
  <class name="UnknownCipherSuiteException" extends="java.io.IOException"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="UnknownCipherSuiteException" type="java.lang.String"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <doc>
    <![CDATA[Thrown when an unknown cipher suite is encountered.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.UnknownCipherSuiteException -->
  <!-- start class org.apache.hadoop.hdfs.UnknownCryptoProtocolVersionException -->
  <class name="UnknownCryptoProtocolVersionException" extends="java.io.IOException"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="UnknownCryptoProtocolVersionException"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <constructor name="UnknownCryptoProtocolVersionException" type="java.lang.String"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
  </class>
  <!-- end class org.apache.hadoop.hdfs.UnknownCryptoProtocolVersionException -->
  <doc>
  <![CDATA[<p>A distributed implementation of {@link
org.apache.hadoop.fs.FileSystem}.  This is loosely modelled after
Google's <a href="http://research.google.com/archive/gfs.html">GFS</a>.</p>

<p>The most important difference is that unlike GFS, Hadoop DFS files 
have strictly one writer at any one time.  Bytes are always appended 
to the end of the writer's stream.  There is no notion of "record appends"
or "mutations" that are then checked or reordered.  Writers simply emit 
a byte stream.  That byte stream is guaranteed to be stored in the 
order written.</p>]]>
  </doc>
</package>
<package name="org.apache.hadoop.hdfs.client">
  <!-- start class org.apache.hadoop.hdfs.client.HdfsAdmin -->
  <class name="HdfsAdmin" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="HdfsAdmin" type="java.net.URI, org.apache.hadoop.conf.Configuration"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Create a new HdfsAdmin client.
 
 @param uri the unique URI of the HDFS file system to administer
 @param conf configuration
 @throws IOException in the event the file system could not be created]]>
      </doc>
    </constructor>
    <method name="setQuota"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="org.apache.hadoop.fs.Path"/>
      <param name="quota" type="long"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Set the namespace quota (count of files, directories, and sym links) for a
 directory.
 
 @param src the path to set the quota for
 @param quota the value to set for the quota
 @throws IOException in the event of error]]>
      </doc>
    </method>
    <method name="clearQuota"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="org.apache.hadoop.fs.Path"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Clear the namespace quota (count of files, directories and sym links) for a
 directory.
 
 @param src the path to clear the quota of
 @throws IOException in the event of error]]>
      </doc>
    </method>
    <method name="setSpaceQuota"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="org.apache.hadoop.fs.Path"/>
      <param name="spaceQuota" type="long"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Set the disk space quota (size of files) for a directory. Note that
 directories and sym links do not occupy disk space.
 
 @param src the path to set the space quota of
 @param spaceQuota the value to set for the space quota
 @throws IOException in the event of error]]>
      </doc>
    </method>
    <method name="clearSpaceQuota"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="org.apache.hadoop.fs.Path"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Clear the disk space quota (size of files) for a directory. Note that
 directories and sym links do not occupy disk space.
 
 @param src the path to clear the space quota of
 @throws IOException in the event of error]]>
      </doc>
    </method>
    <method name="allowSnapshot"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="path" type="org.apache.hadoop.fs.Path"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Allow snapshot on a directory.
 @param path The path of the directory where snapshots will be taken.]]>
      </doc>
    </method>
    <method name="disallowSnapshot"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="path" type="org.apache.hadoop.fs.Path"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Disallow snapshot on a directory.
 @param path The path of the snapshottable directory.]]>
      </doc>
    </method>
    <method name="addCacheDirective" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="info" type="org.apache.hadoop.hdfs.protocol.CacheDirectiveInfo"/>
      <param name="flags" type="java.util.EnumSet"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Add a new CacheDirectiveInfo.
 
 @param info Information about a directive to add.
 @param flags {@link CacheFlag}s to use for this operation.
 @return the ID of the directive that was created.
 @throws IOException if the directive could not be added]]>
      </doc>
    </method>
    <method name="modifyCacheDirective"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="info" type="org.apache.hadoop.hdfs.protocol.CacheDirectiveInfo"/>
      <param name="flags" type="java.util.EnumSet"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Modify a CacheDirective.
 
 @param info Information about the directive to modify. You must set the ID
          to indicate which CacheDirective you want to modify.
 @param flags {@link CacheFlag}s to use for this operation.
 @throws IOException if the directive could not be modified]]>
      </doc>
    </method>
    <method name="removeCacheDirective"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="id" type="long"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Remove a CacheDirective.
 
 @param id identifier of the CacheDirectiveInfo to remove
 @throws IOException if the directive could not be removed]]>
      </doc>
    </method>
    <method name="listCacheDirectives" return="org.apache.hadoop.fs.RemoteIterator"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="filter" type="org.apache.hadoop.hdfs.protocol.CacheDirectiveInfo"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[List cache directives. Incrementally fetches results from the server.
 
 @param filter Filter parameters to use when listing the directives, null to
               list all directives visible to us.
 @return A RemoteIterator which returns CacheDirectiveInfo objects.]]>
      </doc>
    </method>
    <method name="addCachePool"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="info" type="org.apache.hadoop.hdfs.protocol.CachePoolInfo"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Add a cache pool.

 @param info
          The request to add a cache pool.
 @throws IOException 
          If the request could not be completed.]]>
      </doc>
    </method>
    <method name="modifyCachePool"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="info" type="org.apache.hadoop.hdfs.protocol.CachePoolInfo"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Modify an existing cache pool.

 @param info
          The request to modify a cache pool.
 @throws IOException 
          If the request could not be completed.]]>
      </doc>
    </method>
    <method name="removeCachePool"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="poolName" type="java.lang.String"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Remove a cache pool.

 @param poolName
          Name of the cache pool to remove.
 @throws IOException 
          if the cache pool did not exist, or could not be removed.]]>
      </doc>
    </method>
    <method name="listCachePools" return="org.apache.hadoop.fs.RemoteIterator"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[List all cache pools.

 @return A remote iterator from which you can get CachePoolEntry objects.
          Requests will be made as needed.
 @throws IOException
          If there was an error listing cache pools.]]>
      </doc>
    </method>
    <method name="createEncryptionZone"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="path" type="org.apache.hadoop.fs.Path"/>
      <param name="keyName" type="java.lang.String"/>
      <exception name="IOException" type="java.io.IOException"/>
      <exception name="AccessControlException" type="org.apache.hadoop.security.AccessControlException"/>
      <exception name="FileNotFoundException" type="java.io.FileNotFoundException"/>
      <doc>
      <![CDATA[Create an encryption zone rooted at an empty existing directory, using the
 specified encryption key. An encryption zone has an associated encryption
 key used when reading and writing files within the zone.

 @param path    The path of the root of the encryption zone. Must refer to
                an empty, existing directory.
 @param keyName Name of key available at the KeyProvider.
 @throws IOException            if there was a general IO exception
 @throws AccessControlException if the caller does not have access to path
 @throws FileNotFoundException  if the path does not exist]]>
      </doc>
    </method>
    <method name="getEncryptionZoneForPath" return="org.apache.hadoop.hdfs.protocol.EncryptionZone"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="path" type="org.apache.hadoop.fs.Path"/>
      <exception name="IOException" type="java.io.IOException"/>
      <exception name="AccessControlException" type="org.apache.hadoop.security.AccessControlException"/>
      <exception name="FileNotFoundException" type="java.io.FileNotFoundException"/>
      <doc>
      <![CDATA[Get the path of the encryption zone for a given file or directory.

 @param path The path to get the ez for.

 @return The EncryptionZone of the ez, or null if path is not in an ez.
 @throws IOException            if there was a general IO exception
 @throws AccessControlException if the caller does not have access to path
 @throws FileNotFoundException  if the path does not exist]]>
      </doc>
    </method>
    <method name="listEncryptionZones" return="org.apache.hadoop.fs.RemoteIterator"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Returns a RemoteIterator which can be used to list the encryption zones
 in HDFS. For large numbers of encryption zones, the iterator will fetch
 the list of zones in a number of small batches.
 <p/>
 Since the list is fetched in batches, it does not represent a
 consistent snapshot of the entire list of encryption zones.
 <p/>
 This method can only be called by HDFS superusers.]]>
      </doc>
    </method>
    <method name="getInotifyEventStream" return="org.apache.hadoop.hdfs.DFSInotifyEventInputStream"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Exposes a stream of namesystem events. Only events occurring after the
 stream is created are available.
 See {@link org.apache.hadoop.hdfs.DFSInotifyEventInputStream}
 for information on stream usage.
 See {@link org.apache.hadoop.hdfs.inotify.Event}
 for information on the available events.
 <p/>
 Inotify users may want to tune the following HDFS parameters to
 ensure that enough extra HDFS edits are saved to support inotify clients
 that fall behind the current state of the namespace while reading events.
 The default parameter values should generally be reasonable. If edits are
 deleted before their corresponding events can be read, clients will see a
 {@link org.apache.hadoop.hdfs.inotify.MissingEventsException} on
 {@link org.apache.hadoop.hdfs.DFSInotifyEventInputStream} method calls.

 It should generally be sufficient to tune these parameters:
 dfs.namenode.num.extra.edits.retained
 dfs.namenode.max.extra.edits.segments.retained

 Parameters that affect the number of created segments and the number of
 edits that are considered necessary, i.e. do not count towards the
 dfs.namenode.num.extra.edits.retained quota):
 dfs.namenode.checkpoint.period
 dfs.namenode.checkpoint.txns
 dfs.namenode.num.checkpoints.retained
 dfs.ha.log-roll.period
 <p/>
 It is recommended that local journaling be configured
 (dfs.namenode.edits.dir) for inotify (in addition to a shared journal)
 so that edit transfers from the shared journal can be avoided.

 @throws IOException If there was an error obtaining the stream.]]>
      </doc>
    </method>
    <method name="getInotifyEventStream" return="org.apache.hadoop.hdfs.DFSInotifyEventInputStream"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="lastReadTxid" type="long"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[A version of {@link HdfsAdmin#getInotifyEventStream()} meant for advanced
 users who are aware of HDFS edits up to lastReadTxid (e.g. because they
 have access to an FSImage inclusive of lastReadTxid) and only want to read
 events after this point.]]>
      </doc>
    </method>
    <method name="setStoragePolicy"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="org.apache.hadoop.fs.Path"/>
      <param name="policyName" type="java.lang.String"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Set the source path to the specified storage policy.

 @param src The source path referring to either a directory or a file.
 @param policyName The name of the storage policy.]]>
      </doc>
    </method>
    <doc>
    <![CDATA[The public API for performing administrative functions on HDFS. Those writing
 applications against HDFS should prefer this interface to directly accessing
 functionality in DistributedFileSystem or DFSClient.
 
 Note that this is distinct from the similarly-named {@link DFSAdmin}, which
 is a class that provides the functionality for the CLI `hdfs dfsadmin ...'
 commands.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.client.HdfsAdmin -->
  <!-- start class org.apache.hadoop.hdfs.client.HdfsDataInputStream -->
  <class name="HdfsDataInputStream" extends="org.apache.hadoop.fs.FSDataInputStream"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="HdfsDataInputStream" type="org.apache.hadoop.hdfs.DFSInputStream"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
    </constructor>
    <constructor name="HdfsDataInputStream" type="org.apache.hadoop.crypto.CryptoInputStream"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
    </constructor>
    <method name="getWrappedStream" return="java.io.InputStream"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Get a reference to the wrapped output stream. We always want to return the
 actual underlying InputStream, even when we're using a CryptoStream. e.g.
 in the delegated methods below.

 @return the underlying output stream]]>
      </doc>
    </method>
    <method name="getCurrentDatanode" return="org.apache.hadoop.hdfs.protocol.DatanodeInfo"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Get the datanode from which the stream is currently reading.]]>
      </doc>
    </method>
    <method name="getCurrentBlock" return="org.apache.hadoop.hdfs.protocol.ExtendedBlock"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Get the block containing the target position.]]>
      </doc>
    </method>
    <method name="getAllBlocks" return="java.util.List"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Get the collection of blocks that has already been located.]]>
      </doc>
    </method>
    <method name="getVisibleLength" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Get the visible length of the file. It will include the length of the last
 block even if that is in UnderConstruction state.
 
 @return The visible length of the file.]]>
      </doc>
    </method>
    <method name="getReadStatistics" return="org.apache.hadoop.hdfs.DFSInputStream.ReadStatistics"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Get statistics about the reads which this DFSInputStream has done.
 Note that because HdfsDataInputStream is buffered, these stats may
 be higher than you would expect just by adding up the number of
 bytes read through HdfsDataInputStream.]]>
      </doc>
    </method>
    <doc>
    <![CDATA[The Hdfs implementation of {@link FSDataInputStream}.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.client.HdfsDataInputStream -->
  <!-- start class org.apache.hadoop.hdfs.client.HdfsDataOutputStream -->
  <class name="HdfsDataOutputStream" extends="org.apache.hadoop.fs.FSDataOutputStream"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="HdfsDataOutputStream" type="org.apache.hadoop.hdfs.DFSOutputStream, org.apache.hadoop.fs.FileSystem.Statistics, long"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
    </constructor>
    <constructor name="HdfsDataOutputStream" type="org.apache.hadoop.hdfs.DFSOutputStream, org.apache.hadoop.fs.FileSystem.Statistics"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
    </constructor>
    <constructor name="HdfsDataOutputStream" type="org.apache.hadoop.crypto.CryptoOutputStream, org.apache.hadoop.fs.FileSystem.Statistics, long"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
    </constructor>
    <constructor name="HdfsDataOutputStream" type="org.apache.hadoop.crypto.CryptoOutputStream, org.apache.hadoop.fs.FileSystem.Statistics"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
    </constructor>
    <method name="getCurrentBlockReplication" return="int"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Get the actual number of replicas of the current block.
 
 This can be different from the designated replication factor of the file
 because the namenode does not maintain replication for the blocks which are
 currently being written to. Depending on the configuration, the client may
 continue to write to a block even if a few datanodes in the write pipeline
 have failed, or the client may add a new datanodes once a datanode has
 failed.
 
 @return the number of valid replicas of the current block]]>
      </doc>
    </method>
    <method name="hsync"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="syncFlags" type="java.util.EnumSet"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Sync buffered data to DataNodes (flush to disk devices).
 
 @param syncFlags
          Indicate the detailed semantic and actions of the hsync.
 @throws IOException
 @see FSDataOutputStream#hsync()]]>
      </doc>
    </method>
    <doc>
    <![CDATA[The Hdfs implementation of {@link FSDataOutputStream}.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.client.HdfsDataOutputStream -->
  <!-- start class org.apache.hadoop.hdfs.client.HdfsDataOutputStream.SyncFlag -->
  <class name="HdfsDataOutputStream.SyncFlag" extends="java.lang.Enum"
    abstract="false"
    static="true" final="true" visibility="public"
    deprecated="not deprecated">
    <method name="values" return="org.apache.hadoop.hdfs.client.HdfsDataOutputStream.SyncFlag[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="valueOf" return="org.apache.hadoop.hdfs.client.HdfsDataOutputStream.SyncFlag"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="name" type="java.lang.String"/>
    </method>
  </class>
  <!-- end class org.apache.hadoop.hdfs.client.HdfsDataOutputStream.SyncFlag -->
  <!-- start class org.apache.hadoop.hdfs.client.HdfsUtils -->
  <class name="HdfsUtils" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="HdfsUtils"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="isHealthy" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="uri" type="java.net.URI"/>
      <doc>
      <![CDATA[Is the HDFS healthy?
 HDFS is considered as healthy if it is up and not in safemode.

 @param uri the HDFS URI.  Note that the URI path is ignored.
 @return true if HDFS is healthy; false, otherwise.]]>
      </doc>
    </method>
    <doc>
    <![CDATA[The public utility API for HDFS.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.client.HdfsUtils -->
</package>
<package name="org.apache.hadoop.hdfs.inotify">
  <!-- start class org.apache.hadoop.hdfs.inotify.Event -->
  <class name="Event" extends="java.lang.Object"
    abstract="true"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="Event" type="org.apache.hadoop.hdfs.inotify.Event.EventType"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getEventType" return="org.apache.hadoop.hdfs.inotify.Event.EventType"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[Events sent by the inotify system. Note that no events are necessarily sent
 when a file is opened for read (although a MetadataUpdateEvent will be sent
 if the atime is updated).]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.inotify.Event -->
  <!-- start class org.apache.hadoop.hdfs.inotify.Event.AppendEvent -->
  <class name="Event.AppendEvent" extends="org.apache.hadoop.hdfs.inotify.Event"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="Event.AppendEvent" type="java.lang.String"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getPath" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[Sent when an existing file is opened for append.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.inotify.Event.AppendEvent -->
  <!-- start class org.apache.hadoop.hdfs.inotify.Event.CloseEvent -->
  <class name="Event.CloseEvent" extends="org.apache.hadoop.hdfs.inotify.Event"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="Event.CloseEvent" type="java.lang.String, long, long"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getPath" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getFileSize" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[The size of the closed file in bytes. May be -1 if the size is not
 available (e.g. in the case of a close generated by a concat operation).]]>
      </doc>
    </method>
    <method name="getTimestamp" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[The time when this event occurred, in milliseconds since the epoch.]]>
      </doc>
    </method>
    <doc>
    <![CDATA[Sent when a file is closed after append or create.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.inotify.Event.CloseEvent -->
  <!-- start class org.apache.hadoop.hdfs.inotify.Event.CreateEvent -->
  <class name="Event.CreateEvent" extends="org.apache.hadoop.hdfs.inotify.Event"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="getiNodeType" return="org.apache.hadoop.hdfs.inotify.Event.CreateEvent.INodeType"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getPath" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getCtime" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Creation time of the file, directory, or symlink.]]>
      </doc>
    </method>
    <method name="getReplication" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Replication is zero if the CreateEvent iNodeType is directory or symlink.]]>
      </doc>
    </method>
    <method name="getOwnerName" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getGroupName" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getPerms" return="org.apache.hadoop.fs.permission.FsPermission"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getSymlinkTarget" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Symlink target is null if the CreateEvent iNodeType is not symlink.]]>
      </doc>
    </method>
    <method name="getOverwrite" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[Sent when a new file is created (including overwrite).]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.inotify.Event.CreateEvent -->
  <!-- start class org.apache.hadoop.hdfs.inotify.Event.CreateEvent.Builder -->
  <class name="Event.CreateEvent.Builder" extends="java.lang.Object"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="Event.CreateEvent.Builder"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="iNodeType" return="org.apache.hadoop.hdfs.inotify.Event.CreateEvent.Builder"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="type" type="org.apache.hadoop.hdfs.inotify.Event.CreateEvent.INodeType"/>
    </method>
    <method name="path" return="org.apache.hadoop.hdfs.inotify.Event.CreateEvent.Builder"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="path" type="java.lang.String"/>
    </method>
    <method name="ctime" return="org.apache.hadoop.hdfs.inotify.Event.CreateEvent.Builder"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="ctime" type="long"/>
    </method>
    <method name="replication" return="org.apache.hadoop.hdfs.inotify.Event.CreateEvent.Builder"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="replication" type="int"/>
    </method>
    <method name="ownerName" return="org.apache.hadoop.hdfs.inotify.Event.CreateEvent.Builder"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="ownerName" type="java.lang.String"/>
    </method>
    <method name="groupName" return="org.apache.hadoop.hdfs.inotify.Event.CreateEvent.Builder"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="groupName" type="java.lang.String"/>
    </method>
    <method name="perms" return="org.apache.hadoop.hdfs.inotify.Event.CreateEvent.Builder"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="perms" type="org.apache.hadoop.fs.permission.FsPermission"/>
    </method>
    <method name="symlinkTarget" return="org.apache.hadoop.hdfs.inotify.Event.CreateEvent.Builder"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="symlinkTarget" type="java.lang.String"/>
    </method>
    <method name="overwrite" return="org.apache.hadoop.hdfs.inotify.Event.CreateEvent.Builder"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="overwrite" type="boolean"/>
    </method>
    <method name="build" return="org.apache.hadoop.hdfs.inotify.Event.CreateEvent"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
  </class>
  <!-- end class org.apache.hadoop.hdfs.inotify.Event.CreateEvent.Builder -->
  <!-- start class org.apache.hadoop.hdfs.inotify.Event.CreateEvent.INodeType -->
  <class name="Event.CreateEvent.INodeType" extends="java.lang.Enum"
    abstract="false"
    static="true" final="true" visibility="public"
    deprecated="not deprecated">
    <method name="values" return="org.apache.hadoop.hdfs.inotify.Event.CreateEvent.INodeType[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="valueOf" return="org.apache.hadoop.hdfs.inotify.Event.CreateEvent.INodeType"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="name" type="java.lang.String"/>
    </method>
  </class>
  <!-- end class org.apache.hadoop.hdfs.inotify.Event.CreateEvent.INodeType -->
  <!-- start class org.apache.hadoop.hdfs.inotify.Event.EventType -->
  <class name="Event.EventType" extends="java.lang.Enum"
    abstract="false"
    static="true" final="true" visibility="public"
    deprecated="not deprecated">
    <method name="values" return="org.apache.hadoop.hdfs.inotify.Event.EventType[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="valueOf" return="org.apache.hadoop.hdfs.inotify.Event.EventType"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="name" type="java.lang.String"/>
    </method>
  </class>
  <!-- end class org.apache.hadoop.hdfs.inotify.Event.EventType -->
  <!-- start class org.apache.hadoop.hdfs.inotify.Event.MetadataUpdateEvent -->
  <class name="Event.MetadataUpdateEvent" extends="org.apache.hadoop.hdfs.inotify.Event"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="getPath" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getMetadataType" return="org.apache.hadoop.hdfs.inotify.Event.MetadataUpdateEvent.MetadataType"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getMtime" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getAtime" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getReplication" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getOwnerName" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getGroupName" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getPerms" return="org.apache.hadoop.fs.permission.FsPermission"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getAcls" return="java.util.List"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[The full set of ACLs currently associated with this file or directory.
 May be null if all ACLs were removed.]]>
      </doc>
    </method>
    <method name="getxAttrs" return="java.util.List"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="isxAttrsRemoved" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Whether the xAttrs returned by getxAttrs() were removed (as opposed to
 added).]]>
      </doc>
    </method>
    <doc>
    <![CDATA[Sent when there is an update to directory or file (none of the metadata
 tracked here applies to symlinks) that is not associated with another
 inotify event. The tracked metadata includes atime/mtime, replication,
 owner/group, permissions, ACLs, and XAttributes. Fields not relevant to the
 metadataType of the MetadataUpdateEvent will be null or will have their default
 values.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.inotify.Event.MetadataUpdateEvent -->
  <!-- start class org.apache.hadoop.hdfs.inotify.Event.MetadataUpdateEvent.Builder -->
  <class name="Event.MetadataUpdateEvent.Builder" extends="java.lang.Object"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="Event.MetadataUpdateEvent.Builder"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="path" return="org.apache.hadoop.hdfs.inotify.Event.MetadataUpdateEvent.Builder"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="path" type="java.lang.String"/>
    </method>
    <method name="metadataType" return="org.apache.hadoop.hdfs.inotify.Event.MetadataUpdateEvent.Builder"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="type" type="org.apache.hadoop.hdfs.inotify.Event.MetadataUpdateEvent.MetadataType"/>
    </method>
    <method name="mtime" return="org.apache.hadoop.hdfs.inotify.Event.MetadataUpdateEvent.Builder"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="mtime" type="long"/>
    </method>
    <method name="atime" return="org.apache.hadoop.hdfs.inotify.Event.MetadataUpdateEvent.Builder"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="atime" type="long"/>
    </method>
    <method name="replication" return="org.apache.hadoop.hdfs.inotify.Event.MetadataUpdateEvent.Builder"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="replication" type="int"/>
    </method>
    <method name="ownerName" return="org.apache.hadoop.hdfs.inotify.Event.MetadataUpdateEvent.Builder"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="ownerName" type="java.lang.String"/>
    </method>
    <method name="groupName" return="org.apache.hadoop.hdfs.inotify.Event.MetadataUpdateEvent.Builder"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="groupName" type="java.lang.String"/>
    </method>
    <method name="perms" return="org.apache.hadoop.hdfs.inotify.Event.MetadataUpdateEvent.Builder"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="perms" type="org.apache.hadoop.fs.permission.FsPermission"/>
    </method>
    <method name="acls" return="org.apache.hadoop.hdfs.inotify.Event.MetadataUpdateEvent.Builder"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="acls" type="java.util.List"/>
    </method>
    <method name="xAttrs" return="org.apache.hadoop.hdfs.inotify.Event.MetadataUpdateEvent.Builder"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="xAttrs" type="java.util.List"/>
    </method>
    <method name="xAttrsRemoved" return="org.apache.hadoop.hdfs.inotify.Event.MetadataUpdateEvent.Builder"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="xAttrsRemoved" type="boolean"/>
    </method>
    <method name="build" return="org.apache.hadoop.hdfs.inotify.Event.MetadataUpdateEvent"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
  </class>
  <!-- end class org.apache.hadoop.hdfs.inotify.Event.MetadataUpdateEvent.Builder -->
  <!-- start class org.apache.hadoop.hdfs.inotify.Event.MetadataUpdateEvent.MetadataType -->
  <class name="Event.MetadataUpdateEvent.MetadataType" extends="java.lang.Enum"
    abstract="false"
    static="true" final="true" visibility="public"
    deprecated="not deprecated">
    <method name="values" return="org.apache.hadoop.hdfs.inotify.Event.MetadataUpdateEvent.MetadataType[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="valueOf" return="org.apache.hadoop.hdfs.inotify.Event.MetadataUpdateEvent.MetadataType"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="name" type="java.lang.String"/>
    </method>
  </class>
  <!-- end class org.apache.hadoop.hdfs.inotify.Event.MetadataUpdateEvent.MetadataType -->
  <!-- start class org.apache.hadoop.hdfs.inotify.Event.RenameEvent -->
  <class name="Event.RenameEvent" extends="org.apache.hadoop.hdfs.inotify.Event"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="Event.RenameEvent" type="java.lang.String, java.lang.String, long"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getSrcPath" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getDstPath" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getTimestamp" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[The time when this event occurred, in milliseconds since the epoch.]]>
      </doc>
    </method>
    <doc>
    <![CDATA[Sent when a file, directory, or symlink is renamed.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.inotify.Event.RenameEvent -->
  <!-- start class org.apache.hadoop.hdfs.inotify.Event.UnlinkEvent -->
  <class name="Event.UnlinkEvent" extends="org.apache.hadoop.hdfs.inotify.Event"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="Event.UnlinkEvent" type="java.lang.String, long"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getPath" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getTimestamp" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[The time when this event occurred, in milliseconds since the epoch.]]>
      </doc>
    </method>
    <doc>
    <![CDATA[Sent when a file, directory, or symlink is deleted.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.inotify.Event.UnlinkEvent -->
  <!-- start class org.apache.hadoop.hdfs.inotify.MissingEventsException -->
  <class name="MissingEventsException" extends="java.lang.Exception"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="MissingEventsException"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <constructor name="MissingEventsException" type="long, long"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getExpectedTxid" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getActualTxid" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="toString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
  </class>
  <!-- end class org.apache.hadoop.hdfs.inotify.MissingEventsException -->
</package>
<package name="org.apache.hadoop.hdfs.net">
</package>
<package name="org.apache.hadoop.hdfs.protocol">
  <!-- start class org.apache.hadoop.hdfs.protocol.CacheDirectiveEntry -->
  <class name="CacheDirectiveEntry" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="CacheDirectiveEntry" type="org.apache.hadoop.hdfs.protocol.CacheDirectiveInfo, org.apache.hadoop.hdfs.protocol.CacheDirectiveStats"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getInfo" return="org.apache.hadoop.hdfs.protocol.CacheDirectiveInfo"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getStats" return="org.apache.hadoop.hdfs.protocol.CacheDirectiveStats"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[Describes a path-based cache directive entry.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.protocol.CacheDirectiveEntry -->
  <!-- start class org.apache.hadoop.hdfs.protocol.CacheDirectiveInfo -->
  <class name="CacheDirectiveInfo" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="getId" return="java.lang.Long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return The ID of this directive.]]>
      </doc>
    </method>
    <method name="getPath" return="org.apache.hadoop.fs.Path"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return The path used in this request.]]>
      </doc>
    </method>
    <method name="getReplication" return="java.lang.Short"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return The number of times the block should be cached.]]>
      </doc>
    </method>
    <method name="getPool" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return The pool used in this request.]]>
      </doc>
    </method>
    <method name="getExpiration" return="org.apache.hadoop.hdfs.protocol.CacheDirectiveInfo.Expiration"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return When this directive expires.]]>
      </doc>
    </method>
    <method name="equals" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="o" type="java.lang.Object"/>
    </method>
    <method name="hashCode" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="toString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[Describes a path-based cache directive.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.protocol.CacheDirectiveInfo -->
  <!-- start class org.apache.hadoop.hdfs.protocol.CacheDirectiveInfo.Builder -->
  <class name="CacheDirectiveInfo.Builder" extends="java.lang.Object"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="CacheDirectiveInfo.Builder"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Creates an empty builder.]]>
      </doc>
    </constructor>
    <constructor name="CacheDirectiveInfo.Builder" type="org.apache.hadoop.hdfs.protocol.CacheDirectiveInfo"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Creates a builder with all elements set to the same values as the
 given CacheDirectiveInfo.]]>
      </doc>
    </constructor>
    <method name="build" return="org.apache.hadoop.hdfs.protocol.CacheDirectiveInfo"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Builds a new CacheDirectiveInfo populated with the set properties.
 
 @return New CacheDirectiveInfo.]]>
      </doc>
    </method>
    <method name="setId" return="org.apache.hadoop.hdfs.protocol.CacheDirectiveInfo.Builder"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="id" type="java.lang.Long"/>
      <doc>
      <![CDATA[Sets the id used in this request.
 
 @param id The id used in this request.
 @return This builder, for call chaining.]]>
      </doc>
    </method>
    <method name="setPath" return="org.apache.hadoop.hdfs.protocol.CacheDirectiveInfo.Builder"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="path" type="org.apache.hadoop.fs.Path"/>
      <doc>
      <![CDATA[Sets the path used in this request.
 
 @param path The path used in this request.
 @return This builder, for call chaining.]]>
      </doc>
    </method>
    <method name="setReplication" return="org.apache.hadoop.hdfs.protocol.CacheDirectiveInfo.Builder"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="replication" type="java.lang.Short"/>
      <doc>
      <![CDATA[Sets the replication used in this request.
 
 @param replication The replication used in this request.
 @return This builder, for call chaining.]]>
      </doc>
    </method>
    <method name="setPool" return="org.apache.hadoop.hdfs.protocol.CacheDirectiveInfo.Builder"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="pool" type="java.lang.String"/>
      <doc>
      <![CDATA[Sets the pool used in this request.
 
 @param pool The pool used in this request.
 @return This builder, for call chaining.]]>
      </doc>
    </method>
    <method name="setExpiration" return="org.apache.hadoop.hdfs.protocol.CacheDirectiveInfo.Builder"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="expiration" type="org.apache.hadoop.hdfs.protocol.CacheDirectiveInfo.Expiration"/>
      <doc>
      <![CDATA[Sets when the CacheDirective should expire. A
 {@link CacheDirectiveInfo.Expiration} can specify either an absolute or
 relative expiration time.
 
 @param expiration when this CacheDirective should expire
 @return This builder, for call chaining]]>
      </doc>
    </method>
    <doc>
    <![CDATA[A builder for creating new CacheDirectiveInfo instances.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.protocol.CacheDirectiveInfo.Builder -->
  <!-- start class org.apache.hadoop.hdfs.protocol.CacheDirectiveInfo.Expiration -->
  <class name="CacheDirectiveInfo.Expiration" extends="java.lang.Object"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="newRelative" return="org.apache.hadoop.hdfs.protocol.CacheDirectiveInfo.Expiration"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="ms" type="long"/>
      <doc>
      <![CDATA[Create a new relative Expiration.
 <p>
 Use {@link Expiration#NEVER} to indicate an Expiration that never
 expires.
 
 @param ms how long until the CacheDirective expires, in milliseconds
 @return A relative Expiration]]>
      </doc>
    </method>
    <method name="newAbsolute" return="org.apache.hadoop.hdfs.protocol.CacheDirectiveInfo.Expiration"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="date" type="java.util.Date"/>
      <doc>
      <![CDATA[Create a new absolute Expiration.
 <p>
 Use {@link Expiration#NEVER} to indicate an Expiration that never
 expires.
 
 @param date when the CacheDirective expires
 @return An absolute Expiration]]>
      </doc>
    </method>
    <method name="newAbsolute" return="org.apache.hadoop.hdfs.protocol.CacheDirectiveInfo.Expiration"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="ms" type="long"/>
      <doc>
      <![CDATA[Create a new absolute Expiration.
 <p>
 Use {@link Expiration#NEVER} to indicate an Expiration that never
 expires.
 
 @param ms when the CacheDirective expires, in milliseconds since the Unix
          epoch.
 @return An absolute Expiration]]>
      </doc>
    </method>
    <method name="isRelative" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return true if Expiration was specified as a relative duration, false if
         specified as an absolute time.]]>
      </doc>
    </method>
    <method name="getMillis" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return The raw underlying millisecond value, either a relative duration
         or an absolute time as milliseconds since the Unix epoch.]]>
      </doc>
    </method>
    <method name="getAbsoluteDate" return="java.util.Date"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return Expiration time as a {@link Date} object. This converts a
         relative Expiration into an absolute Date based on the local
         clock.]]>
      </doc>
    </method>
    <method name="getAbsoluteMillis" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return Expiration time in milliseconds from the Unix epoch. This
         converts a relative Expiration into an absolute time based on the
         local clock.]]>
      </doc>
    </method>
    <method name="toString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <field name="MAX_RELATIVE_EXPIRY_MS" type="long"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[The maximum value we accept for a relative expiry.]]>
      </doc>
    </field>
    <field name="NEVER" type="org.apache.hadoop.hdfs.protocol.CacheDirectiveInfo.Expiration"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[An relative Expiration that never expires.]]>
      </doc>
    </field>
    <doc>
    <![CDATA[Denotes a relative or absolute expiration time for a CacheDirective. Use
 factory methods {@link CacheDirectiveInfo.Expiration#newAbsolute(Date)} and
 {@link CacheDirectiveInfo.Expiration#newRelative(long)} to create an
 Expiration.
 <p>
 In either case, the server-side clock is used to determine when a
 CacheDirective expires.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.protocol.CacheDirectiveInfo.Expiration -->
  <!-- start class org.apache.hadoop.hdfs.protocol.CacheDirectiveStats -->
  <class name="CacheDirectiveStats" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="getBytesNeeded" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return The bytes needed.]]>
      </doc>
    </method>
    <method name="getBytesCached" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return The bytes cached.]]>
      </doc>
    </method>
    <method name="getFilesNeeded" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return The number of files needed.]]>
      </doc>
    </method>
    <method name="getFilesCached" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return The number of files cached.]]>
      </doc>
    </method>
    <method name="hasExpired" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return Whether this directive has expired.]]>
      </doc>
    </method>
    <method name="toString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[Describes a path-based cache directive.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.protocol.CacheDirectiveStats -->
  <!-- start class org.apache.hadoop.hdfs.protocol.CacheDirectiveStats.Builder -->
  <class name="CacheDirectiveStats.Builder" extends="java.lang.Object"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="CacheDirectiveStats.Builder"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Creates an empty builder.]]>
      </doc>
    </constructor>
    <method name="build" return="org.apache.hadoop.hdfs.protocol.CacheDirectiveStats"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Builds a new CacheDirectiveStats populated with the set properties.
 
 @return New CacheDirectiveStats.]]>
      </doc>
    </method>
    <method name="setBytesNeeded" return="org.apache.hadoop.hdfs.protocol.CacheDirectiveStats.Builder"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="bytesNeeded" type="long"/>
      <doc>
      <![CDATA[Sets the bytes needed by this directive.
 
 @param bytesNeeded The bytes needed.
 @return This builder, for call chaining.]]>
      </doc>
    </method>
    <method name="setBytesCached" return="org.apache.hadoop.hdfs.protocol.CacheDirectiveStats.Builder"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="bytesCached" type="long"/>
      <doc>
      <![CDATA[Sets the bytes cached by this directive.
 
 @param bytesCached The bytes cached.
 @return This builder, for call chaining.]]>
      </doc>
    </method>
    <method name="setFilesNeeded" return="org.apache.hadoop.hdfs.protocol.CacheDirectiveStats.Builder"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="filesNeeded" type="long"/>
      <doc>
      <![CDATA[Sets the files needed by this directive.
 @param filesNeeded The number of files needed
 @return This builder, for call chaining.]]>
      </doc>
    </method>
    <method name="setFilesCached" return="org.apache.hadoop.hdfs.protocol.CacheDirectiveStats.Builder"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="filesCached" type="long"/>
      <doc>
      <![CDATA[Sets the files cached by this directive.
 
 @param filesCached The number of files cached.
 @return This builder, for call chaining.]]>
      </doc>
    </method>
    <method name="setHasExpired" return="org.apache.hadoop.hdfs.protocol.CacheDirectiveStats.Builder"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="hasExpired" type="boolean"/>
      <doc>
      <![CDATA[Sets whether this directive has expired.
 
 @param hasExpired if this directive has expired
 @return This builder, for call chaining.]]>
      </doc>
    </method>
  </class>
  <!-- end class org.apache.hadoop.hdfs.protocol.CacheDirectiveStats.Builder -->
  <!-- start class org.apache.hadoop.hdfs.protocol.CachePoolEntry -->
  <class name="CachePoolEntry" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="CachePoolEntry" type="org.apache.hadoop.hdfs.protocol.CachePoolInfo, org.apache.hadoop.hdfs.protocol.CachePoolStats"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getInfo" return="org.apache.hadoop.hdfs.protocol.CachePoolInfo"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getStats" return="org.apache.hadoop.hdfs.protocol.CachePoolStats"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[Describes a Cache Pool entry.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.protocol.CachePoolEntry -->
  <!-- start class org.apache.hadoop.hdfs.protocol.CachePoolInfo -->
  <class name="CachePoolInfo" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="CachePoolInfo" type="java.lang.String"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getPoolName" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return Name of the pool.]]>
      </doc>
    </method>
    <method name="getOwnerName" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return The owner of the pool. Along with the group and mode, determines
         who has access to view and modify the pool.]]>
      </doc>
    </method>
    <method name="setOwnerName" return="org.apache.hadoop.hdfs.protocol.CachePoolInfo"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="ownerName" type="java.lang.String"/>
    </method>
    <method name="getGroupName" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return The group of the pool. Along with the owner and mode, determines
         who has access to view and modify the pool.]]>
      </doc>
    </method>
    <method name="setGroupName" return="org.apache.hadoop.hdfs.protocol.CachePoolInfo"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="groupName" type="java.lang.String"/>
    </method>
    <method name="getMode" return="org.apache.hadoop.fs.permission.FsPermission"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return Unix-style permissions of the pool. Along with the owner and group,
         determines who has access to view and modify the pool.]]>
      </doc>
    </method>
    <method name="setMode" return="org.apache.hadoop.hdfs.protocol.CachePoolInfo"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="mode" type="org.apache.hadoop.fs.permission.FsPermission"/>
    </method>
    <method name="getLimit" return="java.lang.Long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return The maximum aggregate number of bytes that can be cached by
         directives in this pool.]]>
      </doc>
    </method>
    <method name="setLimit" return="org.apache.hadoop.hdfs.protocol.CachePoolInfo"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="bytes" type="java.lang.Long"/>
    </method>
    <method name="getMaxRelativeExpiryMs" return="java.lang.Long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return The maximum relative expiration of directives of this pool in
         milliseconds]]>
      </doc>
    </method>
    <method name="setMaxRelativeExpiryMs" return="org.apache.hadoop.hdfs.protocol.CachePoolInfo"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="ms" type="java.lang.Long"/>
      <doc>
      <![CDATA[Set the maximum relative expiration of directives of this pool in
 milliseconds.
 
 @param ms in milliseconds
 @return This builder, for call chaining.]]>
      </doc>
    </method>
    <method name="toString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="equals" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="o" type="java.lang.Object"/>
    </method>
    <method name="hashCode" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="validate"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="info" type="org.apache.hadoop.hdfs.protocol.CachePoolInfo"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="validateName"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="poolName" type="java.lang.String"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <field name="LOG" type="org.apache.commons.logging.Log"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="RELATIVE_EXPIRY_NEVER" type="long"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Indicates that the pool does not have a maximum relative expiry.]]>
      </doc>
    </field>
    <field name="DEFAULT_MAX_RELATIVE_EXPIRY" type="long"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Default max relative expiry for cache pools.]]>
      </doc>
    </field>
    <field name="LIMIT_UNLIMITED" type="long"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DEFAULT_LIMIT" type="long"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <doc>
    <![CDATA[CachePoolInfo describes a cache pool.

 This class is used in RPCs to create and modify cache pools.
 It is serializable and can be stored in the edit log.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.protocol.CachePoolInfo -->
  <!-- start class org.apache.hadoop.hdfs.protocol.CachePoolStats -->
  <class name="CachePoolStats" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="getBytesNeeded" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getBytesCached" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getBytesOverlimit" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getFilesNeeded" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getFilesCached" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="toString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[CachePoolStats describes cache pool statistics.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.protocol.CachePoolStats -->
  <!-- start class org.apache.hadoop.hdfs.protocol.CachePoolStats.Builder -->
  <class name="CachePoolStats.Builder" extends="java.lang.Object"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="CachePoolStats.Builder"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="setBytesNeeded" return="org.apache.hadoop.hdfs.protocol.CachePoolStats.Builder"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="bytesNeeded" type="long"/>
    </method>
    <method name="setBytesCached" return="org.apache.hadoop.hdfs.protocol.CachePoolStats.Builder"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="bytesCached" type="long"/>
    </method>
    <method name="setBytesOverlimit" return="org.apache.hadoop.hdfs.protocol.CachePoolStats.Builder"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="bytesOverlimit" type="long"/>
    </method>
    <method name="setFilesNeeded" return="org.apache.hadoop.hdfs.protocol.CachePoolStats.Builder"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="filesNeeded" type="long"/>
    </method>
    <method name="setFilesCached" return="org.apache.hadoop.hdfs.protocol.CachePoolStats.Builder"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="filesCached" type="long"/>
    </method>
    <method name="build" return="org.apache.hadoop.hdfs.protocol.CachePoolStats"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
  </class>
  <!-- end class org.apache.hadoop.hdfs.protocol.CachePoolStats.Builder -->
  <!-- start class org.apache.hadoop.hdfs.protocol.CorruptFileBlocks -->
  <class name="CorruptFileBlocks" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="CorruptFileBlocks"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <constructor name="CorruptFileBlocks" type="java.lang.String[], java.lang.String"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getFiles" return="java.lang.String[]"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getCookie" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="equals" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="obj" type="java.lang.Object"/>
    </method>
    <method name="hashCode" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[Contains a list of paths corresponding to corrupt files and a cookie
 used for iterative calls to NameNode.listCorruptFileBlocks.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.protocol.CorruptFileBlocks -->
  <!-- start class org.apache.hadoop.hdfs.protocol.DatanodeInfo.AdminStates -->
  <class name="DatanodeInfo.AdminStates" extends="java.lang.Enum"
    abstract="false"
    static="true" final="true" visibility="public"
    deprecated="not deprecated">
    <method name="values" return="org.apache.hadoop.hdfs.protocol.DatanodeInfo.AdminStates[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="valueOf" return="org.apache.hadoop.hdfs.protocol.DatanodeInfo.AdminStates"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="name" type="java.lang.String"/>
    </method>
    <method name="toString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="fromValue" return="org.apache.hadoop.hdfs.protocol.DatanodeInfo.AdminStates"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="value" type="java.lang.String"/>
    </method>
  </class>
  <!-- end class org.apache.hadoop.hdfs.protocol.DatanodeInfo.AdminStates -->
  <!-- start class org.apache.hadoop.hdfs.protocol.EncryptionZone -->
  <class name="EncryptionZone" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="EncryptionZone" type="long, java.lang.String, org.apache.hadoop.crypto.CipherSuite, org.apache.hadoop.crypto.CryptoProtocolVersion, java.lang.String"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getId" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getPath" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getSuite" return="org.apache.hadoop.crypto.CipherSuite"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getVersion" return="org.apache.hadoop.crypto.CryptoProtocolVersion"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getKeyName" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="hashCode" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="equals" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="obj" type="java.lang.Object"/>
    </method>
    <method name="toString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[A simple class for representing an encryption zone. Presently an encryption
 zone only has a path (the root of the encryption zone), a key name, and a
 unique id. The id is used to implement batched listing of encryption zones.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.protocol.EncryptionZone -->
  <!-- start class org.apache.hadoop.hdfs.protocol.FSConstants -->
  <class name="FSConstants" extends="org.apache.hadoop.hdfs.protocol.HdfsConstants"
    abstract="true"
    static="false" final="false" visibility="public"
    deprecated="Please use {@link HdfsConstants}. This class
 is left only for other ecosystem projects which depended on
 it for SafemodeAction and DatanodeReport types.">
    <constructor name="FSConstants"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <doc>
    <![CDATA[@deprecated Please use {@link HdfsConstants}. This class
 is left only for other ecosystem projects which depended on
 it for SafemodeAction and DatanodeReport types.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.protocol.FSConstants -->
  <!-- start class org.apache.hadoop.hdfs.protocol.FSLimitException.MaxDirectoryItemsExceededException -->
  <class name="FSLimitException.MaxDirectoryItemsExceededException" extends="org.apache.hadoop.hdfs.protocol.FSLimitException"
    abstract="false"
    static="true" final="true" visibility="public"
    deprecated="not deprecated">
    <constructor name="FSLimitException.MaxDirectoryItemsExceededException"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
    </constructor>
    <constructor name="FSLimitException.MaxDirectoryItemsExceededException" type="java.lang.String"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
    </constructor>
    <constructor name="FSLimitException.MaxDirectoryItemsExceededException" type="long, long"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getMessage" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <field name="serialVersionUID" type="long"
      transient="false" volatile="false"
      static="true" final="true" visibility="protected"
      deprecated="not deprecated">
    </field>
    <doc>
    <![CDATA[Directory has too many items]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.protocol.FSLimitException.MaxDirectoryItemsExceededException -->
  <!-- start class org.apache.hadoop.hdfs.protocol.FSLimitException.PathComponentTooLongException -->
  <class name="FSLimitException.PathComponentTooLongException" extends="org.apache.hadoop.hdfs.protocol.FSLimitException"
    abstract="false"
    static="true" final="true" visibility="public"
    deprecated="not deprecated">
    <constructor name="FSLimitException.PathComponentTooLongException"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
    </constructor>
    <constructor name="FSLimitException.PathComponentTooLongException" type="java.lang.String"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
    </constructor>
    <constructor name="FSLimitException.PathComponentTooLongException" type="long, long, java.lang.String, java.lang.String"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getMessage" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <field name="serialVersionUID" type="long"
      transient="false" volatile="false"
      static="true" final="true" visibility="protected"
      deprecated="not deprecated">
    </field>
    <doc>
    <![CDATA[Path component length is too long]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.protocol.FSLimitException.PathComponentTooLongException -->
  <!-- start class org.apache.hadoop.hdfs.protocol.HdfsConstants.DatanodeReportType -->
  <class name="HdfsConstants.DatanodeReportType" extends="java.lang.Enum"
    abstract="false"
    static="true" final="true" visibility="public"
    deprecated="not deprecated">
    <method name="values" return="org.apache.hadoop.hdfs.protocol.HdfsConstants.DatanodeReportType[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="valueOf" return="org.apache.hadoop.hdfs.protocol.HdfsConstants.DatanodeReportType"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="name" type="java.lang.String"/>
    </method>
  </class>
  <!-- end class org.apache.hadoop.hdfs.protocol.HdfsConstants.DatanodeReportType -->
  <!-- start class org.apache.hadoop.hdfs.protocol.HdfsConstants.RollingUpgradeAction -->
  <class name="HdfsConstants.RollingUpgradeAction" extends="java.lang.Enum"
    abstract="false"
    static="true" final="true" visibility="public"
    deprecated="not deprecated">
    <method name="values" return="org.apache.hadoop.hdfs.protocol.HdfsConstants.RollingUpgradeAction[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="valueOf" return="org.apache.hadoop.hdfs.protocol.HdfsConstants.RollingUpgradeAction"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="name" type="java.lang.String"/>
    </method>
    <method name="fromString" return="org.apache.hadoop.hdfs.protocol.HdfsConstants.RollingUpgradeAction"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="s" type="java.lang.String"/>
      <doc>
      <![CDATA[Convert the given String to a RollingUpgradeAction.]]>
      </doc>
    </method>
  </class>
  <!-- end class org.apache.hadoop.hdfs.protocol.HdfsConstants.RollingUpgradeAction -->
  <!-- start class org.apache.hadoop.hdfs.protocol.HdfsConstants.SafeModeAction -->
  <class name="HdfsConstants.SafeModeAction" extends="java.lang.Enum"
    abstract="false"
    static="true" final="true" visibility="public"
    deprecated="not deprecated">
    <method name="values" return="org.apache.hadoop.hdfs.protocol.HdfsConstants.SafeModeAction[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="valueOf" return="org.apache.hadoop.hdfs.protocol.HdfsConstants.SafeModeAction"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="name" type="java.lang.String"/>
    </method>
  </class>
  <!-- end class org.apache.hadoop.hdfs.protocol.HdfsConstants.SafeModeAction -->
  <!-- start class org.apache.hadoop.hdfs.protocol.LayoutVersion.Feature -->
  <class name="LayoutVersion.Feature" extends="java.lang.Enum"
    abstract="false"
    static="true" final="true" visibility="public"
    deprecated="not deprecated">
    <implements name="org.apache.hadoop.hdfs.protocol.LayoutVersion.LayoutFeature"/>
    <method name="values" return="org.apache.hadoop.hdfs.protocol.LayoutVersion.Feature[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="valueOf" return="org.apache.hadoop.hdfs.protocol.LayoutVersion.Feature"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="name" type="java.lang.String"/>
    </method>
    <method name="getInfo" return="org.apache.hadoop.hdfs.protocol.LayoutVersion.FeatureInfo"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[Enums for features that change the layout version before rolling
 upgrade is supported.
 <br><br>
 To add a new layout version:
 <ul>
 <li>Define a new enum constant with a short enum name, the new layout version 
 and description of the added feature.</li>
 <li>When adding a layout version with an ancestor that is not same as
 its immediate predecessor, use the constructor where a specific ancestor
 can be passed.
 </li>
 </ul>]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.protocol.LayoutVersion.Feature -->
  <!-- start class org.apache.hadoop.hdfs.protocol.LayoutVersion.FeatureInfo -->
  <class name="LayoutVersion.FeatureInfo" extends="java.lang.Object"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="LayoutVersion.FeatureInfo" type="int, int, java.lang.String, boolean, org.apache.hadoop.hdfs.protocol.LayoutVersion.LayoutFeature[]"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getLayoutVersion" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Accessor method for feature layout version 
 @return int lv value]]>
      </doc>
    </method>
    <method name="getAncestorLayoutVersion" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Accessor method for feature ancestor layout version 
 @return int ancestor LV value]]>
      </doc>
    </method>
    <method name="getDescription" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Accessor method for feature description 
 @return String feature description]]>
      </doc>
    </method>
    <method name="isReservedForOldRelease" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getSpecialFeatures" return="org.apache.hadoop.hdfs.protocol.LayoutVersion.LayoutFeature[]"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[Feature information.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.protocol.LayoutVersion.FeatureInfo -->
  <!-- start interface org.apache.hadoop.hdfs.protocol.LayoutVersion.LayoutFeature -->
  <interface name="LayoutVersion.LayoutFeature"    abstract="true"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="getInfo" return="org.apache.hadoop.hdfs.protocol.LayoutVersion.FeatureInfo"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[The interface to be implemented by NameNode and DataNode layout features]]>
    </doc>
  </interface>
  <!-- end interface org.apache.hadoop.hdfs.protocol.LayoutVersion.LayoutFeature -->
  <!-- start class org.apache.hadoop.hdfs.protocol.RollingUpgradeInfo.Bean -->
  <class name="RollingUpgradeInfo.Bean" extends="java.lang.Object"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="RollingUpgradeInfo.Bean" type="org.apache.hadoop.hdfs.protocol.RollingUpgradeInfo"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getBlockPoolId" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getStartTime" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getFinalizeTime" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="isCreatedRollbackImages" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
  </class>
  <!-- end class org.apache.hadoop.hdfs.protocol.RollingUpgradeInfo.Bean -->
  <!-- start class org.apache.hadoop.hdfs.protocol.SnapshotAccessControlException -->
  <class name="SnapshotAccessControlException" extends="org.apache.hadoop.security.AccessControlException"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="SnapshotAccessControlException" type="java.lang.String"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <constructor name="SnapshotAccessControlException" type="java.lang.Throwable"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <doc>
    <![CDATA[Snapshot access related exception.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.protocol.SnapshotAccessControlException -->
  <!-- start class org.apache.hadoop.hdfs.protocol.SnapshotDiffReport -->
  <class name="SnapshotDiffReport" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="SnapshotDiffReport" type="java.lang.String, java.lang.String, java.lang.String, java.util.List"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getSnapshotRoot" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return {@link #snapshotRoot}]]>
      </doc>
    </method>
    <method name="getFromSnapshot" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return {@link #fromSnapshot}]]>
      </doc>
    </method>
    <method name="getLaterSnapshotName" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return {@link #toSnapshot}]]>
      </doc>
    </method>
    <method name="getDiffList" return="java.util.List"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return {@link #diffList}]]>
      </doc>
    </method>
    <method name="toString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[This class represents to end users the difference between two snapshots of 
 the same directory, or the difference between a snapshot of the directory and
 its current state. Instead of capturing all the details of the diff, this
 class only lists where the changes happened and their types.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.protocol.SnapshotDiffReport -->
  <!-- start class org.apache.hadoop.hdfs.protocol.SnapshotDiffReport.DiffReportEntry -->
  <class name="SnapshotDiffReport.DiffReportEntry" extends="java.lang.Object"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="SnapshotDiffReport.DiffReportEntry" type="org.apache.hadoop.hdfs.protocol.SnapshotDiffReport.DiffType, byte[]"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <constructor name="SnapshotDiffReport.DiffReportEntry" type="org.apache.hadoop.hdfs.protocol.SnapshotDiffReport.DiffType, byte[][]"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <constructor name="SnapshotDiffReport.DiffReportEntry" type="org.apache.hadoop.hdfs.protocol.SnapshotDiffReport.DiffType, byte[], byte[]"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <constructor name="SnapshotDiffReport.DiffReportEntry" type="org.apache.hadoop.hdfs.protocol.SnapshotDiffReport.DiffType, byte[][], byte[][]"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="toString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getType" return="org.apache.hadoop.hdfs.protocol.SnapshotDiffReport.DiffType"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getSourcePath" return="byte[]"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getTargetPath" return="byte[]"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="equals" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="other" type="java.lang.Object"/>
    </method>
    <method name="hashCode" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[Representing the full path and diff type of a file/directory where changes
 have happened.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.protocol.SnapshotDiffReport.DiffReportEntry -->
  <!-- start class org.apache.hadoop.hdfs.protocol.SnapshotDiffReport.DiffType -->
  <class name="SnapshotDiffReport.DiffType" extends="java.lang.Enum"
    abstract="false"
    static="true" final="true" visibility="public"
    deprecated="not deprecated">
    <method name="values" return="org.apache.hadoop.hdfs.protocol.SnapshotDiffReport.DiffType[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="valueOf" return="org.apache.hadoop.hdfs.protocol.SnapshotDiffReport.DiffType"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="name" type="java.lang.String"/>
    </method>
    <method name="getLabel" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getTypeFromLabel" return="org.apache.hadoop.hdfs.protocol.SnapshotDiffReport.DiffType"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="label" type="java.lang.String"/>
    </method>
    <doc>
    <![CDATA[Types of the difference, which include CREATE, MODIFY, DELETE, and RENAME.
 Each type has a label for representation: +/M/-/R represent CREATE, MODIFY,
 DELETE, and RENAME respectively.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.protocol.SnapshotDiffReport.DiffType -->
  <!-- start class org.apache.hadoop.hdfs.protocol.SnapshotException -->
  <class name="SnapshotException" extends="java.io.IOException"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="SnapshotException" type="java.lang.String"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <constructor name="SnapshotException" type="java.lang.Throwable"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <doc>
    <![CDATA[Snapshot related exception.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.protocol.SnapshotException -->
  <!-- start class org.apache.hadoop.hdfs.protocol.SnapshotInfo.Bean -->
  <class name="SnapshotInfo.Bean" extends="java.lang.Object"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="SnapshotInfo.Bean" type="java.lang.String, java.lang.String, long"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getSnapshotID" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getSnapshotDirectory" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getModificationTime" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
  </class>
  <!-- end class org.apache.hadoop.hdfs.protocol.SnapshotInfo.Bean -->
  <!-- start class org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus -->
  <class name="SnapshottableDirectoryStatus" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="SnapshottableDirectoryStatus" type="long, long, org.apache.hadoop.fs.permission.FsPermission, java.lang.String, java.lang.String, byte[], long, int, int, int, byte[]"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getSnapshotNumber" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return Number of snapshots that have been taken for the directory]]>
      </doc>
    </method>
    <method name="getSnapshotQuota" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return Number of snapshots allowed for the directory]]>
      </doc>
    </method>
    <method name="getParentFullPath" return="byte[]"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return Full path of the parent]]>
      </doc>
    </method>
    <method name="getDirStatus" return="org.apache.hadoop.hdfs.protocol.HdfsFileStatus"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return The basic information of the directory]]>
      </doc>
    </method>
    <method name="getFullPath" return="org.apache.hadoop.fs.Path"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return Full path of the file]]>
      </doc>
    </method>
    <method name="print"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="stats" type="org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus[]"/>
      <param name="out" type="java.io.PrintStream"/>
      <doc>
      <![CDATA[Print a list of {@link SnapshottableDirectoryStatus} out to a given stream.
 @param stats The list of {@link SnapshottableDirectoryStatus}
 @param out The given stream for printing.]]>
      </doc>
    </method>
    <field name="COMPARATOR" type="java.util.Comparator"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Compare the statuses by full paths.]]>
      </doc>
    </field>
    <doc>
    <![CDATA[Metadata about a snapshottable directory]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus -->
  <!-- start class org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus.Bean -->
  <class name="SnapshottableDirectoryStatus.Bean" extends="java.lang.Object"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="SnapshottableDirectoryStatus.Bean" type="java.lang.String, int, int, long, short, java.lang.String, java.lang.String"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getPath" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getSnapshotNumber" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getSnapshotQuota" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getModificationTime" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getPermission" return="short"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getOwner" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getGroup" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
  </class>
  <!-- end class org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus.Bean -->
</package>
<package name="org.apache.hadoop.hdfs.protocol.datatransfer">
  <!-- start class org.apache.hadoop.hdfs.protocol.datatransfer.ReplaceDatanodeOnFailure.Policy -->
  <class name="ReplaceDatanodeOnFailure.Policy" extends="java.lang.Enum"
    abstract="false"
    static="true" final="true" visibility="public"
    deprecated="not deprecated">
    <method name="values" return="org.apache.hadoop.hdfs.protocol.datatransfer.ReplaceDatanodeOnFailure.Policy[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="valueOf" return="org.apache.hadoop.hdfs.protocol.datatransfer.ReplaceDatanodeOnFailure.Policy"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="name" type="java.lang.String"/>
    </method>
    <doc>
    <![CDATA[The replacement policies]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.protocol.datatransfer.ReplaceDatanodeOnFailure.Policy -->
  <!-- start class org.apache.hadoop.hdfs.protocol.datatransfer.TrustedChannelResolver -->
  <class name="TrustedChannelResolver" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <implements name="org.apache.hadoop.conf.Configurable"/>
    <constructor name="TrustedChannelResolver"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getInstance" return="org.apache.hadoop.hdfs.protocol.datatransfer.TrustedChannelResolver"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
      <doc>
      <![CDATA[Returns an instance of TrustedChannelResolver.
 Looks up the configuration to see if there is custom class specified.
 @param conf
 @return TrustedChannelResolver]]>
      </doc>
    </method>
    <method name="setConf"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
    </method>
    <method name="getConf" return="org.apache.hadoop.conf.Configuration"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="isTrusted" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Return boolean value indicating whether a channel is trusted or not
 from a client's perspective.
 @return true if the channel is trusted and false otherwise.]]>
      </doc>
    </method>
    <method name="isTrusted" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="peerAddress" type="java.net.InetAddress"/>
      <doc>
      <![CDATA[Identify boolean value indicating whether a channel is trusted or not.
 @param peerAddress address of the peer
 @return true if the channel is trusted and false otherwise.]]>
      </doc>
    </method>
    <doc>
    <![CDATA[Class used to indicate whether a channel is trusted or not.
 The default implementation is to return false indicating that
 the channel is not trusted.
 This class can be overridden to provide custom logic to determine
 whether a channel is trusted or not. 
 The custom class can be specified via configuration.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.protocol.datatransfer.TrustedChannelResolver -->
  <!-- start class org.apache.hadoop.hdfs.protocol.datatransfer.WhitelistBasedTrustedChannelResolver -->
  <class name="WhitelistBasedTrustedChannelResolver" extends="org.apache.hadoop.hdfs.protocol.datatransfer.TrustedChannelResolver"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="WhitelistBasedTrustedChannelResolver"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="setConf"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
    </method>
    <method name="isTrusted" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="isTrusted" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="clientAddress" type="java.net.InetAddress"/>
    </method>
    <field name="DFS_DATATRANSFER_SERVER_FIXEDWHITELIST_FILE" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Path to the file to containing subnets and ip addresses to form fixed whitelist.]]>
      </doc>
    </field>
    <field name="DFS_DATATRANSFER_SERVER_VARIABLEWHITELIST_ENABLE" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Enables/Disables variable whitelist]]>
      </doc>
    </field>
    <field name="DFS_DATATRANSFER_SERVER_VARIABLEWHITELIST_FILE" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Path to the file to containing subnets and ip addresses to form variable whitelist.]]>
      </doc>
    </field>
    <field name="DFS_DATATRANSFER_SERVER_VARIABLEWHITELIST_CACHE_SECS" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[time in seconds by which the variable whitelist file is checked for updates]]>
      </doc>
    </field>
    <field name="DFS_DATATRANSFER_CLIENT_FIXEDWHITELIST_FILE" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Path to the file to containing subnets and ip addresses to form fixed whitelist.]]>
      </doc>
    </field>
    <field name="DFS_DATATRANSFER_CLIENT_VARIABLEWHITELIST_ENABLE" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Enables/Disables variable whitelist]]>
      </doc>
    </field>
    <field name="DFS_DATATRANSFER_CLIENT_VARIABLEWHITELIST_FILE" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Path to the file to containing subnets and ip addresses to form variable whitelist.]]>
      </doc>
    </field>
    <field name="DFS_DATATRANSFER_CLIENT_VARIABLEWHITELIST_CACHE_SECS" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[time in seconds by which the variable whitelist file is checked for updates]]>
      </doc>
    </field>
  </class>
  <!-- end class org.apache.hadoop.hdfs.protocol.datatransfer.WhitelistBasedTrustedChannelResolver -->
</package>
<package name="org.apache.hadoop.hdfs.protocol.datatransfer.sasl">
</package>
<package name="org.apache.hadoop.hdfs.protocolPB">
  <!-- start class org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolServerSideTranslatorPB -->
  <class name="DatanodeProtocolServerSideTranslatorPB" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <implements name="org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolPB"/>
    <constructor name="DatanodeProtocolServerSideTranslatorPB" type="org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="registerDatanode" return="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.RegisterDatanodeResponseProto"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="controller" type="com.google.protobuf.RpcController"/>
      <param name="request" type="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.RegisterDatanodeRequestProto"/>
      <exception name="ServiceException" type="com.google.protobuf.ServiceException"/>
    </method>
    <method name="sendHeartbeat" return="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.HeartbeatResponseProto"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="controller" type="com.google.protobuf.RpcController"/>
      <param name="request" type="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.HeartbeatRequestProto"/>
      <exception name="ServiceException" type="com.google.protobuf.ServiceException"/>
    </method>
    <method name="blockReport" return="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.BlockReportResponseProto"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="controller" type="com.google.protobuf.RpcController"/>
      <param name="request" type="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.BlockReportRequestProto"/>
      <exception name="ServiceException" type="com.google.protobuf.ServiceException"/>
    </method>
    <method name="cacheReport" return="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.CacheReportResponseProto"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="controller" type="com.google.protobuf.RpcController"/>
      <param name="request" type="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.CacheReportRequestProto"/>
      <exception name="ServiceException" type="com.google.protobuf.ServiceException"/>
    </method>
    <method name="blockReceivedAndDeleted" return="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.BlockReceivedAndDeletedResponseProto"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="controller" type="com.google.protobuf.RpcController"/>
      <param name="request" type="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.BlockReceivedAndDeletedRequestProto"/>
      <exception name="ServiceException" type="com.google.protobuf.ServiceException"/>
    </method>
    <method name="errorReport" return="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.ErrorReportResponseProto"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="controller" type="com.google.protobuf.RpcController"/>
      <param name="request" type="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.ErrorReportRequestProto"/>
      <exception name="ServiceException" type="com.google.protobuf.ServiceException"/>
    </method>
    <method name="versionRequest" return="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.VersionResponseProto"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="controller" type="com.google.protobuf.RpcController"/>
      <param name="request" type="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.VersionRequestProto"/>
      <exception name="ServiceException" type="com.google.protobuf.ServiceException"/>
    </method>
    <method name="reportBadBlocks" return="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.ReportBadBlocksResponseProto"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="controller" type="com.google.protobuf.RpcController"/>
      <param name="request" type="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.ReportBadBlocksRequestProto"/>
      <exception name="ServiceException" type="com.google.protobuf.ServiceException"/>
    </method>
    <method name="commitBlockSynchronization" return="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.CommitBlockSynchronizationResponseProto"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="controller" type="com.google.protobuf.RpcController"/>
      <param name="request" type="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.CommitBlockSynchronizationRequestProto"/>
      <exception name="ServiceException" type="com.google.protobuf.ServiceException"/>
    </method>
  </class>
  <!-- end class org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolServerSideTranslatorPB -->
  <!-- start class org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB -->
  <class name="NamenodeProtocolServerSideTranslatorPB" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <implements name="org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolPB"/>
    <constructor name="NamenodeProtocolServerSideTranslatorPB" type="org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getBlocks" return="org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos.GetBlocksResponseProto"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="unused" type="com.google.protobuf.RpcController"/>
      <param name="request" type="org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos.GetBlocksRequestProto"/>
      <exception name="ServiceException" type="com.google.protobuf.ServiceException"/>
    </method>
    <method name="getBlockKeys" return="org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos.GetBlockKeysResponseProto"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="unused" type="com.google.protobuf.RpcController"/>
      <param name="request" type="org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos.GetBlockKeysRequestProto"/>
      <exception name="ServiceException" type="com.google.protobuf.ServiceException"/>
    </method>
    <method name="getTransactionId" return="org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos.GetTransactionIdResponseProto"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="unused" type="com.google.protobuf.RpcController"/>
      <param name="request" type="org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos.GetTransactionIdRequestProto"/>
      <exception name="ServiceException" type="com.google.protobuf.ServiceException"/>
    </method>
    <method name="getMostRecentCheckpointTxId" return="org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos.GetMostRecentCheckpointTxIdResponseProto"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="unused" type="com.google.protobuf.RpcController"/>
      <param name="request" type="org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos.GetMostRecentCheckpointTxIdRequestProto"/>
      <exception name="ServiceException" type="com.google.protobuf.ServiceException"/>
    </method>
    <method name="rollEditLog" return="org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos.RollEditLogResponseProto"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="unused" type="com.google.protobuf.RpcController"/>
      <param name="request" type="org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos.RollEditLogRequestProto"/>
      <exception name="ServiceException" type="com.google.protobuf.ServiceException"/>
    </method>
    <method name="errorReport" return="org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos.ErrorReportResponseProto"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="unused" type="com.google.protobuf.RpcController"/>
      <param name="request" type="org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos.ErrorReportRequestProto"/>
      <exception name="ServiceException" type="com.google.protobuf.ServiceException"/>
    </method>
    <method name="registerSubordinateNamenode" return="org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos.RegisterResponseProto"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="unused" type="com.google.protobuf.RpcController"/>
      <param name="request" type="org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos.RegisterRequestProto"/>
      <exception name="ServiceException" type="com.google.protobuf.ServiceException"/>
    </method>
    <method name="startCheckpoint" return="org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos.StartCheckpointResponseProto"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="unused" type="com.google.protobuf.RpcController"/>
      <param name="request" type="org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos.StartCheckpointRequestProto"/>
      <exception name="ServiceException" type="com.google.protobuf.ServiceException"/>
    </method>
    <method name="endCheckpoint" return="org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos.EndCheckpointResponseProto"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="unused" type="com.google.protobuf.RpcController"/>
      <param name="request" type="org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos.EndCheckpointRequestProto"/>
      <exception name="ServiceException" type="com.google.protobuf.ServiceException"/>
    </method>
    <method name="getEditLogManifest" return="org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos.GetEditLogManifestResponseProto"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="unused" type="com.google.protobuf.RpcController"/>
      <param name="request" type="org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos.GetEditLogManifestRequestProto"/>
      <exception name="ServiceException" type="com.google.protobuf.ServiceException"/>
    </method>
    <method name="versionRequest" return="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.VersionResponseProto"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="controller" type="com.google.protobuf.RpcController"/>
      <param name="request" type="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.VersionRequestProto"/>
      <exception name="ServiceException" type="com.google.protobuf.ServiceException"/>
    </method>
    <doc>
    <![CDATA[Implementation for protobuf service that forwards requests
 received on {@link NamenodeProtocolPB} to the
 {@link NamenodeProtocol} server implementation.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB -->
  <!-- start class org.apache.hadoop.hdfs.protocolPB.PBHelper -->
  <class name="PBHelper" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="getByteString" return="com.google.protobuf.ByteString"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="bytes" type="byte[]"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.server.common.HdfsServerConstants.NamenodeRole"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="role" type="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.NamenodeRegistrationProto.NamenodeRoleProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.NamenodeRegistrationProto.NamenodeRoleProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="role" type="org.apache.hadoop.hdfs.server.common.HdfsServerConstants.NamenodeRole"/>
    </method>
    <method name="convertStoragePolicies" return="org.apache.hadoop.hdfs.protocol.BlockStoragePolicy[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="policyProtos" type="java.util.List"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.BlockStoragePolicy"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="proto" type="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.BlockStoragePolicyProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.BlockStoragePolicyProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="policy" type="org.apache.hadoop.hdfs.protocol.BlockStoragePolicy"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.StorageTypesProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="types" type="org.apache.hadoop.hdfs.StorageType[]"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.StorageInfoProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="info" type="org.apache.hadoop.hdfs.server.common.StorageInfo"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.server.common.StorageInfo"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="info" type="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.StorageInfoProto"/>
      <param name="type" type="org.apache.hadoop.hdfs.server.common.HdfsServerConstants.NodeType"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.NamenodeRegistrationProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="reg" type="org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="reg" type="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.NamenodeRegistrationProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.DatanodeID"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="dn" type="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.DatanodeIDProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.DatanodeIDProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="dn" type="org.apache.hadoop.hdfs.protocol.DatanodeID"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.DatanodeIDProto[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="did" type="org.apache.hadoop.hdfs.protocol.DatanodeID[]"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.DatanodeID[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="did" type="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.DatanodeIDProto[]"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.BlockProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="b" type="org.apache.hadoop.hdfs.protocol.Block"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.Block"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="b" type="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.BlockProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.BlockWithLocationsProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="blk" type="org.apache.hadoop.hdfs.server.protocol.BlocksWithLocations.BlockWithLocations"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.server.protocol.BlocksWithLocations.BlockWithLocations"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="b" type="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.BlockWithLocationsProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.BlocksWithLocationsProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="blks" type="org.apache.hadoop.hdfs.server.protocol.BlocksWithLocations"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.server.protocol.BlocksWithLocations"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="blocks" type="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.BlocksWithLocationsProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.BlockKeyProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="key" type="org.apache.hadoop.hdfs.security.token.block.BlockKey"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.security.token.block.BlockKey"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="k" type="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.BlockKeyProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.ExportedBlockKeysProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="keys" type="org.apache.hadoop.hdfs.security.token.block.ExportedBlockKeys"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.security.token.block.ExportedBlockKeys"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="keys" type="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.ExportedBlockKeysProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.CheckpointSignatureProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="s" type="org.apache.hadoop.hdfs.server.namenode.CheckpointSignature"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.server.namenode.CheckpointSignature"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="s" type="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.CheckpointSignatureProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.RemoteEditLogProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="log" type="org.apache.hadoop.hdfs.server.protocol.RemoteEditLog"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.server.protocol.RemoteEditLog"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="l" type="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.RemoteEditLogProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.RemoteEditLogManifestProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="manifest" type="org.apache.hadoop.hdfs.server.protocol.RemoteEditLogManifest"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.server.protocol.RemoteEditLogManifest"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="manifest" type="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.RemoteEditLogManifestProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.CheckpointCommandProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="cmd" type="org.apache.hadoop.hdfs.server.protocol.CheckpointCommand"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.NamenodeCommandProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="cmd" type="org.apache.hadoop.hdfs.server.protocol.NamenodeCommand"/>
    </method>
    <method name="convertBlockKeys" return="org.apache.hadoop.hdfs.security.token.block.BlockKey[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="list" type="java.util.List"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.server.protocol.NamespaceInfo"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="info" type="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.NamespaceInfoProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.server.protocol.NamenodeCommand"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="cmd" type="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.NamenodeCommandProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.ExtendedBlock"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="eb" type="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.ExtendedBlockProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.ExtendedBlockProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="b" type="org.apache.hadoop.hdfs.protocol.ExtendedBlock"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.RecoveringBlockProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="b" type="org.apache.hadoop.hdfs.server.protocol.BlockRecoveryCommand.RecoveringBlock"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.server.protocol.BlockRecoveryCommand.RecoveringBlock"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="b" type="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.RecoveringBlockProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.DatanodeInfoProto.AdminState"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="inAs" type="org.apache.hadoop.hdfs.protocol.DatanodeInfo.AdminStates"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.DatanodeInfo"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="di" type="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.DatanodeInfoProto"/>
    </method>
    <method name="convertDatanodeInfo" return="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.DatanodeInfoProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="di" type="org.apache.hadoop.hdfs.protocol.DatanodeInfo"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.DatanodeInfo[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="di" type="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.DatanodeInfoProto[]"/>
    </method>
    <method name="convert" return="java.util.List"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="dnInfos" type="org.apache.hadoop.hdfs.protocol.DatanodeInfo[]"/>
    </method>
    <method name="convert" return="java.util.List"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="dnInfos" type="org.apache.hadoop.hdfs.protocol.DatanodeInfo[]"/>
      <param name="startIdx" type="int"/>
      <doc>
      <![CDATA[Copy from {@code dnInfos} to a target of list of same size starting at
 {@code startIdx}.]]>
      </doc>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.DatanodeInfo[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="list" type="java.util.List"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.DatanodeInfoProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="info" type="org.apache.hadoop.hdfs.protocol.DatanodeInfo"/>
    </method>
    <method name="convertDatanodeStorageReport" return="org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.DatanodeStorageReportProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="report" type="org.apache.hadoop.hdfs.server.protocol.DatanodeStorageReport"/>
    </method>
    <method name="convertDatanodeStorageReports" return="java.util.List"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="reports" type="org.apache.hadoop.hdfs.server.protocol.DatanodeStorageReport[]"/>
    </method>
    <method name="convertDatanodeStorageReport" return="org.apache.hadoop.hdfs.server.protocol.DatanodeStorageReport"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="proto" type="org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.DatanodeStorageReportProto"/>
    </method>
    <method name="convertDatanodeStorageReports" return="org.apache.hadoop.hdfs.server.protocol.DatanodeStorageReport[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="protos" type="java.util.List"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.DatanodeInfo.AdminStates"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="adminState" type="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.DatanodeInfoProto.AdminState"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.LocatedBlockProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="b" type="org.apache.hadoop.hdfs.protocol.LocatedBlock"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.LocatedBlock"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="proto" type="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.LocatedBlockProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.security.proto.SecurityProtos.TokenProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="tok" type="org.apache.hadoop.security.token.Token"/>
    </method>
    <method name="convert" return="org.apache.hadoop.security.token.Token"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="blockToken" type="org.apache.hadoop.security.proto.SecurityProtos.TokenProto"/>
    </method>
    <method name="convertDelegationToken" return="org.apache.hadoop.security.token.Token"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="blockToken" type="org.apache.hadoop.security.proto.SecurityProtos.TokenProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.server.common.HdfsServerConstants.ReplicaState"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="state" type="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.ReplicaStateProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.ReplicaStateProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="state" type="org.apache.hadoop.hdfs.server.common.HdfsServerConstants.ReplicaState"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.DatanodeRegistrationProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="registration" type="org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="proto" type="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.DatanodeRegistrationProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.server.protocol.DatanodeCommand"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="proto" type="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.DatanodeCommandProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.BalancerBandwidthCommandProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="bbCmd" type="org.apache.hadoop.hdfs.server.protocol.BalancerBandwidthCommand"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.KeyUpdateCommandProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="cmd" type="org.apache.hadoop.hdfs.server.protocol.KeyUpdateCommand"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.BlockRecoveryCommandProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="cmd" type="org.apache.hadoop.hdfs.server.protocol.BlockRecoveryCommand"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.FinalizeCommandProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="cmd" type="org.apache.hadoop.hdfs.server.protocol.FinalizeCommand"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.BlockCommandProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="cmd" type="org.apache.hadoop.hdfs.server.protocol.BlockCommand"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.BlockIdCommandProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="cmd" type="org.apache.hadoop.hdfs.server.protocol.BlockIdCommand"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.DatanodeCommandProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="datanodeCommand" type="org.apache.hadoop.hdfs.server.protocol.DatanodeCommand"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.server.protocol.KeyUpdateCommand"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="keyUpdateCmd" type="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.KeyUpdateCommandProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.server.protocol.FinalizeCommand"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="finalizeCmd" type="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.FinalizeCommandProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.server.protocol.BlockRecoveryCommand"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="recoveryCmd" type="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.BlockRecoveryCommandProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.server.protocol.BlockCommand"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="blkCmd" type="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.BlockCommandProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.server.protocol.BlockIdCommand"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="blkIdCmd" type="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.BlockIdCommandProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.DatanodeInfo[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="datanodeInfosProto" type="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.DatanodeInfosProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.server.protocol.BalancerBandwidthCommand"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="balancerCmd" type="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.BalancerBandwidthCommandProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.ReceivedDeletedBlockInfoProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="receivedDeletedBlockInfo" type="org.apache.hadoop.hdfs.server.protocol.ReceivedDeletedBlockInfo"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.server.protocol.ReceivedDeletedBlockInfo"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="proto" type="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.ReceivedDeletedBlockInfoProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.NamespaceInfoProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="info" type="org.apache.hadoop.hdfs.server.protocol.NamespaceInfo"/>
    </method>
    <method name="convertLocatedBlock" return="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.LocatedBlockProto[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="lb" type="org.apache.hadoop.hdfs.protocol.LocatedBlock[]"/>
    </method>
    <method name="convertLocatedBlock" return="org.apache.hadoop.hdfs.protocol.LocatedBlock[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="lb" type="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.LocatedBlockProto[]"/>
    </method>
    <method name="convertLocatedBlock" return="java.util.List"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="lb" type="java.util.List"/>
    </method>
    <method name="convertLocatedBlock2" return="java.util.List"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="lb" type="java.util.List"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.LocatedBlocks"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="lb" type="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.LocatedBlocksProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.LocatedBlocksProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="lb" type="org.apache.hadoop.hdfs.protocol.LocatedBlocks"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.security.token.block.DataEncryptionKey"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="bet" type="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.DataEncryptionKeyProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.DataEncryptionKeyProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="bet" type="org.apache.hadoop.hdfs.security.token.block.DataEncryptionKey"/>
    </method>
    <method name="convert" return="org.apache.hadoop.fs.FsServerDefaults"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="fs" type="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.FsServerDefaultsProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.FsServerDefaultsProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="fs" type="org.apache.hadoop.fs.FsServerDefaults"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.FsPermissionProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="p" type="org.apache.hadoop.fs.permission.FsPermission"/>
    </method>
    <method name="convert" return="org.apache.hadoop.fs.permission.FsPermission"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="p" type="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.FsPermissionProto"/>
    </method>
    <method name="convertCreateFlag" return="int"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="flag" type="org.apache.hadoop.io.EnumSetWritable"/>
    </method>
    <method name="convertCreateFlag" return="org.apache.hadoop.io.EnumSetWritable"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="flag" type="int"/>
    </method>
    <method name="convertCacheFlags" return="int"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="flags" type="java.util.EnumSet"/>
    </method>
    <method name="convertCacheFlags" return="java.util.EnumSet"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="flags" type="int"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.HdfsFileStatus"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="fs" type="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.HdfsFileStatusProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="sdirStatusProto" type="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.SnapshottableDirectoryStatusProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.HdfsFileStatusProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="fs" type="org.apache.hadoop.hdfs.protocol.HdfsFileStatus"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.SnapshottableDirectoryStatusProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="status" type="org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.HdfsFileStatusProto[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="fs" type="org.apache.hadoop.hdfs.protocol.HdfsFileStatus[]"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.HdfsFileStatus[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="fs" type="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.HdfsFileStatusProto[]"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.DirectoryListing"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="dl" type="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.DirectoryListingProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.DirectoryListingProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="d" type="org.apache.hadoop.hdfs.protocol.DirectoryListing"/>
    </method>
    <method name="convert" return="long[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="res" type="org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetFsStatsResponseProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetFsStatsResponseProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="fsStats" type="long[]"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.DatanodeReportTypeProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="t" type="org.apache.hadoop.hdfs.protocol.HdfsConstants.DatanodeReportType"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.HdfsConstants.DatanodeReportType"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="t" type="org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.DatanodeReportTypeProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SafeModeActionProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="a" type="org.apache.hadoop.hdfs.protocol.HdfsConstants.SafeModeAction"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.HdfsConstants.SafeModeAction"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="a" type="org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SafeModeActionProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RollingUpgradeActionProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="a" type="org.apache.hadoop.hdfs.protocol.HdfsConstants.RollingUpgradeAction"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.HdfsConstants.RollingUpgradeAction"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="a" type="org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RollingUpgradeActionProto"/>
    </method>
    <method name="convertRollingUpgradeStatus" return="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.RollingUpgradeStatusProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="status" type="org.apache.hadoop.hdfs.protocol.RollingUpgradeStatus"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.RollingUpgradeStatus"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="proto" type="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.RollingUpgradeStatusProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RollingUpgradeInfoProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="info" type="org.apache.hadoop.hdfs.protocol.RollingUpgradeInfo"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.RollingUpgradeInfo"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="proto" type="org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RollingUpgradeInfoProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.CorruptFileBlocks"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="c" type="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.CorruptFileBlocksProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.CorruptFileBlocksProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="c" type="org.apache.hadoop.hdfs.protocol.CorruptFileBlocks"/>
    </method>
    <method name="convert" return="org.apache.hadoop.fs.ContentSummary"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="cs" type="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.ContentSummaryProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.ContentSummaryProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="cs" type="org.apache.hadoop.fs.ContentSummary"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.server.protocol.NNHAStatusHeartbeat"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="s" type="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.NNHAStatusHeartbeatProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.NNHAStatusHeartbeatProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="hb" type="org.apache.hadoop.hdfs.server.protocol.NNHAStatusHeartbeat"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.DatanodeStorageProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="s" type="org.apache.hadoop.hdfs.server.protocol.DatanodeStorage"/>
    </method>
    <method name="convertStorageTypes" return="java.util.List"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="types" type="org.apache.hadoop.hdfs.StorageType[]"/>
    </method>
    <method name="convertStorageTypes" return="java.util.List"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="types" type="org.apache.hadoop.hdfs.StorageType[]"/>
      <param name="startIdx" type="int"/>
    </method>
    <method name="convertStorageType" return="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.StorageTypeProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="type" type="org.apache.hadoop.hdfs.StorageType"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.server.protocol.DatanodeStorage"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="s" type="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.DatanodeStorageProto"/>
    </method>
    <method name="convertStorageType" return="org.apache.hadoop.hdfs.StorageType"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="type" type="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.StorageTypeProto"/>
    </method>
    <method name="convertStorageTypes" return="org.apache.hadoop.hdfs.StorageType[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="storageTypesList" type="java.util.List"/>
      <param name="expectedSize" type="int"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.StorageReportProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="r" type="org.apache.hadoop.hdfs.server.protocol.StorageReport"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.server.protocol.StorageReport"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="p" type="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.StorageReportProto"/>
    </method>
    <method name="convertStorageReports" return="org.apache.hadoop.hdfs.server.protocol.StorageReport[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="list" type="java.util.List"/>
    </method>
    <method name="convertStorageReports" return="java.util.List"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="storages" type="org.apache.hadoop.hdfs.server.protocol.StorageReport[]"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.server.protocol.JournalInfo"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="info" type="org.apache.hadoop.hdfs.protocol.proto.JournalProtocolProtos.JournalInfoProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.JournalProtocolProtos.JournalInfoProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="j" type="org.apache.hadoop.hdfs.server.protocol.JournalInfo"/>
      <doc>
      <![CDATA[Method used for converting {@link JournalInfoProto} sent from Namenode
 to Journal receivers to {@link NamenodeRegistration}.]]>
      </doc>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="sdlp" type="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.SnapshottableDirectoryListingProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.SnapshottableDirectoryListingProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="status" type="org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus[]"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.SnapshotDiffReport.DiffReportEntry"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="entry" type="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.SnapshotDiffReportEntryProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.SnapshotDiffReportEntryProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="entry" type="org.apache.hadoop.hdfs.protocol.SnapshotDiffReport.DiffReportEntry"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.SnapshotDiffReport"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="reportProto" type="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.SnapshotDiffReportProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.SnapshotDiffReportProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="report" type="org.apache.hadoop.hdfs.protocol.SnapshotDiffReport"/>
    </method>
    <method name="convert" return="org.apache.hadoop.util.DataChecksum.Type"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="type" type="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.ChecksumTypeProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.CacheDirectiveInfoProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="info" type="org.apache.hadoop.hdfs.protocol.CacheDirectiveInfo"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.CacheDirectiveInfo"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="proto" type="org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.CacheDirectiveInfoProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.CacheDirectiveInfoExpirationProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="expiration" type="org.apache.hadoop.hdfs.protocol.CacheDirectiveInfo.Expiration"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.CacheDirectiveInfo.Expiration"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="proto" type="org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.CacheDirectiveInfoExpirationProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.CacheDirectiveStatsProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="stats" type="org.apache.hadoop.hdfs.protocol.CacheDirectiveStats"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.CacheDirectiveStats"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="proto" type="org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.CacheDirectiveStatsProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.CacheDirectiveEntryProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="entry" type="org.apache.hadoop.hdfs.protocol.CacheDirectiveEntry"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.CacheDirectiveEntry"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="proto" type="org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.CacheDirectiveEntryProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.CachePoolInfoProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="info" type="org.apache.hadoop.hdfs.protocol.CachePoolInfo"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.CachePoolInfo"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="proto" type="org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.CachePoolInfoProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.CachePoolStatsProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="stats" type="org.apache.hadoop.hdfs.protocol.CachePoolStats"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.CachePoolStats"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="proto" type="org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.CachePoolStatsProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.CachePoolEntryProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="entry" type="org.apache.hadoop.hdfs.protocol.CachePoolEntry"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.CachePoolEntry"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="proto" type="org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.CachePoolEntryProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.ChecksumTypeProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="type" type="org.apache.hadoop.util.DataChecksum.Type"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.DatanodeLocalInfoProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="info" type="org.apache.hadoop.hdfs.protocol.DatanodeLocalInfo"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.DatanodeLocalInfo"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="proto" type="org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.DatanodeLocalInfoProto"/>
    </method>
    <method name="vintPrefixed" return="java.io.InputStream"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="input" type="java.io.InputStream"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.AclProtos.AclEntryProto.FsActionProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="v" type="org.apache.hadoop.fs.permission.FsAction"/>
    </method>
    <method name="convert" return="org.apache.hadoop.fs.permission.FsAction"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="v" type="org.apache.hadoop.hdfs.protocol.proto.AclProtos.AclEntryProto.FsActionProto"/>
    </method>
    <method name="convertAclEntryProto" return="java.util.List"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="aclSpec" type="java.util.List"/>
    </method>
    <method name="convertAclEntry" return="java.util.List"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="aclSpec" type="java.util.List"/>
    </method>
    <method name="convert" return="org.apache.hadoop.fs.permission.AclStatus"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="e" type="org.apache.hadoop.hdfs.protocol.proto.AclProtos.GetAclStatusResponseProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.AclProtos.GetAclStatusResponseProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="e" type="org.apache.hadoop.fs.permission.AclStatus"/>
    </method>
    <method name="convertXAttrProto" return="org.apache.hadoop.hdfs.protocol.proto.XAttrProtos.XAttrProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="a" type="org.apache.hadoop.fs.XAttr"/>
    </method>
    <method name="convertXAttrProto" return="java.util.List"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="xAttrSpec" type="java.util.List"/>
    </method>
    <method name="convert" return="int"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="flag" type="java.util.EnumSet"/>
      <doc>
      <![CDATA[The flag field in PB is a bitmask whose values are the same a the 
 emum values of XAttrSetFlag]]>
      </doc>
    </method>
    <method name="convert" return="java.util.EnumSet"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="flag" type="int"/>
    </method>
    <method name="convertXAttr" return="org.apache.hadoop.fs.XAttr"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="a" type="org.apache.hadoop.hdfs.protocol.proto.XAttrProtos.XAttrProto"/>
    </method>
    <method name="convertXAttrs" return="java.util.List"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="xAttrSpec" type="java.util.List"/>
    </method>
    <method name="convert" return="java.util.List"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="a" type="org.apache.hadoop.hdfs.protocol.proto.XAttrProtos.GetXAttrsResponseProto"/>
    </method>
    <method name="convertXAttrsResponse" return="org.apache.hadoop.hdfs.protocol.proto.XAttrProtos.GetXAttrsResponseProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="xAttrs" type="java.util.List"/>
    </method>
    <method name="convert" return="java.util.List"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="a" type="org.apache.hadoop.hdfs.protocol.proto.XAttrProtos.ListXAttrsResponseProto"/>
    </method>
    <method name="convertListXAttrsResponse" return="org.apache.hadoop.hdfs.protocol.proto.XAttrProtos.ListXAttrsResponseProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="names" type="java.util.List"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos.EncryptionZoneProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="zone" type="org.apache.hadoop.hdfs.protocol.EncryptionZone"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.EncryptionZone"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="proto" type="org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos.EncryptionZoneProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos.ShortCircuitShmSlotProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="slotId" type="org.apache.hadoop.hdfs.shortcircuit.ShortCircuitShm.SlotId"/>
    </method>
    <