<?xml version="1.0" encoding="iso-8859-1" standalone="no"?>
<!-- Generated by the JDiff Javadoc doclet -->
<!-- (http://www.jdiff.org) -->
<!-- on Sun Dec 04 01:00:08 UTC 2011 -->

<api
  xmlns:xsi='http://www.w3.org/2001/XMLSchema-instance'
  xsi:noNamespaceSchemaLocation='api.xsd'
  name="hadoop-hdfs 0.22.0"
  jdversion="1.0.9">

<!--  Command line arguments =  -doclet jdiff.JDiff -docletpath /x1/jenkins/jenkins-slave/workspace/Hadoop-22-Build/common/hdfs/build/ivy/lib/Hadoop-Hdfs/jdiff/jdiff-1.0.9.jar:/x1/jenkins/jenkins-slave/workspace/Hadoop-22-Build/common/hdfs/build/ivy/lib/Hadoop-Hdfs/jdiff/xerces-1.4.4.jar -classpath /x1/jenkins/jenkins-slave/workspace/Hadoop-22-Build/common/hdfs/build/classes:/x1/jenkins/jenkins-slave/workspace/Hadoop-22-Build/common/hdfs/conf:/home/jenkins/.ivy2/cache/org.apache.hadoop/hadoop-common/jars/hadoop-common-0.22.0-SNAPSHOT.jar:/home/jenkins/.ivy2/cache/commons-cli/commons-cli/jars/commons-cli-1.2.jar:/home/jenkins/.ivy2/cache/xmlenc/xmlenc/jars/xmlenc-0.52.jar:/home/jenkins/.ivy2/cache/commons-codec/commons-codec/jars/commons-codec-1.4.jar:/home/jenkins/.ivy2/cache/commons-logging/commons-logging/jars/commons-logging-1.1.1.jar:/home/jenkins/.ivy2/cache/org.slf4j/slf4j-api/jars/slf4j-api-1.6.1.jar:/home/jenkins/.ivy2/cache/org.slf4j/slf4j-log4j12/jars/slf4j-log4j12-1.6.1.jar:/home/jenkins/.ivy2/cache/log4j/log4j/bundles/log4j-1.2.16.jar:/home/jenkins/.ivy2/cache/org.mortbay.jetty/jetty/jars/jetty-6.1.26.jar:/home/jenkins/.ivy2/cache/org.mortbay.jetty/jetty-util/jars/jetty-util-6.1.26.jar:/home/jenkins/.ivy2/cache/org.mortbay.jetty/servlet-api/jars/servlet-api-2.5-20081211.jar:/home/jenkins/.ivy2/cache/tomcat/jasper-runtime/jars/jasper-runtime-5.5.12.jar:/home/jenkins/.ivy2/cache/tomcat/jasper-compiler/jars/jasper-compiler-5.5.12.jar:/home/jenkins/.ivy2/cache/org.mortbay.jetty/jsp-2.1-jetty/jars/jsp-2.1-jetty-6.1.26.jar:/home/jenkins/.ivy2/cache/org.eclipse.jdt/core/jars/core-3.1.1.jar:/home/jenkins/.ivy2/cache/org.mortbay.jetty/jsp-api-2.1-glassfish/jars/jsp-api-2.1-glassfish-2.1.v20091210.jar:/home/jenkins/.ivy2/cache/org.mortbay.jetty/jsp-2.1-glassfish/jars/jsp-2.1-glassfish-2.1.v20091210.jar:/home/jenkins/.ivy2/cache/org.eclipse.jdt.core.compiler/ecj/jars/ecj-3.5.1.jar:/home/jenkins/.ivy2/cache/commons-el/commons-el/jars/commons-el-1.0.jar:/home/jenkins/.ivy2/cache/net.java.dev.jets3t/jets3t/jars/jets3t-0.7.1.jar:/home/jenkins/.ivy2/cache/commons-httpclient/commons-httpclient/jars/commons-httpclient-3.1.jar:/home/jenkins/.ivy2/cache/commons-net/commons-net/jars/commons-net-1.4.1.jar:/home/jenkins/.ivy2/cache/oro/oro/jars/oro-2.0.8.jar:/home/jenkins/.ivy2/cache/net.sf.kosmosfs/kfs/jars/kfs-0.3.jar:/home/jenkins/.ivy2/cache/junit/junit/jars/junit-4.8.1.jar:/home/jenkins/.ivy2/cache/hsqldb/hsqldb/jars/hsqldb-1.8.0.10.jar:/home/jenkins/.ivy2/cache/org.apache.avro/avro/jars/avro-1.5.3.jar:/home/jenkins/.ivy2/cache/org.codehaus.jackson/jackson-mapper-asl/jars/jackson-mapper-asl-1.7.3.jar:/home/jenkins/.ivy2/cache/org.codehaus.jackson/jackson-core-asl/jars/jackson-core-asl-1.7.3.jar:/home/jenkins/.ivy2/cache/com.thoughtworks.paranamer/paranamer/jars/paranamer-2.3.jar:/home/jenkins/.ivy2/cache/org.xerial.snappy/snappy-java/bundles/snappy-java-1.0.3.2.jar:/home/jenkins/.ivy2/cache/org.apache.avro/avro-ipc/jars/avro-ipc-1.5.3.jar:/home/jenkins/.ivy2/cache/commons-daemon/commons-daemon/jars/commons-daemon-1.0.1.jar:/home/jenkins/.ivy2/cache/org.apache.avro/avro-compiler/jars/avro-compiler-1.5.3.jar:/home/jenkins/.ivy2/cache/commons-lang/commons-lang/jars/commons-lang-2.5.jar:/home/jenkins/.ivy2/cache/org.apache.velocity/velocity/jars/velocity-1.6.4.jar:/home/jenkins/.ivy2/cache/commons-collections/commons-collections/jars/commons-collections-3.2.1.jar:/home/jenkins/.ivy2/cache/com.thoughtworks.paranamer/paranamer-ant/jars/paranamer-ant-2.3.jar:/home/jenkins/.ivy2/cache/com.thoughtworks.paranamer/paranamer-generator/jars/paranamer-generator-2.3.jar:/home/jenkins/.ivy2/cache/com.thoughtworks.qdox/qdox/jars/qdox-1.12.jar:/home/jenkins/.ivy2/cache/asm/asm/jars/asm-3.3.jar:/home/jenkins/.ivy2/cache/org.apache.ant/ant/jars/ant-1.7.1.jar:/home/jenkins/.ivy2/cache/org.apache.ant/ant-launcher/jars/ant-launcher-1.7.1.jar:/home/jenkins/.ivy2/cache/org.aspectj/aspectjrt/jars/aspectjrt-1.6.5.jar:/home/jenkins/.ivy2/cache/org.aspectj/aspectjtools/jars/aspectjtools-1.6.5.jar:/home/jenkins/.ivy2/cache/org.mockito/mockito-all/jars/mockito-all-1.8.2.jar:/home/jenkins/.ivy2/cache/com.google.guava/guava/jars/guava-r09.jar:/home/jenkins/.ivy2/cache/jdiff/jdiff/jars/jdiff-1.0.9.jar:/home/jenkins/.ivy2/cache/xerces/xerces/jars/xerces-1.4.4.jar:/home/jenkins/tools/ant/latest/lib/ant-launcher.jar:/usr/share/java/xmlParserAPIs.jar:/usr/share/java/xercesImpl.jar:/home/jenkins/tools/ant/latest/lib/ant-apache-resolver.jar:/home/jenkins/tools/ant/latest/lib/ant-apache-bcel.jar:/home/jenkins/tools/ant/latest/lib/ant-jsch.jar:/home/jenkins/tools/ant/latest/lib/ant-jmf.jar:/home/jenkins/tools/ant/latest/lib/ant-apache-oro.jar:/home/jenkins/tools/ant/latest/lib/ant-netrexx.jar:/home/jenkins/tools/ant/latest/lib/ant-testutil.jar:/home/jenkins/tools/ant/latest/lib/ant-apache-xalan2.jar:/home/jenkins/tools/ant/latest/lib/ant-javamail.jar:/home/jenkins/tools/ant/latest/lib/ant.jar:/home/jenkins/tools/ant/latest/lib/ant-junit.jar:/home/jenkins/tools/ant/latest/lib/ant-swing.jar:/home/jenkins/tools/ant/latest/lib/ant-commons-net.jar:/home/jenkins/tools/ant/latest/lib/ant-jdepend.jar:/home/jenkins/tools/ant/latest/lib/ant-junit4.jar:/home/jenkins/tools/ant/latest/lib/ant-commons-logging.jar:/home/jenkins/tools/ant/latest/lib/ant-apache-bsf.jar:/home/jenkins/tools/ant/latest/lib/ant-apache-log4j.jar:/home/jenkins/tools/ant/latest/lib/ant-jai.jar:/home/jenkins/tools/ant/latest/lib/ant-apache-regexp.jar:/home/jenkins/tools/ant/latest/lib/ant-antlr.jar:/tmp/jdk1.6.0_29/lib/tools.jar -sourcepath /x1/jenkins/jenkins-slave/workspace/Hadoop-22-Build/common/hdfs/src/java -apidir /x1/jenkins/jenkins-slave/workspace/Hadoop-22-Build/common/hdfs/lib/jdiff -apiname hadoop-hdfs 0.22.0 -->
<package name="org.apache.hadoop.fs">
  <!-- start class org.apache.hadoop.fs.Hdfs -->
  <class name="Hdfs" extends="org.apache.hadoop.fs.AbstractFileSystem"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="getUriDefaultPort" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="createInternal" return="org.apache.hadoop.fs.FSDataOutputStream"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="f" type="org.apache.hadoop.fs.Path"/>
      <param name="createFlag" type="java.util.EnumSet"/>
      <param name="absolutePermission" type="org.apache.hadoop.fs.permission.FsPermission"/>
      <param name="bufferSize" type="int"/>
      <param name="replication" type="short"/>
      <param name="blockSize" type="long"/>
      <param name="progress" type="org.apache.hadoop.util.Progressable"/>
      <param name="bytesPerChecksum" type="int"/>
      <param name="createParent" type="boolean"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="delete" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="f" type="org.apache.hadoop.fs.Path"/>
      <param name="recursive" type="boolean"/>
      <exception name="IOException" type="java.io.IOException"/>
      <exception name="UnresolvedLinkException" type="org.apache.hadoop.fs.UnresolvedLinkException"/>
    </method>
    <method name="getFileBlockLocations" return="org.apache.hadoop.fs.BlockLocation[]"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="p" type="org.apache.hadoop.fs.Path"/>
      <param name="start" type="long"/>
      <param name="len" type="long"/>
      <exception name="IOException" type="java.io.IOException"/>
      <exception name="UnresolvedLinkException" type="org.apache.hadoop.fs.UnresolvedLinkException"/>
    </method>
    <method name="getFileChecksum" return="org.apache.hadoop.fs.FileChecksum"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="f" type="org.apache.hadoop.fs.Path"/>
      <exception name="IOException" type="java.io.IOException"/>
      <exception name="UnresolvedLinkException" type="org.apache.hadoop.fs.UnresolvedLinkException"/>
    </method>
    <method name="getFileStatus" return="org.apache.hadoop.fs.FileStatus"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="f" type="org.apache.hadoop.fs.Path"/>
      <exception name="IOException" type="java.io.IOException"/>
      <exception name="UnresolvedLinkException" type="org.apache.hadoop.fs.UnresolvedLinkException"/>
    </method>
    <method name="getFileLinkStatus" return="org.apache.hadoop.fs.FileStatus"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="f" type="org.apache.hadoop.fs.Path"/>
      <exception name="IOException" type="java.io.IOException"/>
      <exception name="UnresolvedLinkException" type="org.apache.hadoop.fs.UnresolvedLinkException"/>
    </method>
    <method name="getFsStatus" return="org.apache.hadoop.fs.FsStatus"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="getServerDefaults" return="org.apache.hadoop.fs.FsServerDefaults"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="listLocatedStatus" return="org.apache.hadoop.fs.RemoteIterator"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="p" type="org.apache.hadoop.fs.Path"/>
      <exception name="FileNotFoundException" type="java.io.FileNotFoundException"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="listStatusIterator" return="org.apache.hadoop.fs.RemoteIterator"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="f" type="org.apache.hadoop.fs.Path"/>
      <exception name="AccessControlException" type="org.apache.hadoop.security.AccessControlException"/>
      <exception name="FileNotFoundException" type="java.io.FileNotFoundException"/>
      <exception name="UnresolvedLinkException" type="org.apache.hadoop.fs.UnresolvedLinkException"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="listStatus" return="org.apache.hadoop.fs.FileStatus[]"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="f" type="org.apache.hadoop.fs.Path"/>
      <exception name="IOException" type="java.io.IOException"/>
      <exception name="UnresolvedLinkException" type="org.apache.hadoop.fs.UnresolvedLinkException"/>
    </method>
    <method name="mkdir"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="dir" type="org.apache.hadoop.fs.Path"/>
      <param name="permission" type="org.apache.hadoop.fs.permission.FsPermission"/>
      <param name="createParent" type="boolean"/>
      <exception name="IOException" type="java.io.IOException"/>
      <exception name="UnresolvedLinkException" type="org.apache.hadoop.fs.UnresolvedLinkException"/>
    </method>
    <method name="open" return="org.apache.hadoop.fs.FSDataInputStream"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="f" type="org.apache.hadoop.fs.Path"/>
      <param name="bufferSize" type="int"/>
      <exception name="IOException" type="java.io.IOException"/>
      <exception name="UnresolvedLinkException" type="org.apache.hadoop.fs.UnresolvedLinkException"/>
    </method>
    <method name="renameInternal"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="org.apache.hadoop.fs.Path"/>
      <param name="dst" type="org.apache.hadoop.fs.Path"/>
      <exception name="IOException" type="java.io.IOException"/>
      <exception name="UnresolvedLinkException" type="org.apache.hadoop.fs.UnresolvedLinkException"/>
    </method>
    <method name="renameInternal"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="org.apache.hadoop.fs.Path"/>
      <param name="dst" type="org.apache.hadoop.fs.Path"/>
      <param name="overwrite" type="boolean"/>
      <exception name="IOException" type="java.io.IOException"/>
      <exception name="UnresolvedLinkException" type="org.apache.hadoop.fs.UnresolvedLinkException"/>
    </method>
    <method name="setOwner"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="f" type="org.apache.hadoop.fs.Path"/>
      <param name="username" type="java.lang.String"/>
      <param name="groupname" type="java.lang.String"/>
      <exception name="IOException" type="java.io.IOException"/>
      <exception name="UnresolvedLinkException" type="org.apache.hadoop.fs.UnresolvedLinkException"/>
    </method>
    <method name="setPermission"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="f" type="org.apache.hadoop.fs.Path"/>
      <param name="permission" type="org.apache.hadoop.fs.permission.FsPermission"/>
      <exception name="IOException" type="java.io.IOException"/>
      <exception name="UnresolvedLinkException" type="org.apache.hadoop.fs.UnresolvedLinkException"/>
    </method>
    <method name="setReplication" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="f" type="org.apache.hadoop.fs.Path"/>
      <param name="replication" type="short"/>
      <exception name="IOException" type="java.io.IOException"/>
      <exception name="UnresolvedLinkException" type="org.apache.hadoop.fs.UnresolvedLinkException"/>
    </method>
    <method name="setTimes"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="f" type="org.apache.hadoop.fs.Path"/>
      <param name="mtime" type="long"/>
      <param name="atime" type="long"/>
      <exception name="IOException" type="java.io.IOException"/>
      <exception name="UnresolvedLinkException" type="org.apache.hadoop.fs.UnresolvedLinkException"/>
    </method>
    <method name="setVerifyChecksum"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="verifyChecksum" type="boolean"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="supportsSymlinks" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="createSymlink"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="target" type="org.apache.hadoop.fs.Path"/>
      <param name="link" type="org.apache.hadoop.fs.Path"/>
      <param name="createParent" type="boolean"/>
      <exception name="IOException" type="java.io.IOException"/>
      <exception name="UnresolvedLinkException" type="org.apache.hadoop.fs.UnresolvedLinkException"/>
    </method>
    <method name="getLinkTarget" return="org.apache.hadoop.fs.Path"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="p" type="org.apache.hadoop.fs.Path"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
  </class>
  <!-- end class org.apache.hadoop.fs.Hdfs -->
</package>
<package name="org.apache.hadoop.hdfs">
  <!-- start class org.apache.hadoop.hdfs.BlockMissingException -->
  <class name="BlockMissingException" extends="java.io.IOException"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="BlockMissingException" type="java.lang.String, java.lang.String, long"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[An exception that indicates that file was corrupted.
 @param filename name of corrupted file
 @param description a description of the corruption details]]>
      </doc>
    </constructor>
    <method name="getFile" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Returns the name of the corrupted file.
 @return name of corrupted file]]>
      </doc>
    </method>
    <method name="getOffset" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Returns the offset at which this file is corrupted
 @return offset of corrupted file]]>
      </doc>
    </method>
    <doc>
    <![CDATA[This exception is thrown when a read encounters a block that has no locations
 associated with it.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.BlockMissingException -->
  <!-- start class org.apache.hadoop.hdfs.BlockReader -->
  <class name="BlockReader" extends="org.apache.hadoop.fs.FSInputChecker"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="read" return="int"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="buf" type="byte[]"/>
      <param name="off" type="int"/>
      <param name="len" type="int"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="skip" return="long"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="n" type="long"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="read" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="seekToNewSource" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="targetPos" type="long"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="seek"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="pos" type="long"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="getChunkPosition" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
      <param name="pos" type="long"/>
    </method>
    <method name="readChunk" return="int"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
      <param name="pos" type="long"/>
      <param name="buf" type="byte[]"/>
      <param name="offset" type="int"/>
      <param name="len" type="int"/>
      <param name="checksumBuf" type="byte[]"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="newBlockReader" return="org.apache.hadoop.hdfs.BlockReader"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="sock" type="java.net.Socket"/>
      <param name="file" type="java.lang.String"/>
      <param name="block" type="org.apache.hadoop.hdfs.protocol.Block"/>
      <param name="blockToken" type="org.apache.hadoop.security.token.Token"/>
      <param name="startOffset" type="long"/>
      <param name="len" type="long"/>
      <param name="bufferSize" type="int"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="newBlockReader" return="org.apache.hadoop.hdfs.BlockReader"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="sock" type="java.net.Socket"/>
      <param name="file" type="java.lang.String"/>
      <param name="block" type="org.apache.hadoop.hdfs.protocol.Block"/>
      <param name="blockToken" type="org.apache.hadoop.security.token.Token"/>
      <param name="startOffset" type="long"/>
      <param name="len" type="long"/>
      <param name="bufferSize" type="int"/>
      <param name="verifyChecksum" type="boolean"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Java Doc required]]>
      </doc>
    </method>
    <method name="newBlockReader" return="org.apache.hadoop.hdfs.BlockReader"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="sock" type="java.net.Socket"/>
      <param name="file" type="java.lang.String"/>
      <param name="block" type="org.apache.hadoop.hdfs.protocol.Block"/>
      <param name="blockToken" type="org.apache.hadoop.security.token.Token"/>
      <param name="startOffset" type="long"/>
      <param name="len" type="long"/>
      <param name="bufferSize" type="int"/>
      <param name="verifyChecksum" type="boolean"/>
      <param name="clientName" type="java.lang.String"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Create a new BlockReader specifically to satisfy a read.
 This method also sends the OP_READ_BLOCK request.

 @param sock  An established Socket to the DN. The BlockReader will not close it normally
 @param file  File location
 @param block  The block object
 @param blockToken  The block token for security
 @param startOffset  The read offset, relative to block head
 @param len  The number of bytes to read
 @param bufferSize  The IO buffer size (not the client buffer size)
 @param verifyChecksum  Whether to verify checksum
 @param clientName  Client name
 @return New BlockReader instance, or null on error.]]>
      </doc>
    </method>
    <method name="close"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="readAll" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="buf" type="byte[]"/>
      <param name="offset" type="int"/>
      <param name="len" type="int"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[kind of like readFully(). Only reads as much as possible.
 And allows use of protected readFully().]]>
      </doc>
    </method>
    <method name="takeSocket" return="java.net.Socket"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Take the socket used to talk to the DN.]]>
      </doc>
    </method>
    <method name="hasSentStatusCode" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Whether the BlockReader has reached the end of its input stream
 and successfully sent a status code back to the datanode.]]>
      </doc>
    </method>
    <method name="getFileName" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="s" type="java.net.InetSocketAddress"/>
      <param name="blockId" type="long"/>
    </method>
    <doc>
    <![CDATA[This is a wrapper around connection to datanode
 and understands checksum, offset etc.

 Terminology:
 <dl>
 <dt>block</dt>
   <dd>The hdfs block, typically large (~64MB).
   </dd>
 <dt>chunk</dt>
   <dd>A block is divided into chunks, each comes with a checksum.
       We want transfers to be chunk-aligned, to be able to
       verify checksums.
   </dd>
 <dt>packet</dt>
   <dd>A grouping of chunks used for transport. It contains a
       header, followed by checksum data, followed by real data.
   </dd>
 </dl>
 Please see DataNode for the RPC specification.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.BlockReader -->
  <!-- start class org.apache.hadoop.hdfs.DeprecatedUTF8 -->
  <class name="DeprecatedUTF8" extends="org.apache.hadoop.io.UTF8"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="DeprecatedUTF8"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <constructor name="DeprecatedUTF8" type="java.lang.String"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Construct from a given string.]]>
      </doc>
    </constructor>
    <constructor name="DeprecatedUTF8" type="org.apache.hadoop.hdfs.DeprecatedUTF8"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Construct from a given string.]]>
      </doc>
    </constructor>
    <method name="readString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="in" type="java.io.DataInput"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="writeString" return="int"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="out" type="java.io.DataOutput"/>
      <param name="s" type="java.lang.String"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <doc>
    <![CDATA[A simple wrapper around {@link org.apache.hadoop.io.UTF8}.
 This class should be used only when it is absolutely necessary
 to use {@link org.apache.hadoop.io.UTF8}. The only difference is that 
 using this class does not require "@SuppressWarning" annotation to avoid 
 javac warning. Instead the deprecation is implied in the class name.
 
 This should be treated as package private class to HDFS.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.DeprecatedUTF8 -->
  <!-- start class org.apache.hadoop.hdfs.DFSClient -->
  <class name="DFSClient" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <implements name="org.apache.hadoop.hdfs.protocol.FSConstants"/>
    <implements name="java.io.Closeable"/>
    <constructor name="DFSClient" type="org.apache.hadoop.conf.Configuration"
      static="false" final="false" visibility="public"
      deprecated="Deprecated at 0.21">
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Same as this(NameNode.getAddress(conf), conf);
 @see #DFSClient(InetSocketAddress, Configuration)
 @deprecated Deprecated at 0.21]]>
      </doc>
    </constructor>
    <constructor name="DFSClient" type="java.net.InetSocketAddress, org.apache.hadoop.conf.Configuration"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Same as this(nameNodeAddr, conf, null);
 @see #DFSClient(InetSocketAddress, Configuration, org.apache.hadoop.fs.FileSystem.Statistics)]]>
      </doc>
    </constructor>
    <constructor name="DFSClient" type="java.net.InetSocketAddress, org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.FileSystem.Statistics"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Same as this(nameNodeAddr, null, conf, stats);
 @see #DFSClient(InetSocketAddress, ClientProtocol, Configuration, org.apache.hadoop.fs.FileSystem.Statistics)]]>
      </doc>
    </constructor>
    <method name="createNamenode" return="org.apache.hadoop.hdfs.protocol.ClientProtocol"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[The locking hierarchy is to first acquire lock on DFSClient object, followed by 
 lock on leasechecker, followed by lock on an individual DFSOutputStream.]]>
      </doc>
    </method>
    <method name="createNamenode" return="org.apache.hadoop.hdfs.protocol.ClientProtocol"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="nameNodeAddr" type="java.net.InetSocketAddress"/>
      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="close"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Close the file system, abandoning all of the leases and files being
 created and close connections to the namenode.]]>
      </doc>
    </method>
    <method name="getDefaultBlockSize" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Get the default block size for this cluster
 @return the default block size in bytes]]>
      </doc>
    </method>
    <method name="getBlockSize" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="f" type="java.lang.String"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[@see ClientProtocol#getPreferredBlockSize(String)]]>
      </doc>
    </method>
    <method name="getServerDefaults" return="org.apache.hadoop.fs.FsServerDefaults"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Get server default values for a number of configuration params.
 @see ClientProtocol#getServerDefaults()]]>
      </doc>
    </method>
    <method name="stringifyToken" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="token" type="org.apache.hadoop.security.token.Token"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[A test method for printing out tokens 
  @param token
  @return Stringify version of the token]]>
      </doc>
    </method>
    <method name="getDelegationToken" return="org.apache.hadoop.security.token.Token"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="renewer" type="org.apache.hadoop.io.Text"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[@see ClientProtocol#getDelegationToken(Text)]]>
      </doc>
    </method>
    <method name="renewDelegationToken" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="token" type="org.apache.hadoop.security.token.Token"/>
      <exception name="SecretManager.InvalidToken" type="org.apache.hadoop.security.token.SecretManager.InvalidToken"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[@see ClientProtocol#renewDelegationToken(Token)]]>
      </doc>
    </method>
    <method name="cancelDelegationToken"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="token" type="org.apache.hadoop.security.token.Token"/>
      <exception name="SecretManager.InvalidToken" type="org.apache.hadoop.security.token.SecretManager.InvalidToken"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[@see ClientProtocol#cancelDelegationToken(Token)]]>
      </doc>
    </method>
    <method name="reportBadBlocks"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="blocks" type="org.apache.hadoop.hdfs.protocol.LocatedBlock[]"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Report corrupt blocks that were discovered by the client.
 @see ClientProtocol#reportBadBlocks(LocatedBlock[])]]>
      </doc>
    </method>
    <method name="getDefaultReplication" return="short"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getBlockLocations" return="org.apache.hadoop.fs.BlockLocation[]"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="java.lang.String"/>
      <param name="start" type="long"/>
      <param name="length" type="long"/>
      <exception name="IOException" type="java.io.IOException"/>
      <exception name="UnresolvedLinkException" type="org.apache.hadoop.fs.UnresolvedLinkException"/>
      <doc>
      <![CDATA[Get block location info about file
 
 getBlockLocations() returns a list of hostnames that store 
 data for a specific file region.  It returns a set of hostnames
 for every block within the indicated region.

 This function is very useful when writing code that considers
 data-placement when performing operations.  For example, the
 MapReduce system tries to schedule tasks on the same machines
 as the data-block the task processes.]]>
      </doc>
    </method>
    <method name="open" return="org.apache.hadoop.hdfs.DFSInputStream"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="java.lang.String"/>
      <exception name="IOException" type="java.io.IOException"/>
      <exception name="UnresolvedLinkException" type="org.apache.hadoop.fs.UnresolvedLinkException"/>
    </method>
    <method name="open" return="org.apache.hadoop.hdfs.DFSInputStream"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="Use {@link #open(String, int, boolean)} instead.">
      <param name="src" type="java.lang.String"/>
      <param name="buffersize" type="int"/>
      <param name="verifyChecksum" type="boolean"/>
      <param name="stats" type="org.apache.hadoop.fs.FileSystem.Statistics"/>
      <exception name="IOException" type="java.io.IOException"/>
      <exception name="UnresolvedLinkException" type="org.apache.hadoop.fs.UnresolvedLinkException"/>
      <doc>
      <![CDATA[Create an input stream that obtains a nodelist from the
 namenode, and then reads from all the right places.  Creates
 inner subclass of InputStream that does the right out-of-band
 work.
 @deprecated Use {@link #open(String, int, boolean)} instead.]]>
      </doc>
    </method>
    <method name="open" return="org.apache.hadoop.hdfs.DFSInputStream"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="java.lang.String"/>
      <param name="buffersize" type="int"/>
      <param name="verifyChecksum" type="boolean"/>
      <exception name="IOException" type="java.io.IOException"/>
      <exception name="UnresolvedLinkException" type="org.apache.hadoop.fs.UnresolvedLinkException"/>
      <doc>
      <![CDATA[Create an input stream that obtains a nodelist from the
 namenode, and then reads from all the right places.  Creates
 inner subclass of InputStream that does the right out-of-band
 work.]]>
      </doc>
    </method>
    <method name="getNamenode" return="org.apache.hadoop.hdfs.protocol.ClientProtocol"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Get the namenode associated with this DFSClient object
 @return the namenode associated with this DFSClient object]]>
      </doc>
    </method>
    <method name="create" return="java.io.OutputStream"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="java.lang.String"/>
      <param name="overwrite" type="boolean"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Call {@link #create(String, boolean, short, long, Progressable)} with
 default <code>replication</code> and <code>blockSize<code> and null <code>
 progress</code>.]]>
      </doc>
    </method>
    <method name="create" return="java.io.OutputStream"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="java.lang.String"/>
      <param name="overwrite" type="boolean"/>
      <param name="progress" type="org.apache.hadoop.util.Progressable"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Call {@link #create(String, boolean, short, long, Progressable)} with
 default <code>replication</code> and <code>blockSize<code>.]]>
      </doc>
    </method>
    <method name="create" return="java.io.OutputStream"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="java.lang.String"/>
      <param name="overwrite" type="boolean"/>
      <param name="replication" type="short"/>
      <param name="blockSize" type="long"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Call {@link #create(String, boolean, short, long, Progressable)} with
 null <code>progress</code>.]]>
      </doc>
    </method>
    <method name="create" return="java.io.OutputStream"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="java.lang.String"/>
      <param name="overwrite" type="boolean"/>
      <param name="replication" type="short"/>
      <param name="blockSize" type="long"/>
      <param name="progress" type="org.apache.hadoop.util.Progressable"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Call {@link #create(String, boolean, short, long, Progressable, int)}
 with default bufferSize.]]>
      </doc>
    </method>
    <method name="create" return="java.io.OutputStream"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="java.lang.String"/>
      <param name="overwrite" type="boolean"/>
      <param name="replication" type="short"/>
      <param name="blockSize" type="long"/>
      <param name="progress" type="org.apache.hadoop.util.Progressable"/>
      <param name="buffersize" type="int"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Call {@link #create(String, FsPermission, EnumSet, short, long, 
 Progressable, int)} with default <code>permission</code>
 {@link FsPermission#getDefault()}.
 
 @param src File name
 @param overwrite overwrite an existing file if true
 @param replication replication factor for the file
 @param blockSize maximum block size
 @param progress interface for reporting client progress
 @param buffersize underlying buffersize
 
 @return output stream]]>
      </doc>
    </method>
    <method name="create" return="java.io.OutputStream"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="java.lang.String"/>
      <param name="permission" type="org.apache.hadoop.fs.permission.FsPermission"/>
      <param name="flag" type="java.util.EnumSet"/>
      <param name="replication" type="short"/>
      <param name="blockSize" type="long"/>
      <param name="progress" type="org.apache.hadoop.util.Progressable"/>
      <param name="buffersize" type="int"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Call {@link #create(String, FsPermission, EnumSet, boolean, short, 
 long, Progressable, int)} with <code>createParent</code> set to true.]]>
      </doc>
    </method>
    <method name="create" return="java.io.OutputStream"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="java.lang.String"/>
      <param name="permission" type="org.apache.hadoop.fs.permission.FsPermission"/>
      <param name="flag" type="java.util.EnumSet"/>
      <param name="createParent" type="boolean"/>
      <param name="replication" type="short"/>
      <param name="blockSize" type="long"/>
      <param name="progress" type="org.apache.hadoop.util.Progressable"/>
      <param name="buffersize" type="int"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Create a new dfs file with the specified block replication 
 with write-progress reporting and return an output stream for writing
 into the file.  
 
 @param src File name
 @param permission The permission of the directory being created.
          If null, use default permission {@link FsPermission#getDefault()}
 @param flag indicates create a new file or create/overwrite an
          existing file or append to an existing file
 @param createParent create missing parent directory if true
 @param replication block replication
 @param blockSize maximum block size
 @param progress interface for reporting client progress
 @param buffersize underlying buffer size 
 
 @return output stream
 
 @see ClientProtocol#create(String, FsPermission, String, EnumSetWritable,
 boolean, short, long) for detailed description of exceptions thrown]]>
      </doc>
    </method>
    <method name="primitiveCreate" return="java.io.OutputStream"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="java.lang.String"/>
      <param name="absPermission" type="org.apache.hadoop.fs.permission.FsPermission"/>
      <param name="flag" type="java.util.EnumSet"/>
      <param name="createParent" type="boolean"/>
      <param name="replication" type="short"/>
      <param name="blockSize" type="long"/>
      <param name="progress" type="org.apache.hadoop.util.Progressable"/>
      <param name="buffersize" type="int"/>
      <param name="bytesPerChecksum" type="int"/>
      <exception name="IOException" type="java.io.IOException"/>
      <exception name="UnresolvedLinkException" type="org.apache.hadoop.fs.UnresolvedLinkException"/>
      <doc>
      <![CDATA[Same as {{@link #create(String, FsPermission, EnumSet, short, long,
  Progressable, int)} except that the permission
   is absolute (ie has already been masked with umask.]]>
      </doc>
    </method>
    <method name="createSymlink"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="target" type="java.lang.String"/>
      <param name="link" type="java.lang.String"/>
      <param name="createParent" type="boolean"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Creates a symbolic link.
 
 @see ClientProtocol#createSymlink(String, String,FsPermission, boolean)]]>
      </doc>
    </method>
    <method name="getLinkTarget" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="path" type="java.lang.String"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Resolve the *first* symlink, if any, in the path.
 
 @see ClientProtocol#getLinkTarget(String)]]>
      </doc>
    </method>
    <method name="setReplication" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="java.lang.String"/>
      <param name="replication" type="short"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Set replication for an existing file.
 @param src file name
 @param replication
 
 @see ClientProtocol#setReplication(String, short)]]>
      </doc>
    </method>
    <method name="rename" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="Use {@link #rename(String, String, Options.Rename...)} instead.">
      <param name="src" type="java.lang.String"/>
      <param name="dst" type="java.lang.String"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Rename file or directory.
 @see ClientProtocol#rename(String, String)
 @deprecated Use {@link #rename(String, String, Options.Rename...)} instead.]]>
      </doc>
    </method>
    <method name="concat"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="trg" type="java.lang.String"/>
      <param name="srcs" type="java.lang.String[]"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Move blocks from src to trg and delete src
 See {@link ClientProtocol#concat(String, String [])}.]]>
      </doc>
    </method>
    <method name="rename"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="java.lang.String"/>
      <param name="dst" type="java.lang.String"/>
      <param name="options" type="org.apache.hadoop.fs.Options.Rename[]"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Rename file or directory.
 @see ClientProtocol#rename(String, String, Options.Rename...)]]>
      </doc>
    </method>
    <method name="delete" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="java.lang.String"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Delete file or directory.
 See {@link ClientProtocol#delete(String)}.]]>
      </doc>
    </method>
    <method name="delete" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="java.lang.String"/>
      <param name="recursive" type="boolean"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[delete file or directory.
 delete contents of the directory if non empty and recursive 
 set to true

 @see ClientProtocol#delete(String, boolean)]]>
      </doc>
    </method>
    <method name="exists" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="java.lang.String"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Implemented using getFileInfo(src)]]>
      </doc>
    </method>
    <method name="listPaths" return="org.apache.hadoop.hdfs.protocol.DirectoryListing"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="java.lang.String"/>
      <param name="startAfter" type="byte[]"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Get a partial listing of the indicated directory
 No block locations need to be fetched]]>
      </doc>
    </method>
    <method name="listPaths" return="org.apache.hadoop.hdfs.protocol.DirectoryListing"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="java.lang.String"/>
      <param name="startAfter" type="byte[]"/>
      <param name="needLocation" type="boolean"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Get a partial listing of the indicated directory

 Recommend to use HdfsFileStatus.EMPTY_NAME as startAfter
 if the application wants to fetch a listing starting from
 the first entry in the directory

 @see ClientProtocol#getListing(String, byte[], boolean)]]>
      </doc>
    </method>
    <method name="getFileInfo" return="org.apache.hadoop.hdfs.protocol.HdfsFileStatus"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="java.lang.String"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Get the file info for a specific file or directory.
 @param src The string representation of the path to the file
 @return object containing information regarding the file
         or null if file not found
         
 @see ClientProtocol#getFileInfo(String) for description of exceptions]]>
      </doc>
    </method>
    <method name="getFileLinkInfo" return="org.apache.hadoop.hdfs.protocol.HdfsFileStatus"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="java.lang.String"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Get the file info for a specific file or directory. If src
 refers to a symlink then the FileStatus of the link is returned.
 @param src path to a file or directory.
 
 For description of exceptions thrown 
 @see ClientProtocol#getFileLinkInfo(String)]]>
      </doc>
    </method>
    <method name="getFileChecksum" return="org.apache.hadoop.fs.MD5MD5CRC32FileChecksum"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="java.lang.String"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Get the checksum of a file.
 @param src The file path
 @return The checksum 
 @see DistributedFileSystem#getFileChecksum(Path)]]>
      </doc>
    </method>
    <method name="getFileChecksum" return="org.apache.hadoop.fs.MD5MD5CRC32FileChecksum"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="java.lang.String"/>
      <param name="namenode" type="org.apache.hadoop.hdfs.protocol.ClientProtocol"/>
      <param name="socketFactory" type="javax.net.SocketFactory"/>
      <param name="socketTimeout" type="int"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Get the checksum of a file.
 @param src The file path
 @return The checksum]]>
      </doc>
    </method>
    <method name="setPermission"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="java.lang.String"/>
      <param name="permission" type="org.apache.hadoop.fs.permission.FsPermission"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Set permissions to a file or directory.
 @param src path name.
 @param permission
 
 @see ClientProtocol#setPermission(String, FsPermission)]]>
      </doc>
    </method>
    <method name="setOwner"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="java.lang.String"/>
      <param name="username" type="java.lang.String"/>
      <param name="groupname" type="java.lang.String"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Set file or directory owner.
 @param src path name.
 @param username user id.
 @param groupname user group.
 
 @see ClientProtocol#setOwner(String, String, String)]]>
      </doc>
    </method>
    <method name="getDiskStatus" return="org.apache.hadoop.fs.FsStatus"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[@see ClientProtocol#getStats()]]>
      </doc>
    </method>
    <method name="getMissingBlocksCount" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Returns count of blocks with no good replicas left. Normally should be 
 zero.
 @throws IOException]]>
      </doc>
    </method>
    <method name="getUnderReplicatedBlocksCount" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Returns count of blocks with one of more replica missing.
 @throws IOException]]>
      </doc>
    </method>
    <method name="getCorruptBlocksCount" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Returns count of blocks with at least one replica marked corrupt. 
 @throws IOException]]>
      </doc>
    </method>
    <method name="datanodeReport" return="org.apache.hadoop.hdfs.protocol.DatanodeInfo[]"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="type" type="org.apache.hadoop.hdfs.protocol.FSConstants.DatanodeReportType"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="setSafeMode" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="action" type="org.apache.hadoop.hdfs.protocol.FSConstants.SafeModeAction"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Enter, leave or get safe mode.
 
 @see ClientProtocol#setSafeMode(FSConstants.SafeModeAction)]]>
      </doc>
    </method>
    <method name="refreshNodes"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Refresh the hosts and exclude files.  (Rereads them.)
 See {@link ClientProtocol#refreshNodes()} 
 for more details.
 
 @see ClientProtocol#refreshNodes()]]>
      </doc>
    </method>
    <method name="metaSave"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="pathname" type="java.lang.String"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Dumps DFS data structures into specified file.
 
 @see ClientProtocol#metaSave(String)]]>
      </doc>
    </method>
    <method name="finalizeUpgrade"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[@see ClientProtocol#finalizeUpgrade()]]>
      </doc>
    </method>
    <method name="distributedUpgradeProgress" return="org.apache.hadoop.hdfs.server.common.UpgradeStatusReport"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="action" type="org.apache.hadoop.hdfs.protocol.FSConstants.UpgradeAction"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[@see ClientProtocol#distributedUpgradeProgress(FSConstants.UpgradeAction)]]>
      </doc>
    </method>
    <method name="mkdirs" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="java.lang.String"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="mkdirs" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="java.lang.String"/>
      <param name="permission" type="org.apache.hadoop.fs.permission.FsPermission"/>
      <param name="createParent" type="boolean"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Create a directory (or hierarchy of directories) with the given
 name and permission.

 @param src The path of the directory being created
 @param permission The permission of the directory being created.
 If permission == null, use {@link FsPermission#getDefault()}.
 @param createParent create missing parent directory if true
 
 @return True if the operation success.
 
 @see ClientProtocol#mkdirs(String, FsPermission, boolean)]]>
      </doc>
    </method>
    <method name="primitiveMkdir" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="java.lang.String"/>
      <param name="absPermission" type="org.apache.hadoop.fs.permission.FsPermission"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Same {{@link #mkdirs(String, FsPermission, boolean)} except
 that the permissions has already been masked against umask.]]>
      </doc>
    </method>
    <method name="setTimes"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="java.lang.String"/>
      <param name="mtime" type="long"/>
      <param name="atime" type="long"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[set the modification and access time of a file
 
 @see ClientProtocol#setTimes(String, long, long)]]>
      </doc>
    </method>
    <method name="toString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[{@inheritDoc}]]>
      </doc>
    </method>
    <field name="LOG" type="org.apache.commons.logging.Log"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="SERVER_DEFAULTS_VALIDITY_PERIOD" type="long"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="MAX_BLOCK_ACQUIRE_FAILURES" type="int"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <doc>
    <![CDATA[DFSClient can connect to a Hadoop Filesystem and 
 perform basic file tasks.  It uses the ClientProtocol
 to communicate with a NameNode daemon, and connects 
 directly to DataNodes to read/write block data.

 Hadoop DFS users should obtain an instance of 
 DistributedFileSystem, which uses DFSClient to handle
 filesystem tasks.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.DFSClient -->
  <!-- start class org.apache.hadoop.hdfs.DFSClient.DFSDataInputStream -->
  <class name="DFSClient.DFSDataInputStream" extends="org.apache.hadoop.fs.FSDataInputStream"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="DFSClient.DFSDataInputStream" type="org.apache.hadoop.hdfs.DFSInputStream"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
    </constructor>
    <method name="getCurrentDatanode" return="org.apache.hadoop.hdfs.protocol.DatanodeInfo"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Returns the datanode from which the stream is currently reading.]]>
      </doc>
    </method>
    <method name="getCurrentBlock" return="org.apache.hadoop.hdfs.protocol.Block"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Returns the block containing the target position.]]>
      </doc>
    </method>
    <method name="getVisibleLength" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[@return The visible length of the file.]]>
      </doc>
    </method>
    <doc>
    <![CDATA[The Hdfs implementation of {@link FSDataInputStream}]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.DFSClient.DFSDataInputStream -->
  <!-- start class org.apache.hadoop.hdfs.DFSConfigKeys -->
  <class name="DFSConfigKeys" extends="org.apache.hadoop.fs.CommonConfigurationKeys"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="DFSConfigKeys"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <field name="DFS_BLOCK_SIZE_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_BLOCK_SIZE_DEFAULT" type="long"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_REPLICATION_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_REPLICATION_DEFAULT" type="short"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_STREAM_BUFFER_SIZE_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_STREAM_BUFFER_SIZE_DEFAULT" type="int"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_BYTES_PER_CHECKSUM_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_BYTES_PER_CHECKSUM_DEFAULT" type="int"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_CLIENT_WRITE_PACKET_SIZE_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_CLIENT_WRITE_PACKET_SIZE_DEFAULT" type="int"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_BACKUP_ADDRESS_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_BACKUP_ADDRESS_DEFAULT" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_BACKUP_HTTP_ADDRESS_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_BACKUP_HTTP_ADDRESS_DEFAULT" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_BACKUP_SERVICE_RPC_ADDRESS_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_DATANODE_BALANCE_BANDWIDTHPERSEC_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_DATANODE_BALANCE_BANDWIDTHPERSEC_DEFAULT" type="long"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_HTTP_ADDRESS_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_HTTP_ADDRESS_DEFAULT" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_SERVICE_RPC_ADDRESS_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_MAX_OBJECTS_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_MAX_OBJECTS_DEFAULT" type="long"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_SAFEMODE_EXTENSION_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_SAFEMODE_EXTENSION_DEFAULT" type="int"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_SAFEMODE_THRESHOLD_PCT_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_SAFEMODE_THRESHOLD_PCT_DEFAULT" type="float"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_SAFEMODE_MIN_DATANODES_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_SAFEMODE_MIN_DATANODES_DEFAULT" type="int"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_DEFAULT" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_CHECKPOINT_PERIOD_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_CHECKPOINT_PERIOD_DEFAULT" type="long"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_CHECKPOINT_SIZE_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_CHECKPOINT_SIZE_DEFAULT" type="long"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_UPGRADE_PERMISSION_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_UPGRADE_PERMISSION_DEFAULT" type="int"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_DEFAULT" type="int"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_CLIENT_HTTPS_KEYSTORE_RESOURCE_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_CLIENT_HTTPS_KEYSTORE_RESOURCE_DEFAULT" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_CLIENT_HTTPS_NEED_AUTH_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_CLIENT_HTTPS_NEED_AUTH_DEFAULT" type="boolean"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_CLIENT_CACHED_CONN_RETRY_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_CLIENT_CACHED_CONN_RETRY_DEFAULT" type="int"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_CLIENT_SOCKET_CACHE_CAPACITY_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_CLIENT_SOCKET_CACHE_CAPACITY_DEFAULT" type="int"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_ACCESSTIME_PRECISION_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_ACCESSTIME_PRECISION_DEFAULT" type="long"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_REPLICATION_CONSIDERLOAD_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_REPLICATION_CONSIDERLOAD_DEFAULT" type="boolean"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_REPLICATION_INTERVAL_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_REPLICATION_INTERVAL_DEFAULT" type="int"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_REPLICATION_MIN_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_REPLICATION_MIN_DEFAULT" type="int"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_REPLICATION_PENDING_TIMEOUT_SEC_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_REPLICATION_PENDING_TIMEOUT_SEC_DEFAULT" type="int"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_REPLICATION_MAX_STREAMS_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_REPLICATION_MAX_STREAMS_DEFAULT" type="int"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_PERMISSIONS_ENABLED_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_PERMISSIONS_ENABLED_DEFAULT" type="boolean"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_PERMISSIONS_SUPERUSERGROUP_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_PERMISSIONS_SUPERUSERGROUP_DEFAULT" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_ADMIN" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_SERVER_HTTPS_KEYSTORE_RESOURCE_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_SERVER_HTTPS_KEYSTORE_RESOURCE_DEFAULT" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_NAME_DIR_RESTORE_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_NAME_DIR_RESTORE_DEFAULT" type="boolean"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_SUPPORT_ALLOW_FORMAT_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_SUPPORT_ALLOW_FORMAT_DEFAULT" type="boolean"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_LIST_LIMIT" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_LIST_LIMIT_DEFAULT" type="int"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_DATANODE_FAILED_VOLUMES_TOLERATED_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_DATANODE_FAILED_VOLUMES_TOLERATED_DEFAULT" type="int"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_DATANODE_SOCKET_REUSE_KEEPALIVE_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_DATANODE_SOCKET_REUSE_KEEPALIVE_DEFAULT" type="int"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_DELEGATION_KEY_UPDATE_INTERVAL_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_DELEGATION_KEY_UPDATE_INTERVAL_DEFAULT" type="long"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_DELEGATION_TOKEN_RENEW_INTERVAL_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_DELEGATION_TOKEN_RENEW_INTERVAL_DEFAULT" type="long"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_DELEGATION_TOKEN_MAX_LIFETIME_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_DELEGATION_TOKEN_MAX_LIFETIME_DEFAULT" type="long"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_DATANODE_DATA_DIR_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_HTTPS_ADDRESS_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_HTTPS_ADDRESS_DEFAULT" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_NAME_DIR_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_EDITS_DIR_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_CLIENT_READ_PREFETCH_SIZE_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_CLIENT_RETRY_WINDOW_BASE" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_METRICS_SESSION_ID_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_DATANODE_HOST_NAME_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_DATANODE_STORAGEID_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_HOSTS_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_HOSTS_EXCLUDE_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_CLIENT_SOCKET_TIMEOUT_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_CHECKPOINT_DIR_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_CHECKPOINT_EDITS_DIR_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_CLIENT_BLOCK_WRITE_LOCATEFOLLOWINGBLOCK_RETRIES_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_CLIENT_BLOCK_WRITE_LOCATEFOLLOWINGBLOCK_RETRIES_DEFAULT" type="int"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_CLIENT_BLOCK_WRITE_RETRIES_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_CLIENT_BLOCK_WRITE_RETRIES_DEFAULT" type="int"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_CLIENT_MAX_BLOCK_ACQUIRE_FAILURES_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_CLIENT_MAX_BLOCK_ACQUIRE_FAILURES_DEFAULT" type="int"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_BALANCER_MOVEDWINWIDTH_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_BALANCER_MOVEDWINWIDTH_DEFAULT" type="int"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_DATANODE_ADDRESS_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_DATANODE_ADDRESS_DEFAULT" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_DATANODE_DATA_DIR_PERMISSION_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_DATANODE_DATA_DIR_PERMISSION_DEFAULT" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_DATANODE_DIRECTORYSCAN_INTERVAL_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_DATANODE_DIRECTORYSCAN_INTERVAL_DEFAULT" type="int"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_DATANODE_DIRECTORYSCAN_THREADS_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_DATANODE_DIRECTORYSCAN_THREADS_DEFAULT" type="int"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_DATANODE_DNS_INTERFACE_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_DATANODE_DNS_INTERFACE_DEFAULT" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_DATANODE_DNS_NAMESERVER_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_DATANODE_DNS_NAMESERVER_DEFAULT" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_DATANODE_DU_RESERVED_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_DATANODE_DU_RESERVED_DEFAULT" type="long"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_DATANODE_HANDLER_COUNT_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_DATANODE_HANDLER_COUNT_DEFAULT" type="int"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_DATANODE_HTTP_ADDRESS_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_DATANODE_HTTP_ADDRESS_DEFAULT" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_DATANODE_MAX_RECEIVER_THREADS_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_DATANODE_MAX_RECEIVER_THREADS_DEFAULT" type="int"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_DATANODE_NUMBLOCKS_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_DATANODE_NUMBLOCKS_DEFAULT" type="int"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_DATANODE_SCAN_PERIOD_HOURS_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_DATANODE_SCAN_PERIOD_HOURS_DEFAULT" type="int"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_DATANODE_SIMULATEDDATASTORAGE_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_DATANODE_SIMULATEDDATASTORAGE_DEFAULT" type="boolean"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_DATANODE_SIMULATEDDATASTORAGE_CAPACITY_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_DATANODE_SIMULATEDDATASTORAGE_CAPACITY_DEFAULT" type="long"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_DATANODE_TRANSFERTO_ALLOWED_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_DATANODE_TRANSFERTO_ALLOWED_DEFAULT" type="boolean"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_HEARTBEAT_INTERVAL_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_HEARTBEAT_INTERVAL_DEFAULT" type="long"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_DECOMMISSION_INTERVAL_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_DECOMMISSION_INTERVAL_DEFAULT" type="int"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_DECOMMISSION_NODES_PER_INTERVAL_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_DECOMMISSION_NODES_PER_INTERVAL_DEFAULT" type="int"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_HANDLER_COUNT_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_HANDLER_COUNT_DEFAULT" type="int"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_SERVICE_HANDLER_COUNT_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_SERVICE_HANDLER_COUNT_DEFAULT" type="int"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_SUPPORT_APPEND_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_SUPPORT_APPEND_DEFAULT" type="boolean"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_HTTPS_ENABLE_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_HTTPS_ENABLE_DEFAULT" type="boolean"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_DEFAULT_CHUNK_VIEW_SIZE_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_DEFAULT_CHUNK_VIEW_SIZE_DEFAULT" type="int"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_DATANODE_HTTPS_ADDRESS_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_DATANODE_HTTPS_ADDRESS_DEFAULT" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_DATANODE_IPC_ADDRESS_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_DATANODE_IPC_ADDRESS_DEFAULT" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_BLOCK_ACCESS_TOKEN_ENABLE_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_BLOCK_ACCESS_TOKEN_ENABLE_DEFAULT" type="boolean"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_BLOCK_ACCESS_KEY_UPDATE_INTERVAL_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_BLOCK_ACCESS_KEY_UPDATE_INTERVAL_DEFAULT" type="long"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_BLOCK_ACCESS_TOKEN_LIFETIME_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_BLOCK_ACCESS_TOKEN_LIFETIME_DEFAULT" type="long"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_REPLICATION_MAX_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_REPLICATION_MAX_DEFAULT" type="int"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_DF_INTERVAL_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_DF_INTERVAL_DEFAULT" type="int"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_BLOCKREPORT_INTERVAL_MSEC_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_BLOCKREPORT_INTERVAL_MSEC_DEFAULT" type="long"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_BLOCKREPORT_INITIAL_DELAY_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_BLOCKREPORT_INITIAL_DELAY_DEFAULT" type="int"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_IMAGE_COMPRESS_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_IMAGE_COMPRESS_DEFAULT" type="boolean"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_IMAGE_COMPRESSION_CODEC_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_IMAGE_COMPRESSION_CODEC_DEFAULT" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_IMAGE_TRANSFER_RATE_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_IMAGE_TRANSFER_RATE_DEFAULT" type="long"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_DATANODE_PLUGINS_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_DATANODE_SOCKET_WRITE_TIMEOUT_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_DATANODE_STARTUP_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_PLUGINS_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_WEB_UGI_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_STARTUP_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_DATANODE_KEYTAB_FILE_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_DATANODE_USER_NAME_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_KEYTAB_FILE_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_USER_NAME_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_KRB_HTTPS_USER_NAME_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_SECONDARY_NAMENODE_USER_NAME_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_SECONDARY_NAMENODE_KRB_HTTPS_USER_NAME_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_NAME_CACHE_THRESHOLD_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DFS_NAMENODE_NAME_CACHE_THRESHOLD_DEFAULT" type="int"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <doc>
    <![CDATA[This class contains constants for configuration keys used
 in hdfs.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.DFSConfigKeys -->
  <!-- start class org.apache.hadoop.hdfs.DFSInputStream -->
  <class name="DFSInputStream" extends="org.apache.hadoop.fs.FSInputStream"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="getFileLength" return="long"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getCurrentDatanode" return="org.apache.hadoop.hdfs.protocol.DatanodeInfo"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Returns the datanode from which the stream is currently reading.]]>
      </doc>
    </method>
    <method name="getCurrentBlock" return="org.apache.hadoop.hdfs.protocol.Block"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Returns the block containing the target position.]]>
      </doc>
    </method>
    <method name="close"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Close it down!]]>
      </doc>
    </method>
    <method name="read" return="int"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="read" return="int"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="buf" type="byte[]"/>
      <param name="off" type="int"/>
      <param name="len" type="int"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Read the entire buffer.]]>
      </doc>
    </method>
    <method name="getBlockReader" return="org.apache.hadoop.hdfs.BlockReader"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
      <param name="dnAddr" type="java.net.InetSocketAddress"/>
      <param name="file" type="java.lang.String"/>
      <param name="block" type="org.apache.hadoop.hdfs.protocol.Block"/>
      <param name="blockToken" type="org.apache.hadoop.security.token.Token"/>
      <param name="startOffset" type="long"/>
      <param name="len" type="long"/>
      <param name="bufferSize" type="int"/>
      <param name="verifyChecksum" type="boolean"/>
      <param name="clientName" type="java.lang.String"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Retrieve a BlockReader suitable for reading.
 This method will reuse the cached connection to the DN if appropriate.
 Otherwise, it will create a new connection.

 @param dnAddr  Address of the datanode
 @param file  File location
 @param block  The Block object
 @param blockToken  The access token for security
 @param startOffset  The read offset, relative to block head
 @param len  The number of bytes to read
 @param bufferSize  The IO buffer size (not the client buffer size)
 @param verifyChecksum  Whether to verify checksum
 @param clientName  Client name
 @return New BlockReader instance]]>
      </doc>
    </method>
    <method name="read" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="position" type="long"/>
      <param name="buffer" type="byte[]"/>
      <param name="offset" type="int"/>
      <param name="length" type="int"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Read bytes starting from the specified position.
 
 @param position start read from this position
 @param buffer read buffer
 @param offset offset into buffer
 @param length number of bytes to read
 
 @return actual number of bytes read]]>
      </doc>
    </method>
    <method name="skip" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="n" type="long"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="seek"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="targetPos" type="long"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Seek to a new arbitrary location]]>
      </doc>
    </method>
    <method name="seekToNewSource" return="boolean"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="targetPos" type="long"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Seek to given position on a node other than the current node.  If
 a node other than the current node is found, then returns true. 
 If another node could not be found, then returns false.]]>
      </doc>
    </method>
    <method name="getPos" return="long"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="available" return="int"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Return the size of the remaining available bytes
 if the size is less than or equal to {@link Integer#MAX_VALUE},
 otherwise, return {@link Integer#MAX_VALUE}.]]>
      </doc>
    </method>
    <method name="markSupported" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[We definitely don't support marks]]>
      </doc>
    </method>
    <method name="mark"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="readLimit" type="int"/>
    </method>
    <method name="reset"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <doc>
    <![CDATA[DFSInputStream provides bytes from a named file.  It handles 
 negotiation of the namenode and various datanodes as necessary.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.DFSInputStream -->
  <!-- start class org.apache.hadoop.hdfs.DFSUtil -->
  <class name="DFSUtil" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="DFSUtil"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="isValidName" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="java.lang.String"/>
      <doc>
      <![CDATA[Whether the pathname is valid.  Currently prohibits relative paths, 
 and names which contain a ":" or "/"]]>
      </doc>
    </method>
    <method name="bytes2String" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="bytes" type="byte[]"/>
      <doc>
      <![CDATA[Converts a byte array to a string using UTF8 encoding.]]>
      </doc>
    </method>
    <method name="string2Bytes" return="byte[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="str" type="java.lang.String"/>
      <doc>
      <![CDATA[Converts a string to a byte array using UTF8 encoding.]]>
      </doc>
    </method>
    <method name="byteArray2String" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="pathComponents" type="byte[][]"/>
      <doc>
      <![CDATA[Given a list of path components returns a path as a UTF8 String]]>
      </doc>
    </method>
    <method name="bytes2byteArray" return="byte[][]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="bytes" type="byte[]"/>
      <param name="separator" type="byte"/>
      <doc>
      <![CDATA[Splits the array of bytes into array of arrays of bytes
 on byte separator
 @param bytes the array of bytes to split
 @param separator the delimiting byte]]>
      </doc>
    </method>
    <method name="bytes2byteArray" return="byte[][]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="bytes" type="byte[]"/>
      <param name="len" type="int"/>
      <param name="separator" type="byte"/>
      <doc>
      <![CDATA[Splits first len bytes in bytes to array of arrays of bytes
 on byte separator
 @param bytes the byte array to split
 @param len the number of bytes to split
 @param separator the delimiting byte]]>
      </doc>
    </method>
    <method name="locatedBlocks2Locations" return="org.apache.hadoop.fs.BlockLocation[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="blocks" type="org.apache.hadoop.hdfs.protocol.LocatedBlocks"/>
      <doc>
      <![CDATA[Convert a LocatedBlocks to BlockLocations[]
 @param blocks a LocatedBlocks
 @return an array of BlockLocations]]>
      </doc>
    </method>
  </class>
  <!-- end class org.apache.hadoop.hdfs.DFSUtil -->
  <!-- start class org.apache.hadoop.hdfs.DFSUtil.ErrorSimulator -->
  <class name="DFSUtil.ErrorSimulator" extends="java.lang.Object"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="DFSUtil.ErrorSimulator"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="initializeErrorSimulationEvent"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="numberOfEvents" type="int"/>
    </method>
    <method name="getErrorSimulation" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="index" type="int"/>
    </method>
    <method name="setErrorSimulation"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="index" type="int"/>
    </method>
    <method name="clearErrorSimulation"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="index" type="int"/>
    </method>
    <doc>
    <![CDATA[Utility class to facilitate junit test error simulation.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.DFSUtil.ErrorSimulator -->
  <!-- start class org.apache.hadoop.hdfs.DistributedFileSystem -->
  <class name="DistributedFileSystem" extends="org.apache.hadoop.fs.FileSystem"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="DistributedFileSystem"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <constructor name="DistributedFileSystem" type="java.net.InetSocketAddress, org.apache.hadoop.conf.Configuration"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
    </constructor>
    <method name="getUri" return="java.net.URI"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="initialize"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="uri" type="java.net.URI"/>
      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="checkPath"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
      <param name="path" type="org.apache.hadoop.fs.Path"/>
      <doc>
      <![CDATA[Permit paths which explicitly specify the default port.]]>
      </doc>
    </method>
    <method name="makeQualified" return="org.apache.hadoop.fs.Path"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="path" type="org.apache.hadoop.fs.Path"/>
      <doc>
      <![CDATA[Normalize paths that explicitly specify the default port.]]>
      </doc>
    </method>
    <method name="getWorkingDirectory" return="org.apache.hadoop.fs.Path"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getDefaultBlockSize" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getDefaultReplication" return="short"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="setWorkingDirectory"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="dir" type="org.apache.hadoop.fs.Path"/>
    </method>
    <method name="getHomeDirectory" return="org.apache.hadoop.fs.Path"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[{@inheritDoc}]]>
      </doc>
    </method>
    <method name="getFileBlockLocations" return="org.apache.hadoop.fs.BlockLocation[]"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="file" type="org.apache.hadoop.fs.FileStatus"/>
      <param name="start" type="long"/>
      <param name="len" type="long"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="getFileBlockLocations" return="org.apache.hadoop.fs.BlockLocation[]"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="p" type="org.apache.hadoop.fs.Path"/>
      <param name="start" type="long"/>
      <param name="len" type="long"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="setVerifyChecksum"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="verifyChecksum" type="boolean"/>
    </method>
    <method name="recoverLease" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="f" type="org.apache.hadoop.fs.Path"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Start the lease recovery of a file

 @param f a file
 @return true if the file is already closed
 @throws IOException if an error occurs]]>
      </doc>
    </method>
    <method name="open" return="org.apache.hadoop.fs.FSDataInputStream"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="f" type="org.apache.hadoop.fs.Path"/>
      <param name="bufferSize" type="int"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="append" return="org.apache.hadoop.fs.FSDataOutputStream"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="f" type="org.apache.hadoop.fs.Path"/>
      <param name="bufferSize" type="int"/>
      <param name="progress" type="org.apache.hadoop.util.Progressable"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[This optional operation is not yet supported.]]>
      </doc>
    </method>
    <method name="create" return="org.apache.hadoop.fs.FSDataOutputStream"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="f" type="org.apache.hadoop.fs.Path"/>
      <param name="permission" type="org.apache.hadoop.fs.permission.FsPermission"/>
      <param name="overwrite" type="boolean"/>
      <param name="bufferSize" type="int"/>
      <param name="replication" type="short"/>
      <param name="blockSize" type="long"/>
      <param name="progress" type="org.apache.hadoop.util.Progressable"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="primitiveCreate" return="org.apache.hadoop.fs.FSDataOutputStream"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
      <param name="f" type="org.apache.hadoop.fs.Path"/>
      <param name="absolutePermission" type="org.apache.hadoop.fs.permission.FsPermission"/>
      <param name="flag" type="java.util.EnumSet"/>
      <param name="bufferSize" type="int"/>
      <param name="replication" type="short"/>
      <param name="blockSize" type="long"/>
      <param name="progress" type="org.apache.hadoop.util.Progressable"/>
      <param name="bytesPerChecksum" type="int"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="createNonRecursive" return="org.apache.hadoop.fs.FSDataOutputStream"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="f" type="org.apache.hadoop.fs.Path"/>
      <param name="permission" type="org.apache.hadoop.fs.permission.FsPermission"/>
      <param name="flag" type="java.util.EnumSet"/>
      <param name="bufferSize" type="int"/>
      <param name="replication" type="short"/>
      <param name="blockSize" type="long"/>
      <param name="progress" type="org.apache.hadoop.util.Progressable"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Same as create(), except fails if parent directory doesn't already exist.]]>
      </doc>
    </method>
    <method name="setReplication" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="org.apache.hadoop.fs.Path"/>
      <param name="replication" type="short"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="concat"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="trg" type="org.apache.hadoop.fs.Path"/>
      <param name="psrcs" type="org.apache.hadoop.fs.Path[]"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[THIS IS DFS only operations, it is not part of FileSystem
 move blocks from srcs to trg
 and delete srcs afterwards
 all blocks should be the same size
 @param trg existing file to append to
 @param psrcs list of files (same block size, same replication)
 @throws IOException]]>
      </doc>
    </method>
    <method name="rename" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="org.apache.hadoop.fs.Path"/>
      <param name="dst" type="org.apache.hadoop.fs.Path"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[{@inheritDoc}]]>
      </doc>
    </method>
    <method name="rename"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="org.apache.hadoop.fs.Path"/>
      <param name="dst" type="org.apache.hadoop.fs.Path"/>
      <param name="options" type="org.apache.hadoop.fs.Options.Rename[]"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[{@inheritDoc}
 This rename operation is guaranteed to be atomic.]]>
      </doc>
    </method>
    <method name="delete" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="f" type="org.apache.hadoop.fs.Path"/>
      <param name="recursive" type="boolean"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="getContentSummary" return="org.apache.hadoop.fs.ContentSummary"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="f" type="org.apache.hadoop.fs.Path"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[{@inheritDoc}]]>
      </doc>
    </method>
    <method name="setQuota"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="org.apache.hadoop.fs.Path"/>
      <param name="namespaceQuota" type="long"/>
      <param name="diskspaceQuota" type="long"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Set a directory's quotas
 @see org.apache.hadoop.hdfs.protocol.ClientProtocol#setQuota(String, long, long)]]>
      </doc>
    </method>
    <method name="listStatus" return="org.apache.hadoop.fs.FileStatus[]"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="p" type="org.apache.hadoop.fs.Path"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[List all the entries of a directory

 Note that this operation is not atomic for a large directory.
 The entries of a directory may be fetched from NameNode multiple times.
 It only guarantees that  each name occurs once if a directory
 undergoes changes between the calls.]]>
      </doc>
    </method>
    <method name="listLocatedStatus" return="org.apache.hadoop.fs.RemoteIterator"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
      <param name="p" type="org.apache.hadoop.fs.Path"/>
      <param name="filter" type="org.apache.hadoop.fs.PathFilter"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="mkdir" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="f" type="org.apache.hadoop.fs.Path"/>
      <param name="permission" type="org.apache.hadoop.fs.permission.FsPermission"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Create a directory with given name and permission, only when
 parent directory exists.]]>
      </doc>
    </method>
    <method name="mkdirs" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="f" type="org.apache.hadoop.fs.Path"/>
      <param name="permission" type="org.apache.hadoop.fs.permission.FsPermission"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="primitiveMkdir" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
      <param name="f" type="org.apache.hadoop.fs.Path"/>
      <param name="absolutePermission" type="org.apache.hadoop.fs.permission.FsPermission"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="close"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[{@inheritDoc}]]>
      </doc>
    </method>
    <method name="toString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getClient" return="org.apache.hadoop.hdfs.DFSClient"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getStatus" return="org.apache.hadoop.fs.FsStatus"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="p" type="org.apache.hadoop.fs.Path"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[{@inheritDoc}]]>
      </doc>
    </method>
    <method name="getDiskStatus" return="org.apache.hadoop.hdfs.DistributedFileSystem.DiskStatus"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="Use {@link org.apache.hadoop.fs.FileSystem#getStatus()} 
 instead">
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Return the disk usage of the filesystem, including total capacity,
 used space, and remaining space 
 @deprecated Use {@link org.apache.hadoop.fs.FileSystem#getStatus()} 
 instead]]>
      </doc>
    </method>
    <method name="getRawCapacity" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="Use {@link org.apache.hadoop.fs.FileSystem#getStatus()} 
 instead">
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Return the total raw capacity of the filesystem, disregarding
 replication.
 @deprecated Use {@link org.apache.hadoop.fs.FileSystem#getStatus()} 
 instead]]>
      </doc>
    </method>
    <method name="getRawUsed" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="Use {@link org.apache.hadoop.fs.FileSystem#getStatus()} 
 instead">
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Return the total raw used space in the filesystem, disregarding
 replication.
 @deprecated Use {@link org.apache.hadoop.fs.FileSystem#getStatus()} 
 instead]]>
      </doc>
    </method>
    <method name="getMissingBlocksCount" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Returns count of blocks with no good replicas left. Normally should be
 zero.
 
 @throws IOException]]>
      </doc>
    </method>
    <method name="getUnderReplicatedBlocksCount" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Returns count of blocks with one of more replica missing.
 
 @throws IOException]]>
      </doc>
    </method>
    <method name="getCorruptBlocksCount" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Returns count of blocks with at least one replica marked corrupt.
 
 @throws IOException]]>
      </doc>
    </method>
    <method name="getDataNodeStats" return="org.apache.hadoop.hdfs.protocol.DatanodeInfo[]"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Return statistics for each datanode.]]>
      </doc>
    </method>
    <method name="setSafeMode" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="action" type="org.apache.hadoop.hdfs.protocol.FSConstants.SafeModeAction"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Enter, leave or get safe mode.
  
 @see org.apache.hadoop.hdfs.protocol.ClientProtocol#setSafeMode(
    FSConstants.SafeModeAction)]]>
      </doc>
    </method>
    <method name="saveNamespace"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="AccessControlException" type="org.apache.hadoop.security.AccessControlException"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Save namespace image.
 
 @see org.apache.hadoop.hdfs.protocol.ClientProtocol#saveNamespace()]]>
      </doc>
    </method>
    <method name="restoreFailedStorage" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="arg" type="java.lang.String"/>
      <exception name="AccessControlException" type="org.apache.hadoop.security.AccessControlException"/>
      <doc>
      <![CDATA[enable/disable/check restoreFaileStorage
 
 @see org.apache.hadoop.hdfs.protocol.ClientProtocol#restoreFailedStorage(String arg)]]>
      </doc>
    </method>
    <method name="refreshNodes"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Refreshes the list of hosts and excluded hosts from the configured 
 files.]]>
      </doc>
    </method>
    <method name="finalizeUpgrade"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Finalize previously upgraded files system state.
 @throws IOException]]>
      </doc>
    </method>
    <method name="distributedUpgradeProgress" return="org.apache.hadoop.hdfs.server.common.UpgradeStatusReport"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="action" type="org.apache.hadoop.hdfs.protocol.FSConstants.UpgradeAction"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="metaSave"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="pathname" type="java.lang.String"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="getServerDefaults" return="org.apache.hadoop.fs.FsServerDefaults"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[{@inheritDoc}]]>
      </doc>
    </method>
    <method name="reportChecksumFailure" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="f" type="org.apache.hadoop.fs.Path"/>
      <param name="in" type="org.apache.hadoop.fs.FSDataInputStream"/>
      <param name="inPos" type="long"/>
      <param name="sums" type="org.apache.hadoop.fs.FSDataInputStream"/>
      <param name="sumsPos" type="long"/>
      <doc>
      <![CDATA[We need to find the blocks that didn't match.  Likely only one 
 is corrupt but we will report both to the namenode.  In the future,
 we can consider figuring out exactly which block is corrupt.]]>
      </doc>
    </method>
    <method name="getFileStatus" return="org.apache.hadoop.fs.FileStatus"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="f" type="org.apache.hadoop.fs.Path"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Returns the stat information about the file.
 @throws FileNotFoundException if the file does not exist.]]>
      </doc>
    </method>
    <method name="getFileChecksum" return="org.apache.hadoop.fs.MD5MD5CRC32FileChecksum"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="f" type="org.apache.hadoop.fs.Path"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[{@inheritDoc}]]>
      </doc>
    </method>
    <method name="setPermission"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="p" type="org.apache.hadoop.fs.Path"/>
      <param name="permission" type="org.apache.hadoop.fs.permission.FsPermission"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[{@inheritDoc }]]>
      </doc>
    </method>
    <method name="setOwner"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="p" type="org.apache.hadoop.fs.Path"/>
      <param name="username" type="java.lang.String"/>
      <param name="groupname" type="java.lang.String"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[{@inheritDoc }]]>
      </doc>
    </method>
    <method name="setTimes"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="p" type="org.apache.hadoop.fs.Path"/>
      <param name="mtime" type="long"/>
      <param name="atime" type="long"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[{@inheritDoc }]]>
      </doc>
    </method>
    <method name="getDefaultPort" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
    </method>
    <method name="getDelegationToken" return="org.apache.hadoop.security.token.Token"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="renewer" type="java.lang.String"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="getDelegationToken" return="org.apache.hadoop.security.token.Token"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="use {@link #getDelegationToken(String)}">
      <param name="renewer" type="org.apache.hadoop.io.Text"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Get a valid Delegation Token.
 
 @param renewer Name of the designated renewer for the token
 @return Token<DelegationTokenIdentifier>
 @throws IOException
 @deprecated use {@link #getDelegationToken(String)}]]>
      </doc>
    </method>
    <method name="renewDelegationToken" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="token" type="org.apache.hadoop.security.token.Token"/>
      <exception name="SecretManager.InvalidToken" type="org.apache.hadoop.security.token.SecretManager.InvalidToken"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Renew an existing delegation token.
 
 @param token delegation token obtained earlier
 @return the new expiration time
 @throws IOException]]>
      </doc>
    </method>
    <method name="cancelDelegationToken"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="token" type="org.apache.hadoop.security.token.Token"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Cancel an existing delegation token.
 
 @param token delegation token
 @throws IOException]]>
      </doc>
    </method>
    <doc>
    <![CDATA[Implementation of the abstract FileSystem for the DFS system.
 This object is the way end-user code interacts with a Hadoop
 DistributedFileSystem.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.DistributedFileSystem -->
  <!-- start class org.apache.hadoop.hdfs.DistributedFileSystem.DiskStatus -->
  <class name="DistributedFileSystem.DiskStatus" extends="org.apache.hadoop.fs.FsStatus"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="Use {@link org.apache.hadoop.fs.FsStatus} instead">
    <constructor name="DistributedFileSystem.DiskStatus" type="org.apache.hadoop.fs.FsStatus"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <constructor name="DistributedFileSystem.DiskStatus" type="long, long, long"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getDfsUsed" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[@deprecated Use {@link org.apache.hadoop.fs.FsStatus} instead]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.DistributedFileSystem.DiskStatus -->
  <!-- start class org.apache.hadoop.hdfs.HdfsConfiguration -->
  <class name="HdfsConfiguration" extends="org.apache.hadoop.conf.Configuration"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="HdfsConfiguration"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <constructor name="HdfsConfiguration" type="boolean"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <constructor name="HdfsConfiguration" type="org.apache.hadoop.conf.Configuration"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="init"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[This method is here so that when invoked, HdfsConfiguration is class-loaded if
 it hasn't already been previously loaded.  Upon loading the class, the static 
 initializer block above will be executed to add the deprecated keys and to add
 the default resources.   It is safe for this method to be called multiple times 
 as the static initializer block will only get invoked once.
 
 This replaces the previously, dangerous practice of other classes calling
 Configuration.addDefaultResource("hdfs-default.xml") directly without loading 
 HdfsConfiguration class first, thereby skipping the key deprecation]]>
      </doc>
    </method>
    <doc>
    <![CDATA[Adds deprecated keys into the configuration.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.HdfsConfiguration -->
  <!-- start class org.apache.hadoop.hdfs.HDFSPolicyProvider -->
  <class name="HDFSPolicyProvider" extends="org.apache.hadoop.security.authorize.PolicyProvider"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="HDFSPolicyProvider"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getServices" return="org.apache.hadoop.security.authorize.Service[]"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[{@link PolicyProvider} for HDFS protocols.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.HDFSPolicyProvider -->
  <!-- start class org.apache.hadoop.hdfs.HftpFileSystem -->
  <class name="HftpFileSystem" extends="org.apache.hadoop.fs.FileSystem"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="HftpFileSystem"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getDateFormat" return="java.text.SimpleDateFormat"
      abstract="false" native="false" synchronized="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getDefaultPort" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
    </method>
    <method name="getCanonicalServiceName" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="initialize"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="name" type="java.net.URI"/>
      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="getDelegationToken" return="org.apache.hadoop.security.token.Token"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="renewer" type="java.lang.String"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="getUri" return="java.net.URI"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="openConnection" return="java.net.HttpURLConnection"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
      <param name="path" type="java.lang.String"/>
      <param name="query" type="java.lang.String"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Open an HTTP connection to the namenode to read file data and metadata.
 @param path The path component of the URL
 @param query The query component of the URL]]>
      </doc>
    </method>
    <method name="updateQuery" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
      <param name="query" type="java.lang.String"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="open" return="org.apache.hadoop.fs.FSDataInputStream"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="f" type="org.apache.hadoop.fs.Path"/>
      <param name="buffersize" type="int"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="listStatus" return="org.apache.hadoop.fs.FileStatus[]"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="f" type="org.apache.hadoop.fs.Path"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="getFileStatus" return="org.apache.hadoop.fs.FileStatus"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="f" type="org.apache.hadoop.fs.Path"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="getFileChecksum" return="org.apache.hadoop.fs.FileChecksum"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="f" type="org.apache.hadoop.fs.Path"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[{@inheritDoc}]]>
      </doc>
    </method>
    <method name="getWorkingDirectory" return="org.apache.hadoop.fs.Path"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="setWorkingDirectory"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="f" type="org.apache.hadoop.fs.Path"/>
    </method>
    <method name="append" return="org.apache.hadoop.fs.FSDataOutputStream"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="f" type="org.apache.hadoop.fs.Path"/>
      <param name="bufferSize" type="int"/>
      <param name="progress" type="org.apache.hadoop.util.Progressable"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[This optional operation is not yet supported.]]>
      </doc>
    </method>
    <method name="create" return="org.apache.hadoop.fs.FSDataOutputStream"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="f" type="org.apache.hadoop.fs.Path"/>
      <param name="permission" type="org.apache.hadoop.fs.permission.FsPermission"/>
      <param name="overwrite" type="boolean"/>
      <param name="bufferSize" type="int"/>
      <param name="replication" type="short"/>
      <param name="blockSize" type="long"/>
      <param name="progress" type="org.apache.hadoop.util.Progressable"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="rename" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="org.apache.hadoop.fs.Path"/>
      <param name="dst" type="org.apache.hadoop.fs.Path"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="delete" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="f" type="org.apache.hadoop.fs.Path"/>
      <param name="recursive" type="boolean"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="mkdirs" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="f" type="org.apache.hadoop.fs.Path"/>
      <param name="permission" type="org.apache.hadoop.fs.permission.FsPermission"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="getContentSummary" return="org.apache.hadoop.fs.ContentSummary"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="f" type="org.apache.hadoop.fs.Path"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[{@inheritDoc}]]>
      </doc>
    </method>
    <field name="nnAddr" type="java.net.InetSocketAddress"
      transient="false" volatile="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
    </field>
    <field name="ugi" type="org.apache.hadoop.security.UserGroupInformation"
      transient="false" volatile="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
    </field>
    <field name="ran" type="java.util.Random"
      transient="false" volatile="false"
      static="false" final="true" visibility="protected"
      deprecated="not deprecated">
    </field>
    <field name="HFTP_TIMEZONE" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="HFTP_DATE_FORMAT" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="HFTP_SERVICE_NAME_KEY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="df" type="java.lang.ThreadLocal"
      transient="false" volatile="false"
      static="true" final="true" visibility="protected"
      deprecated="not deprecated">
    </field>
    <doc>
    <![CDATA[An implementation of a protocol for accessing filesystems over HTTP.
 The following implementation provides a limited, read-only interface
 to a filesystem over HTTP.
 @see org.apache.hadoop.hdfs.server.namenode.ListPathsServlet
 @see org.apache.hadoop.hdfs.server.namenode.FileDataServlet]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.HftpFileSystem -->
  <!-- start class org.apache.hadoop.hdfs.HsftpFileSystem -->
  <class name="HsftpFileSystem" extends="org.apache.hadoop.hdfs.HftpFileSystem"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="HsftpFileSystem"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="initialize"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="name" type="java.net.URI"/>
      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="openConnection" return="java.net.HttpURLConnection"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
      <param name="path" type="java.lang.String"/>
      <param name="query" type="java.lang.String"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="getUri" return="java.net.URI"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[An implementation of a protocol for accessing filesystems over HTTPS. The
 following implementation provides a limited, read-only interface to a
 filesystem over HTTPS.
 
 @see org.apache.hadoop.hdfs.server.namenode.ListPathsServlet
 @see org.apache.hadoop.hdfs.server.namenode.FileDataServlet]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.HsftpFileSystem -->
  <!-- start class org.apache.hadoop.hdfs.HsftpFileSystem.DummyHostnameVerifier -->
  <class name="HsftpFileSystem.DummyHostnameVerifier" extends="java.lang.Object"
    abstract="false"
    static="true" final="false" visibility="protected"
    deprecated="not deprecated">
    <implements name="javax.net.ssl.HostnameVerifier"/>
    <constructor name="HsftpFileSystem.DummyHostnameVerifier"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
    </constructor>
    <method name="verify" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="hostname" type="java.lang.String"/>
      <param name="session" type="javax.net.ssl.SSLSession"/>
    </method>
    <doc>
    <![CDATA[Dummy hostname verifier that is used to bypass hostname checking]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.HsftpFileSystem.DummyHostnameVerifier -->
  <!-- start class org.apache.hadoop.hdfs.HsftpFileSystem.DummyTrustManager -->
  <class name="HsftpFileSystem.DummyTrustManager" extends="java.lang.Object"
    abstract="false"
    static="true" final="false" visibility="protected"
    deprecated="not deprecated">
    <implements name="javax.net.ssl.X509TrustManager"/>
    <constructor name="HsftpFileSystem.DummyTrustManager"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
    </constructor>
    <method name="checkClientTrusted"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="chain" type="java.security.cert.X509Certificate[]"/>
      <param name="authType" type="java.lang.String"/>
    </method>
    <method name="checkServerTrusted"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="chain" type="java.security.cert.X509Certificate[]"/>
      <param name="authType" type="java.lang.String"/>
    </method>
    <method name="getAcceptedIssuers" return="java.security.cert.X509Certificate[]"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[Dummy trustmanager that is used to trust all server certificates]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.HsftpFileSystem.DummyTrustManager -->
  <doc>
  <![CDATA[<p>A distributed implementation of {@link
org.apache.hadoop.fs.FileSystem}.  This is loosely modelled after
Google's <a href="http://labs.google.com/papers/gfs.html">GFS</a>.</p>

<p>The most important difference is that unlike GFS, Hadoop DFS files 
have strictly one writer at any one time.  Bytes are always appended 
to the end of the writer's stream.  There is no notion of "record appends"
or "mutations" that are then checked or reordered.  Writers simply emit 
a byte stream.  That byte stream is guaranteed to be stored in the 
order written.</p>]]>
  </doc>
</package>
<package name="org.apache.hadoop.hdfs.protocol">
  <!-- start class org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException -->
  <class name="AlreadyBeingCreatedException" extends="java.io.IOException"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="AlreadyBeingCreatedException" type="java.lang.String"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <doc>
    <![CDATA[The exception that happens when you ask to create a file that already
 is being created, but is not closed yet.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException -->
  <!-- start class org.apache.hadoop.hdfs.protocol.Block -->
  <class name="Block" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <implements name="org.apache.hadoop.io.Writable"/>
    <implements name="java.lang.Comparable"/>
    <constructor name="Block"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <constructor name="Block" type="long, long, long"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <constructor name="Block" type="long"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <constructor name="Block" type="org.apache.hadoop.hdfs.protocol.Block"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <constructor name="Block" type="java.io.File, long, long"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Find the blockid from the given filename]]>
      </doc>
    </constructor>
    <method name="isBlockFilename" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="f" type="java.io.File"/>
    </method>
    <method name="filename2id" return="long"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="name" type="java.lang.String"/>
    </method>
    <method name="isMetaFilename" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="name" type="java.lang.String"/>
    </method>
    <method name="getGenerationStamp" return="long"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="metaFile" type="java.lang.String"/>
      <doc>
      <![CDATA[Get generation stamp from the name of the metafile name]]>
      </doc>
    </method>
    <method name="getBlockId" return="long"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="metaFile" type="java.lang.String"/>
      <doc>
      <![CDATA[Get the blockId from the name of the metafile name]]>
      </doc>
    </method>
    <method name="set"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="blkid" type="long"/>
      <param name="len" type="long"/>
      <param name="genStamp" type="long"/>
    </method>
    <method name="getBlockId" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="setBlockId"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="bid" type="long"/>
    </method>
    <method name="getBlockName" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getNumBytes" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="setNumBytes"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="len" type="long"/>
    </method>
    <method name="getGenerationStamp" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="setGenerationStamp"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="stamp" type="long"/>
    </method>
    <method name="toString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="write"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="out" type="java.io.DataOutput"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="readFields"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="in" type="java.io.DataInput"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="writeId"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="out" type="java.io.DataOutput"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="readId"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="in" type="java.io.DataInput"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="compareTo" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="b" type="org.apache.hadoop.hdfs.protocol.Block"/>
    </method>
    <method name="equals" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="o" type="java.lang.Object"/>
    </method>
    <method name="hashCode" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <field name="BLOCK_FILE_PREFIX" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="METADATA_EXTENSION" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="blockFilePattern" type="java.util.regex.Pattern"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="metaFilePattern" type="java.util.regex.Pattern"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <doc>
    <![CDATA[A Block is a Hadoop FS primitive, identified by a 
 long.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.protocol.Block -->
  <!-- start class org.apache.hadoop.hdfs.protocol.BlockListAsLongs -->
  <class name="BlockListAsLongs" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <implements name="java.lang.Iterable"/>
    <constructor name="BlockListAsLongs" type="java.util.List, java.util.List"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Create block report from finalized and under construction lists of blocks.
 
 @param finalized - list of finalized blocks
 @param uc - list of under construction blocks]]>
      </doc>
    </constructor>
    <constructor name="BlockListAsLongs"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <constructor name="BlockListAsLongs" type="long[]"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Constructor
 @param iBlockList - BlockListALongs create from this long[] parameter]]>
      </doc>
    </constructor>
    <method name="getBlockListAsLongs" return="long[]"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="iterator" return="java.util.Iterator"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Returns an iterator over blocks in the block report.]]>
      </doc>
    </method>
    <method name="getBlockReportIterator" return="org.apache.hadoop.hdfs.protocol.BlockListAsLongs.BlockReportIterator"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Returns {@link BlockReportIterator}.]]>
      </doc>
    </method>
    <method name="getNumberOfBlocks" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[The number of blocks
 @return - the number of blocks]]>
      </doc>
    </method>
    <method name="getBlockId" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="index" type="int"/>
      <doc>
      <![CDATA[The block-id of the indexTh block
 @param index - the block whose block-id is desired
 @return the block-id]]>
      </doc>
    </method>
    <method name="getBlockLen" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="index" type="int"/>
      <doc>
      <![CDATA[The block-len of the indexTh block
 @param index - the block whose block-len is desired
 @return - the block-len]]>
      </doc>
    </method>
    <method name="getBlockGenStamp" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="index" type="int"/>
      <doc>
      <![CDATA[The generation stamp of the indexTh block
 @param index - the block whose block-len is desired
 @return - the generation stamp]]>
      </doc>
    </method>
    <doc>
    <![CDATA[This class provides an interface for accessing list of blocks that
 has been implemented as long[].
 This class is useful for block report. Rather than send block reports
 as a Block[] we can send it as a long[].

 The structure of the array is as follows:
 0: the length of the finalized replica list;
 1: the length of the under-construction replica list;
 - followed by finalized replica list where each replica is represented by
   3 longs: one for the blockId, one for the block length, and one for
   the generation stamp;
 - followed by the invalid replica represented with three -1s;
 - followed by the under-construction replica list where each replica is
   represented by 4 longs: three for the block id, length, generation 
   stamp, and the forth for the replica state.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.protocol.BlockListAsLongs -->
  <!-- start class org.apache.hadoop.hdfs.protocol.BlockListAsLongs.BlockReportIterator -->
  <class name="BlockListAsLongs.BlockReportIterator" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <implements name="java.util.Iterator"/>
    <method name="hasNext" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="next" return="org.apache.hadoop.hdfs.protocol.Block"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="remove"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getCurrentReplicaState" return="org.apache.hadoop.hdfs.server.common.HdfsConstants.ReplicaState"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Get the state of the current replica.
 The state corresponds to the replica returned
 by the latest {@link #next()}.]]>
      </doc>
    </method>
    <doc>
    <![CDATA[Iterates over blocks in the block report.
 Avoids object allocation on each iteration.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.protocol.BlockListAsLongs.BlockReportIterator -->
  <!-- start interface org.apache.hadoop.hdfs.protocol.ClientDatanodeProtocol -->
  <interface name="ClientDatanodeProtocol"    abstract="true"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <implements name="org.apache.hadoop.ipc.VersionedProtocol"/>
    <method name="getReplicaVisibleLength" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="b" type="org.apache.hadoop.hdfs.protocol.Block"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Return the visible length of a replica.]]>
      </doc>
    </method>
    <field name="LOG" type="org.apache.commons.logging.Log"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="versionID" type="long"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[6: recoverBlock() removed.]]>
      </doc>
    </field>
    <doc>
    <![CDATA[An client-datanode protocol for block recovery]]>
    </doc>
  </interface>
  <!-- end interface org.apache.hadoop.hdfs.protocol.ClientDatanodeProtocol -->
  <!-- start interface org.apache.hadoop.hdfs.protocol.ClientProtocol -->
  <interface name="ClientProtocol"    abstract="true"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <implements name="org.apache.hadoop.ipc.VersionedProtocol"/>
    <method name="getBlockLocations" return="org.apache.hadoop.hdfs.protocol.LocatedBlocks"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="java.lang.String"/>
      <param name="offset" type="long"/>
      <param name="length" type="long"/>
      <exception name="AccessControlException" type="org.apache.hadoop.security.AccessControlException"/>
      <exception name="FileNotFoundException" type="java.io.FileNotFoundException"/>
      <exception name="UnresolvedLinkException" type="org.apache.hadoop.fs.UnresolvedLinkException"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Get locations of the blocks of the specified file within the specified range.
 DataNode locations for each block are sorted by
 the proximity to the client.
 <p>
 Return {@link LocatedBlocks} which contains
 file length, blocks and their locations.
 DataNode locations for each block are sorted by
 the distance to the client's address.
 <p>
 The client will then have to contact 
 one of the indicated DataNodes to obtain the actual data.
 
 @param src file name
 @param offset range start offset
 @param length range length

 @return file length and array of blocks with their locations

 @throws AccessControlException If access is denied
 @throws FileNotFoundException If file <code>src</code> does not exist
 @throws UnresolvedLinkException If <code>src</code> contains a symlink
 @throws IOException If an I/O error occurred]]>
      </doc>
    </method>
    <method name="getServerDefaults" return="org.apache.hadoop.fs.FsServerDefaults"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Get server default values for a number of configuration params.
 @return a set of server default configuration values
 @throws IOException]]>
      </doc>
    </method>
    <method name="create"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="java.lang.String"/>
      <param name="masked" type="org.apache.hadoop.fs.permission.FsPermission"/>
      <param name="clientName" type="java.lang.String"/>
      <param name="flag" type="org.apache.hadoop.io.EnumSetWritable"/>
      <param name="createParent" type="boolean"/>
      <param name="replication" type="short"/>
      <param name="blockSize" type="long"/>
      <exception name="AccessControlException" type="org.apache.hadoop.security.AccessControlException"/>
      <exception name="AlreadyBeingCreatedException" type="org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException"/>
      <exception name="DSQuotaExceededException" type="org.apache.hadoop.hdfs.protocol.DSQuotaExceededException"/>
      <exception name="FileAlreadyExistsException" type="org.apache.hadoop.fs.FileAlreadyExistsException"/>
      <exception name="FileNotFoundException" type="java.io.FileNotFoundException"/>
      <exception name="NSQuotaExceededException" type="org.apache.hadoop.hdfs.protocol.NSQuotaExceededException"/>
      <exception name="ParentNotDirectoryException" type="org.apache.hadoop.fs.ParentNotDirectoryException"/>
      <exception name="SafeModeException" type="org.apache.hadoop.hdfs.server.namenode.SafeModeException"/>
      <exception name="UnresolvedLinkException" type="org.apache.hadoop.fs.UnresolvedLinkException"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Create a new file entry in the namespace.
 <p>
 This will create an empty file specified by the source path.
 The path should reflect a full path originated at the root.
 The name-node does not have a notion of "current" directory for a client.
 <p>
 Once created, the file is visible and available for read to other clients.
 Although, other clients cannot {@link #delete(String, boolean)}, re-create or 
 {@link #rename(String, String)} it until the file is completed
 or explicitly as a result of lease expiration.
 <p>
 Blocks have a maximum size.  Clients that intend to create
 multi-block files must also use 
 {@link #addBlock(String, String, Block, DatanodeInfo[])}

 @param src path of the file being created.
 @param masked masked permission.
 @param clientName name of the current client.
 @param flag indicates whether the file should be 
 overwritten if it already exists or create if it does not exist or append.
 @param createParent create missing parent directory if true
 @param replication block replication factor.
 @param blockSize maximum block size.
 
 @throws AccessControlException If access is denied
 @throws AlreadyBeingCreatedException if the path does not exist.
 @throws DSQuotaExceededException If file creation violates disk space 
           quota restriction
 @throws FileAlreadyExistsException If file <code>src</code> already exists
 @throws FileNotFoundException If parent of <code>src</code> does not exist
           and <code>createParent</code> is false
 @throws ParentNotDirectoryException If parent of <code>src</code> is not a
           directory.
 @throws NSQuotaExceededException If file creation violates name space 
           quota restriction
 @throws SafeModeException create not allowed in safemode
 @throws UnresolvedLinkException If <code>src</code> contains a symlink
 @throws IOException If an I/O error occurred

 RuntimeExceptions:
 @throws InvalidPathException Path <code>src</code> is invalid]]>
      </doc>
    </method>
    <method name="append" return="org.apache.hadoop.hdfs.protocol.LocatedBlock"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="java.lang.String"/>
      <param name="clientName" type="java.lang.String"/>
      <exception name="AccessControlException" type="org.apache.hadoop.security.AccessControlException"/>
      <exception name="DSQuotaExceededException" type="org.apache.hadoop.hdfs.protocol.DSQuotaExceededException"/>
      <exception name="FileNotFoundException" type="java.io.FileNotFoundException"/>
      <exception name="SafeModeException" type="org.apache.hadoop.hdfs.server.namenode.SafeModeException"/>
      <exception name="UnresolvedLinkException" type="org.apache.hadoop.fs.UnresolvedLinkException"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Append to the end of the file. 
 @param src path of the file being created.
 @param clientName name of the current client.
 @return information about the last partial block if any.
 @throws AccessControlException if permission to append file is 
 denied by the system. As usually on the client side the exception will 
 be wrapped into {@link org.apache.hadoop.ipc.RemoteException}.
 Allows appending to an existing file if the server is
 configured with the parameter dfs.support.append set to true, otherwise
 throws an IOException.
 
 @throws AccessControlException If permission to append to file is denied
 @throws FileNotFoundException If file <code>src</code> is not found
 @throws DSQuotaExceededException If append violates disk space quota 
           restriction
 @throws SafeModeException append not allowed in safemode
 @throws UnresolvedLinkException If <code>src</code> contains a symlink
 @throws IOException If an I/O error occurred.

 RuntimeExceptions:
 @throws UnsupportedOperationException if append is not supported]]>
      </doc>
    </method>
    <method name="setReplication" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="java.lang.String"/>
      <param name="replication" type="short"/>
      <exception name="AccessControlException" type="org.apache.hadoop.security.AccessControlException"/>
      <exception name="DSQuotaExceededException" type="org.apache.hadoop.hdfs.protocol.DSQuotaExceededException"/>
      <exception name="FileNotFoundException" type="java.io.FileNotFoundException"/>
      <exception name="SafeModeException" type="org.apache.hadoop.hdfs.server.namenode.SafeModeException"/>
      <exception name="UnresolvedLinkException" type="org.apache.hadoop.fs.UnresolvedLinkException"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Set replication for an existing file.
 <p>
 The NameNode sets replication to the new value and returns.
 The actual block replication is not expected to be performed during  
 this method call. The blocks will be populated or removed in the 
 background as the result of the routine block maintenance procedures.
 
 @param src file name
 @param replication new replication
 
 @return true if successful;
         false if file does not exist or is a directory

 @throws AccessControlException If access is denied
 @throws DSQuotaExceededException If replication violates disk space 
           quota restriction
 @throws FileNotFoundException If file <code>src</code> is not found
 @throws SafeModeException not allowed in safemode
 @throws UnresolvedLinkException if <code>src</code> contains a symlink
 @throws IOException If an I/O error occurred]]>
      </doc>
    </method>
    <method name="setPermission"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="java.lang.String"/>
      <param name="permission" type="org.apache.hadoop.fs.permission.FsPermission"/>
      <exception name="AccessControlException" type="org.apache.hadoop.security.AccessControlException"/>
      <exception name="FileNotFoundException" type="java.io.FileNotFoundException"/>
      <exception name="SafeModeException" type="org.apache.hadoop.hdfs.server.namenode.SafeModeException"/>
      <exception name="UnresolvedLinkException" type="org.apache.hadoop.fs.UnresolvedLinkException"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Set permissions for an existing file/directory.
 
 @throws AccessControlException If access is denied
 @throws FileNotFoundException If file <code>src</code> is not found
 @throws SafeModeException not allowed in safemode
 @throws UnresolvedLinkException If <code>src</code> contains a symlink
 @throws IOException If an I/O error occurred]]>
      </doc>
    </method>
    <method name="setOwner"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="java.lang.String"/>
      <param name="username" type="java.lang.String"/>
      <param name="groupname" type="java.lang.String"/>
      <exception name="AccessControlException" type="org.apache.hadoop.security.AccessControlException"/>
      <exception name="FileNotFoundException" type="java.io.FileNotFoundException"/>
      <exception name="SafeModeException" type="org.apache.hadoop.hdfs.server.namenode.SafeModeException"/>
      <exception name="UnresolvedLinkException" type="org.apache.hadoop.fs.UnresolvedLinkException"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Set Owner of a path (i.e. a file or a directory).
 The parameters username and groupname cannot both be null.
 @param src
 @param username If it is null, the original username remains unchanged.
 @param groupname If it is null, the original groupname remains unchanged.

 @throws AccessControlException If access is denied
 @throws FileNotFoundException If file <code>src</code> is not found
 @throws SafeModeException not allowed in safemode
 @throws UnresolvedLinkException If <code>src</code> contains a symlink
 @throws IOException If an I/O error occurred]]>
      </doc>
    </method>
    <method name="abandonBlock"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="b" type="org.apache.hadoop.hdfs.protocol.Block"/>
      <param name="src" type="java.lang.String"/>
      <param name="holder" type="java.lang.String"/>
      <exception name="AccessControlException" type="org.apache.hadoop.security.AccessControlException"/>
      <exception name="FileNotFoundException" type="java.io.FileNotFoundException"/>
      <exception name="UnresolvedLinkException" type="org.apache.hadoop.fs.UnresolvedLinkException"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[The client can give up on a blcok by calling abandonBlock().
 The client can then
 either obtain a new block, or complete or abandon the file.
 Any partial writes to the block will be discarded.
 
 @throws AccessControlException If access is denied
 @throws FileNotFoundException file <code>src</code> is not found
 @throws UnresolvedLinkException If <code>src</code> contains a symlink
 @throws IOException If an I/O error occurred]]>
      </doc>
    </method>
    <method name="addBlock" return="org.apache.hadoop.hdfs.protocol.LocatedBlock"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="java.lang.String"/>
      <param name="clientName" type="java.lang.String"/>
      <param name="previous" type="org.apache.hadoop.hdfs.protocol.Block"/>
      <param name="excludeNodes" type="org.apache.hadoop.hdfs.protocol.DatanodeInfo[]"/>
      <exception name="AccessControlException" type="org.apache.hadoop.security.AccessControlException"/>
      <exception name="FileNotFoundException" type="java.io.FileNotFoundException"/>
      <exception name="NotReplicatedYetException" type="org.apache.hadoop.hdfs.server.namenode.NotReplicatedYetException"/>
      <exception name="SafeModeException" type="org.apache.hadoop.hdfs.server.namenode.SafeModeException"/>
      <exception name="UnresolvedLinkException" type="org.apache.hadoop.fs.UnresolvedLinkException"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[A client that wants to write an additional block to the 
 indicated filename (which must currently be open for writing)
 should call addBlock().  

 addBlock() allocates a new block and datanodes the block data
 should be replicated to.
 
 addBlock() also commits the previous block by reporting
 to the name-node the actual generation stamp and the length
 of the block that the client has transmitted to data-nodes.

 @param src the file being created
 @param clientName the name of the client that adds the block
 @param previous  previous block
 @param excludeNodes a list of nodes that should not be
 allocated for the current block

 @return LocatedBlock allocated block information.

 @throws AccessControlException If access is denied
 @throws FileNotFoundException If file <code>src</code> is not found
 @throws NotReplicatedYetException previous blocks of the file are not
           replicated yet. Blocks cannot be added until replication
           completes.
 @throws SafeModeException create not allowed in safemode
 @throws UnresolvedLinkException If <code>src</code> contains a symlink
 @throws IOException If an I/O error occurred]]>
      </doc>
    </method>
    <method name="complete" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="java.lang.String"/>
      <param name="clientName" type="java.lang.String"/>
      <param name="last" type="org.apache.hadoop.hdfs.protocol.Block"/>
      <exception name="AccessControlException" type="org.apache.hadoop.security.AccessControlException"/>
      <exception name="FileNotFoundException" type="java.io.FileNotFoundException"/>
      <exception name="SafeModeException" type="org.apache.hadoop.hdfs.server.namenode.SafeModeException"/>
      <exception name="UnresolvedLinkException" type="org.apache.hadoop.fs.UnresolvedLinkException"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[The client is done writing data to the given filename, and would 
 like to complete it.  

 The function returns whether the file has been closed successfully.
 If the function returns false, the caller should try again.
 
 close() also commits the last block of the file by reporting
 to the name-node the actual generation stamp and the length
 of the block that the client has transmitted to data-nodes.

 A call to complete() will not return true until all the file's
 blocks have been replicated the minimum number of times.  Thus,
 DataNode failures may cause a client to call complete() several
 times before succeeding.

 @throws AccessControlException If access is denied
 @throws FileNotFoundException If file <code>src</code> is not found
 @throws SafeModeException create not allowed in safemode
 @throws UnresolvedLinkException If <code>src</code> contains a symlink 
 @throws IOException If an I/O error occurred]]>
      </doc>
    </method>
    <method name="reportBadBlocks"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="blocks" type="org.apache.hadoop.hdfs.protocol.LocatedBlock[]"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[The client wants to report corrupted blocks (blocks with specified
 locations on datanodes).
 @param blocks Array of located blocks to report]]>
      </doc>
    </method>
    <method name="rename" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="Use {@link #rename(String, String, Options.Rename...)} instead.">
      <param name="src" type="java.lang.String"/>
      <param name="dst" type="java.lang.String"/>
      <exception name="UnresolvedLinkException" type="org.apache.hadoop.fs.UnresolvedLinkException"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Rename an item in the file system namespace.
 @param src existing file or directory name.
 @param dst new name.
 @return true if successful, or false if the old name does not exist
 or if the new name already belongs to the namespace.
 
 @throws IOException an I/O error occurred
 
 @deprecated Use {@link #rename(String, String, Options.Rename...)} instead.]]>
      </doc>
    </method>
    <method name="concat"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="trg" type="java.lang.String"/>
      <param name="srcs" type="java.lang.String[]"/>
      <exception name="IOException" type="java.io.IOException"/>
      <exception name="UnresolvedLinkException" type="org.apache.hadoop.fs.UnresolvedLinkException"/>
      <doc>
      <![CDATA[Moves blocks from srcs to trg and delete srcs
 
 @param trg existing file
 @param srcs - list of existing files (same block size, same replication)
 @throws IOException if some arguments are invalid
 @throws UnresolvedLinkException if <code>trg</code> or <code>srcs</code>
           contains a symlink]]>
      </doc>
    </method>
    <method name="rename"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="java.lang.String"/>
      <param name="dst" type="java.lang.String"/>
      <param name="options" type="org.apache.hadoop.fs.Options.Rename[]"/>
      <exception name="AccessControlException" type="org.apache.hadoop.security.AccessControlException"/>
      <exception name="DSQuotaExceededException" type="org.apache.hadoop.hdfs.protocol.DSQuotaExceededException"/>
      <exception name="FileAlreadyExistsException" type="org.apache.hadoop.fs.FileAlreadyExistsException"/>
      <exception name="FileNotFoundException" type="java.io.FileNotFoundException"/>
      <exception name="NSQuotaExceededException" type="org.apache.hadoop.hdfs.protocol.NSQuotaExceededException"/>
      <exception name="ParentNotDirectoryException" type="org.apache.hadoop.fs.ParentNotDirectoryException"/>
      <exception name="SafeModeException" type="org.apache.hadoop.hdfs.server.namenode.SafeModeException"/>
      <exception name="UnresolvedLinkException" type="org.apache.hadoop.fs.UnresolvedLinkException"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Rename src to dst.
 <ul>
 <li>Fails if src is a file and dst is a directory.
 <li>Fails if src is a directory and dst is a file.
 <li>Fails if the parent of dst does not exist or is a file.
 </ul>
 <p>
 Without OVERWRITE option, rename fails if the dst already exists.
 With OVERWRITE option, rename overwrites the dst, if it is a file 
 or an empty directory. Rename fails if dst is a non-empty directory.
 <p>
 This implementation of rename is atomic.
 <p>
 @param src existing file or directory name.
 @param dst new name.
 @param options Rename options
 
 @throws AccessControlException If access is denied
 @throws DSQuotaExceededException If rename violates disk space 
           quota restriction
 @throws FileAlreadyExistsException If <code>dst</code> already exists and
           <code>options</options> has {@link Rename#OVERWRITE} option
           false.
 @throws FileNotFoundException If <code>src</code> does not exist
 @throws NSQuotaExceededException If rename violates namespace 
           quota restriction
 @throws ParentNotDirectoryException If parent of <code>dst</code> 
           is not a directory
 @throws SafeModeException rename not allowed in safemode
 @throws UnresolvedLinkException If <code>src</code> or
           <code>dst</code> contains a symlink
 @throws IOException If an I/O error occurred]]>
      </doc>
    </method>
    <method name="delete" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="use {@link #delete(String, boolean)} istead.">
      <param name="src" type="java.lang.String"/>
      <exception name="IOException" type="java.io.IOException"/>
      <exception name="UnresolvedLinkException" type="org.apache.hadoop.fs.UnresolvedLinkException"/>
      <doc>
      <![CDATA[Delete the given file or directory from the file system.
 <p>
 Any blocks belonging to the deleted files will be garbage-collected.
 
 @param src existing name.
 @return true only if the existing file or directory was actually removed 
 from the file system. 
 @throws UnresolvedLinkException if <code>src</code> contains a symlink. 
 @deprecated use {@link #delete(String, boolean)} istead.]]>
      </doc>
    </method>
    <method name="delete" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="java.lang.String"/>
      <param name="recursive" type="boolean"/>
      <exception name="AccessControlException" type="org.apache.hadoop.security.AccessControlException"/>
      <exception name="FileNotFoundException" type="java.io.FileNotFoundException"/>
      <exception name="SafeModeException" type="org.apache.hadoop.hdfs.server.namenode.SafeModeException"/>
      <exception name="UnresolvedLinkException" type="org.apache.hadoop.fs.UnresolvedLinkException"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Delete the given file or directory from the file system.
 <p>
 same as delete but provides a way to avoid accidentally 
 deleting non empty directories programmatically. 
 @param src existing name
 @param recursive if true deletes a non empty directory recursively,
 else throws an exception.
 @return true only if the existing file or directory was actually removed 
 from the file system.
 
 @throws AccessControlException If access is denied
 @throws FileNotFoundException If file <code>src</code> is not found
 @throws SafeModeException create not allowed in safemode
 @throws UnresolvedLinkException If <code>src</code> contains a symlink
 @throws IOException If an I/O error occurred]]>
      </doc>
    </method>
    <method name="mkdirs" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="java.lang.String"/>
      <param name="masked" type="org.apache.hadoop.fs.permission.FsPermission"/>
      <param name="createParent" type="boolean"/>
      <exception name="AccessControlException" type="org.apache.hadoop.security.AccessControlException"/>
      <exception name="FileAlreadyExistsException" type="org.apache.hadoop.fs.FileAlreadyExistsException"/>
      <exception name="FileNotFoundException" type="java.io.FileNotFoundException"/>
      <exception name="NSQuotaExceededException" type="org.apache.hadoop.hdfs.protocol.NSQuotaExceededException"/>
      <exception name="ParentNotDirectoryException" type="org.apache.hadoop.fs.ParentNotDirectoryException"/>
      <exception name="SafeModeException" type="org.apache.hadoop.hdfs.server.namenode.SafeModeException"/>
      <exception name="UnresolvedLinkException" type="org.apache.hadoop.fs.UnresolvedLinkException"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Create a directory (or hierarchy of directories) with the given
 name and permission.

 @param src The path of the directory being created
 @param masked The masked permission of the directory being created
 @param createParent create missing parent directory if true

 @return True if the operation success.

 @throws AccessControlException If access is denied
 @throws FileAlreadyExistsException If <code>src</code> already exists
 @throws FileNotFoundException If parent of <code>src</code> does not exist
           and <code>createParent</code> is false
 @throws NSQuotaExceededException If file creation violates quota restriction
 @throws ParentNotDirectoryException If parent of <code>src</code> 
           is not a directory
 @throws SafeModeException create not allowed in safemode
 @throws UnresolvedLinkException If <code>src</code> contains a symlink
 @throws IOException If an I/O error occurred.

 RunTimeExceptions:
 @throws InvalidPathException If <code>src</code> is invalid]]>
      </doc>
    </method>
    <method name="getListing" return="org.apache.hadoop.hdfs.protocol.DirectoryListing"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="java.lang.String"/>
      <param name="startAfter" type="byte[]"/>
      <param name="needLocation" type="boolean"/>
      <exception name="AccessControlException" type="org.apache.hadoop.security.AccessControlException"/>
      <exception name="FileNotFoundException" type="java.io.FileNotFoundException"/>
      <exception name="UnresolvedLinkException" type="org.apache.hadoop.fs.UnresolvedLinkException"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Get a partial listing of the indicated directory

 @param src the directory name
 @param startAfter the name to start listing after encoded in java UTF8
 @param needLocation if the FileStatus should contain block locations

 @return a partial listing starting after startAfter

 @throws AccessControlException permission denied
 @throws FileNotFoundException file <code>src</code> is not found
 @throws UnresolvedLinkException If <code>src</code> contains a symlink
 @throws IOException If an I/O error occurred]]>
      </doc>
    </method>
    <method name="renewLease"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="clientName" type="java.lang.String"/>
      <exception name="AccessControlException" type="org.apache.hadoop.security.AccessControlException"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Client programs can cause stateful changes in the NameNode
 that affect other clients.  A client may obtain a file and 
 neither abandon nor complete it.  A client might hold a series
 of locks that prevent other clients from proceeding.
 Clearly, it would be bad if a client held a bunch of locks
 that it never gave up.  This can happen easily if the client
 dies unexpectedly.
 <p>
 So, the NameNode will revoke the locks and live file-creates
 for clients that it thinks have died.  A client tells the
 NameNode that it is still alive by periodically calling
 renewLease().  If a certain amount of time passes since
 the last call to renewLease(), the NameNode assumes the
 client has died.

 @throws AccessControlException permission denied
 @throws IOException If an I/O error occurred]]>
      </doc>
    </method>
    <method name="recoverLease" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="java.lang.String"/>
      <param name="clientName" type="java.lang.String"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Start lease recovery.
 Lightweight NameNode operation to trigger lease recovery
 
 @param src path of the file to start lease recovery
 @param clientName name of the current client
 @return true if the file is already closed
 @throws IOException]]>
      </doc>
    </method>
    <method name="getStats" return="long[]"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Get a set of statistics about the filesystem.
 Right now, only three values are returned.
 <ul>
 <li> [0] contains the total storage capacity of the system, in bytes.</li>
 <li> [1] contains the total used space of the system, in bytes.</li>
 <li> [2] contains the available storage of the system, in bytes.</li>
 <li> [3] contains number of under replicated blocks in the system.</li>
 <li> [4] contains number of blocks with a corrupt replica. </li>
 <li> [5] contains number of blocks without any good replicas left. </li>
 </ul>
 Use public constants like {@link #GET_STATS_CAPACITY_IDX} in place of 
 actual numbers to index into the array.]]>
      </doc>
    </method>
    <method name="getDatanodeReport" return="org.apache.hadoop.hdfs.protocol.DatanodeInfo[]"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="type" type="org.apache.hadoop.hdfs.protocol.FSConstants.DatanodeReportType"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Get a report on the system's current datanodes.
 One DatanodeInfo object is returned for each DataNode.
 Return live datanodes if type is LIVE; dead datanodes if type is DEAD;
 otherwise all datanodes if type is ALL.]]>
      </doc>
    </method>
    <method name="getPreferredBlockSize" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="filename" type="java.lang.String"/>
      <exception name="IOException" type="java.io.IOException"/>
      <exception name="UnresolvedLinkException" type="org.apache.hadoop.fs.UnresolvedLinkException"/>
      <doc>
      <![CDATA[Get the block size for the given file.
 @param filename The name of the file
 @return The number of bytes in each block
 @throws IOException
 @throws UnresolvedLinkException if the path contains a symlink.]]>
      </doc>
    </method>
    <method name="setSafeMode" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="action" type="org.apache.hadoop.hdfs.protocol.FSConstants.SafeModeAction"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Enter, leave or get safe mode.
 <p>
 Safe mode is a name node state when it
 <ol><li>does not accept changes to name space (read-only), and</li>
 <li>does not replicate or delete blocks.</li></ol>
 
 <p>
 Safe mode is entered automatically at name node startup.
 Safe mode can also be entered manually using
 {@link #setSafeMode(FSConstants.SafeModeAction) setSafeMode(SafeModeAction.SAFEMODE_GET)}.
 <p>
 At startup the name node accepts data node reports collecting
 information about block locations.
 In order to leave safe mode it needs to collect a configurable
 percentage called threshold of blocks, which satisfy the minimal 
 replication condition.
 The minimal replication condition is that each block must have at least
 <tt>dfs.namenode.replication.min</tt> replicas.
 When the threshold is reached the name node extends safe mode
 for a configurable amount of time
 to let the remaining data nodes to check in before it
 will start replicating missing blocks.
 Then the name node leaves safe mode.
 <p>
 If safe mode is turned on manually using
 {@link #setSafeMode(FSConstants.SafeModeAction) setSafeMode(SafeModeAction.SAFEMODE_ENTER)}
 then the name node stays in safe mode until it is manually turned off
 using {@link #setSafeMode(FSConstants.SafeModeAction) setSafeMode(SafeModeAction.SAFEMODE_LEAVE)}.
 Current state of the name node can be verified using
 {@link #setSafeMode(FSConstants.SafeModeAction) setSafeMode(SafeModeAction.SAFEMODE_GET)}
 <h4>Configuration parameters:</h4>
 <tt>dfs.safemode.threshold.pct</tt> is the threshold parameter.<br>
 <tt>dfs.safemode.extension</tt> is the safe mode extension parameter.<br>
 <tt>dfs.namenode.replication.min</tt> is the minimal replication parameter.
 
 <h4>Special cases:</h4>
 The name node does not enter safe mode at startup if the threshold is 
 set to 0 or if the name space is empty.<br>
 If the threshold is set to 1 then all blocks need to have at least 
 minimal replication.<br>
 If the threshold value is greater than 1 then the name node will not be 
 able to turn off safe mode automatically.<br>
 Safe mode can always be turned off manually.
 
 @param action  <ul> <li>0 leave safe mode;</li>
                <li>1 enter safe mode;</li>
                <li>2 get safe mode state.</li></ul>
 @return <ul><li>0 if the safe mode is OFF or</li> 
         <li>1 if the safe mode is ON.</li></ul>
                   
 @throws IOException]]>
      </doc>
    </method>
    <method name="saveNamespace"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="AccessControlException" type="org.apache.hadoop.security.AccessControlException"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Save namespace image.
 <p>
 Saves current namespace into storage directories and reset edits log.
 Requires superuser privilege and safe mode.
 
 @throws AccessControlException if the superuser privilege is violated.
 @throws IOException if image creation failed.]]>
      </doc>
    </method>
    <method name="restoreFailedStorage" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="arg" type="java.lang.String"/>
      <exception name="AccessControlException" type="org.apache.hadoop.security.AccessControlException"/>
      <doc>
      <![CDATA[Enable/Disable restore failed storage.
 <p>
 sets flag to enable restore of failed storage replicas
 
 @throws AccessControlException if the superuser privilege is violated.]]>
      </doc>
    </method>
    <method name="refreshNodes"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Tells the namenode to reread the hosts and exclude files. 
 @throws IOException]]>
      </doc>
    </method>
    <method name="finalizeUpgrade"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Finalize previous upgrade.
 Remove file system state saved during the upgrade.
 The upgrade will become irreversible.
 
 @throws IOException]]>
      </doc>
    </method>
    <method name="distributedUpgradeProgress" return="org.apache.hadoop.hdfs.server.common.UpgradeStatusReport"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="action" type="org.apache.hadoop.hdfs.protocol.FSConstants.UpgradeAction"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Report distributed upgrade progress or force current upgrade to proceed.
 
 @param action {@link FSConstants.UpgradeAction} to perform
 @return upgrade status information or null if no upgrades are in progress
 @throws IOException]]>
      </doc>
    </method>
    <method name="metaSave"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="filename" type="java.lang.String"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Dumps namenode data structures into specified file. If the file
 already exists, then append.

 @throws IOException]]>
      </doc>
    </method>
    <method name="getFileInfo" return="org.apache.hadoop.hdfs.protocol.HdfsFileStatus"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="java.lang.String"/>
      <exception name="AccessControlException" type="org.apache.hadoop.security.AccessControlException"/>
      <exception name="FileNotFoundException" type="java.io.FileNotFoundException"/>
      <exception name="UnresolvedLinkException" type="org.apache.hadoop.fs.UnresolvedLinkException"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Get the file info for a specific file or directory.
 @param src The string representation of the path to the file

 @return object containing information regarding the file
         or null if file not found
 @throws AccessControlException permission denied
 @throws FileNotFoundException file <code>src</code> is not found
 @throws UnresolvedLinkException if the path contains a symlink. 
 @throws IOException If an I/O error occurred]]>
      </doc>
    </method>
    <method name="getFileLinkInfo" return="org.apache.hadoop.hdfs.protocol.HdfsFileStatus"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="java.lang.String"/>
      <exception name="AccessControlException" type="org.apache.hadoop.security.AccessControlException"/>
      <exception name="UnresolvedLinkException" type="org.apache.hadoop.fs.UnresolvedLinkException"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Get the file info for a specific file or directory. If the path 
 refers to a symlink then the FileStatus of the symlink is returned.
 @param src The string representation of the path to the file

 @return object containing information regarding the file
         or null if file not found

 @throws AccessControlException permission denied
 @throws UnresolvedLinkException if <code>src</code> contains a symlink
 @throws IOException If an I/O error occurred]]>
      </doc>
    </method>
    <method name="getContentSummary" return="org.apache.hadoop.fs.ContentSummary"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="path" type="java.lang.String"/>
      <exception name="AccessControlException" type="org.apache.hadoop.security.AccessControlException"/>
      <exception name="FileNotFoundException" type="java.io.FileNotFoundException"/>
      <exception name="UnresolvedLinkException" type="org.apache.hadoop.fs.UnresolvedLinkException"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Get {@link ContentSummary} rooted at the specified directory.
 @param path The string representation of the path

 @throws AccessControlException permission denied
 @throws FileNotFoundException file <code>path</code> is not found
 @throws UnresolvedLinkException if <code>path</code> contains a symlink. 
 @throws IOException If an I/O error occurred]]>
      </doc>
    </method>
    <method name="setQuota"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="path" type="java.lang.String"/>
      <param name="namespaceQuota" type="long"/>
      <param name="diskspaceQuota" type="long"/>
      <exception name="AccessControlException" type="org.apache.hadoop.security.AccessControlException"/>
      <exception name="FileNotFoundException" type="java.io.FileNotFoundException"/>
      <exception name="UnresolvedLinkException" type="org.apache.hadoop.fs.UnresolvedLinkException"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Set the quota for a directory.
 @param path  The string representation of the path to the directory
 @param namespaceQuota Limit on the number of names in the tree rooted 
                       at the directory
 @param diskspaceQuota Limit on disk space occupied all the files under
                       this directory. 
 <br><br>
                       
 The quota can have three types of values : (1) 0 or more will set 
 the quota to that value, (2) {@link FSConstants#QUOTA_DONT_SET}  implies 
 the quota will not be changed, and (3) {@link FSConstants#QUOTA_RESET} 
 implies the quota will be reset. Any other value is a runtime error.
 
 @throws AccessControlException permission denied
 @throws FileNotFoundException file <code>path</code> is not found
 @throws QuotaExceededException if the directory size 
           is greater than the given quota
 @throws UnresolvedLinkException if the <code>path</code> contains a symlink. 
 @throws IOException If an I/O error occurred]]>
      </doc>
    </method>
    <method name="fsync"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="java.lang.String"/>
      <param name="client" type="java.lang.String"/>
      <exception name="AccessControlException" type="org.apache.hadoop.security.AccessControlException"/>
      <exception name="FileNotFoundException" type="java.io.FileNotFoundException"/>
      <exception name="UnresolvedLinkException" type="org.apache.hadoop.fs.UnresolvedLinkException"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Write all metadata for this file into persistent storage.
 The file must be currently open for writing.
 @param src The string representation of the path
 @param client The string representation of the client
 
 @throws AccessControlException permission denied
 @throws FileNotFoundException file <code>src</code> is not found
 @throws UnresolvedLinkException if <code>src</code> contains a symlink. 
 @throws IOException If an I/O error occurred]]>
      </doc>
    </method>
    <method name="setTimes"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="java.lang.String"/>
      <param name="mtime" type="long"/>
      <param name="atime" type="long"/>
      <exception name="AccessControlException" type="org.apache.hadoop.security.AccessControlException"/>
      <exception name="FileNotFoundException" type="java.io.FileNotFoundException"/>
      <exception name="UnresolvedLinkException" type="org.apache.hadoop.fs.UnresolvedLinkException"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Sets the modification and access time of the file to the specified time.
 @param src The string representation of the path
 @param mtime The number of milliseconds since Jan 1, 1970.
              Setting mtime to -1 means that modification time should not be set
              by this call.
 @param atime The number of milliseconds since Jan 1, 1970.
              Setting atime to -1 means that access time should not be set
              by this call.
              
 @throws AccessControlException permission denied
 @throws FileNotFoundException file <code>src</code> is not found
 @throws UnresolvedLinkException if <code>src</code> contains a symlink. 
 @throws IOException If an I/O error occurred]]>
      </doc>
    </method>
    <method name="createSymlink"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="target" type="java.lang.String"/>
      <param name="link" type="java.lang.String"/>
      <param name="dirPerm" type="org.apache.hadoop.fs.permission.FsPermission"/>
      <param name="createParent" type="boolean"/>
      <exception name="AccessControlException" type="org.apache.hadoop.security.AccessControlException"/>
      <exception name="FileAlreadyExistsException" type="org.apache.hadoop.fs.FileAlreadyExistsException"/>
      <exception name="FileNotFoundException" type="java.io.FileNotFoundException"/>
      <exception name="ParentNotDirectoryException" type="org.apache.hadoop.fs.ParentNotDirectoryException"/>
      <exception name="SafeModeException" type="org.apache.hadoop.hdfs.server.namenode.SafeModeException"/>
      <exception name="UnresolvedLinkException" type="org.apache.hadoop.fs.UnresolvedLinkException"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Create symlink to a file or directory.
 @param target The path of the destination that the
               link points to.
 @param link The path of the link being created.
 @param dirPerm permissions to use when creating parent directories
 @param createParent - if true then missing parent dirs are created
                       if false then parent must exist

 @throws AccessControlException permission denied
 @throws FileAlreadyExistsException If file <code>link</code> already exists
 @throws FileNotFoundException If parent of <code>link</code> does not exist
           and <code>createParent</code> is false
 @throws ParentNotDirectoryException If parent of <code>link</code> is not a
           directory.
 @throws UnresolvedLinkException if <code>link</target> contains a symlink. 
 @throws IOException If an I/O error occurred]]>
      </doc>
    </method>
    <method name="getLinkTarget" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="path" type="java.lang.String"/>
      <exception name="AccessControlException" type="org.apache.hadoop.security.AccessControlException"/>
      <exception name="FileNotFoundException" type="java.io.FileNotFoundException"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Return the target of the given symlink. If there is an intermediate
 symlink in the path (ie a symlink leading up to the final path component)
 then the given path is returned with this symlink resolved.

 @param path The path with a link that needs resolution.
 @return The path after resolving the first symbolic link in the path.
 @throws AccessControlException permission denied
 @throws FileNotFoundException If <code>path</code> does not exist
 @throws IOException If the given path does not refer to a symlink
           or an I/O error occurred]]>
      </doc>
    </method>
    <method name="updateBlockForPipeline" return="org.apache.hadoop.hdfs.protocol.LocatedBlock"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="block" type="org.apache.hadoop.hdfs.protocol.Block"/>
      <param name="clientName" type="java.lang.String"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Get a new generation stamp together with an access token for 
 a block under construction
 
 This method is called only when a client needs to recover a failed
 pipeline or set up a pipeline for appending to a block.
 
 @param block a block
 @param clientName the name of the client
 @return a located block with a new generation stamp and an access token
 @throws IOException if any error occurs]]>
      </doc>
    </method>
    <method name="updatePipeline"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="clientName" type="java.lang.String"/>
      <param name="oldBlock" type="org.apache.hadoop.hdfs.protocol.Block"/>
      <param name="newBlock" type="org.apache.hadoop.hdfs.protocol.Block"/>
      <param name="newNodes" type="org.apache.hadoop.hdfs.protocol.DatanodeID[]"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Update a pipeline for a block under construction
 
 @param clientName the name of the client
 @param oldBlock the old block
 @param newBlock the new block containing new generation stamp and length
 @param newNodes datanodes in the pipeline
 @throws IOException if any error occurs]]>
      </doc>
    </method>
    <method name="getDelegationToken" return="org.apache.hadoop.security.token.Token"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="renewer" type="org.apache.hadoop.io.Text"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Get a valid Delegation Token.
 
 @param renewer the designated renewer for the token
 @return Token<DelegationTokenIdentifier>
 @throws IOException]]>
      </doc>
    </method>
    <method name="renewDelegationToken" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="token" type="org.apache.hadoop.security.token.Token"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Renew an existing delegation token.
 
 @param token delegation token obtained earlier
 @return the new expiration time
 @throws IOException]]>
      </doc>
    </method>
    <method name="cancelDelegationToken"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="token" type="org.apache.hadoop.security.token.Token"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Cancel an existing delegation token.
 
 @param token delegation token
 @throws IOException]]>
      </doc>
    </method>
    <field name="versionID" type="long"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Compared to the previous version the following changes have been introduced:
 (Only the latest change is reflected.
 The log of historical changes can be retrieved from the svn).
 65: recoverLease return if the file is closed or not]]>
      </doc>
    </field>
    <field name="GET_STATS_CAPACITY_IDX" type="int"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="GET_STATS_USED_IDX" type="int"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="GET_STATS_REMAINING_IDX" type="int"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="GET_STATS_UNDER_REPLICATED_IDX" type="int"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="GET_STATS_CORRUPT_BLOCKS_IDX" type="int"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="GET_STATS_MISSING_BLOCKS_IDX" type="int"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <doc>
    <![CDATA[ClientProtocol is used by user code via 
 {@link org.apache.hadoop.hdfs.DistributedFileSystem} class to communicate 
 with the NameNode.  User code can manipulate the directory namespace, 
 as well as open/close file streams, etc.]]>
    </doc>
  </interface>
  <!-- end interface org.apache.hadoop.hdfs.protocol.ClientProtocol -->
  <!-- start class org.apache.hadoop.hdfs.protocol.DatanodeID -->
  <class name="DatanodeID" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <implements name="org.apache.hadoop.io.WritableComparable"/>
    <constructor name="DatanodeID"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Equivalent to DatanodeID("").]]>
      </doc>
    </constructor>
    <constructor name="DatanodeID" type="java.lang.String"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Equivalent to DatanodeID(nodeName, "", -1, -1).]]>
      </doc>
    </constructor>
    <constructor name="DatanodeID" type="org.apache.hadoop.hdfs.protocol.DatanodeID"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[DatanodeID copy constructor
 
 @param from]]>
      </doc>
    </constructor>
    <constructor name="DatanodeID" type="java.lang.String, java.lang.String, int, int"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Create DatanodeID
 @param nodeName (hostname:portNumber) 
 @param storageID data storage ID
 @param infoPort info server port 
 @param ipcPort ipc server port]]>
      </doc>
    </constructor>
    <method name="getName" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return hostname:portNumber.]]>
      </doc>
    </method>
    <method name="getStorageID" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return data storage ID.]]>
      </doc>
    </method>
    <method name="getInfoPort" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return infoPort (the port at which the HTTP server bound to)]]>
      </doc>
    </method>
    <method name="getIpcPort" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return ipcPort (the port at which the IPC server bound to)]]>
      </doc>
    </method>
    <method name="setStorageID"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="storageID" type="java.lang.String"/>
      <doc>
      <![CDATA[sets the data storage ID.]]>
      </doc>
    </method>
    <method name="getHost" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return hostname and no :portNumber.]]>
      </doc>
    </method>
    <method name="getPort" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="equals" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="to" type="java.lang.Object"/>
    </method>
    <method name="hashCode" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="toString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="updateRegInfo"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="nodeReg" type="org.apache.hadoop.hdfs.protocol.DatanodeID"/>
      <doc>
      <![CDATA[Update fields when a new registration request comes in.
 Note that this does not update storageID.]]>
      </doc>
    </method>
    <method name="compareTo" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="that" type="org.apache.hadoop.hdfs.protocol.DatanodeID"/>
      <doc>
      <![CDATA[Comparable.
 Basis of compare is the String name (host:portNumber) only.
 @param that
 @return as specified by Comparable.]]>
      </doc>
    </method>
    <method name="write"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="out" type="java.io.DataOutput"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[{@inheritDoc}]]>
      </doc>
    </method>
    <method name="readFields"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="in" type="java.io.DataInput"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[{@inheritDoc}]]>
      </doc>
    </method>
    <field name="EMPTY_ARRAY" type="org.apache.hadoop.hdfs.protocol.DatanodeID[]"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="name" type="java.lang.String"
      transient="false" volatile="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="storageID" type="java.lang.String"
      transient="false" volatile="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="infoPort" type="int"
      transient="false" volatile="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
    </field>
    <field name="ipcPort" type="int"
      transient="false" volatile="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </field>
    <doc>
    <![CDATA[DatanodeID is composed of the data node 
 name (hostname:portNumber) and the data storage ID, 
 which it currently represents.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.protocol.DatanodeID -->
  <!-- start class org.apache.hadoop.hdfs.protocol.DatanodeInfo -->
  <class name="DatanodeInfo" extends="org.apache.hadoop.hdfs.protocol.DatanodeID"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <implements name="org.apache.hadoop.net.Node"/>
    <constructor name="DatanodeInfo"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <constructor name="DatanodeInfo" type="org.apache.hadoop.hdfs.protocol.DatanodeInfo"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <constructor name="DatanodeInfo" type="org.apache.hadoop.hdfs.protocol.DatanodeID"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <constructor name="DatanodeInfo" type="org.apache.hadoop.hdfs.protocol.DatanodeID, java.lang.String, java.lang.String"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
    </constructor>
    <method name="getCapacity" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[The raw capacity.]]>
      </doc>
    </method>
    <method name="getDfsUsed" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[The used space by the data node.]]>
      </doc>
    </method>
    <method name="getNonDfsUsed" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[The used space by the data node.]]>
      </doc>
    </method>
    <method name="getDfsUsedPercent" return="float"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[The used space by the data node as percentage of present capacity]]>
      </doc>
    </method>
    <method name="getRemaining" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[The raw free space.]]>
      </doc>
    </method>
    <method name="getRemainingPercent" return="float"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[The remaining space as percentage of configured capacity.]]>
      </doc>
    </method>
    <method name="getLastUpdate" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[The time when this information was accurate.]]>
      </doc>
    </method>
    <method name="getXceiverCount" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[number of active connections]]>
      </doc>
    </method>
    <method name="setCapacity"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="capacity" type="long"/>
      <doc>
      <![CDATA[Sets raw capacity.]]>
      </doc>
    </method>
    <method name="setRemaining"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="remaining" type="long"/>
      <doc>
      <![CDATA[Sets raw free space.]]>
      </doc>
    </method>
    <method name="setLastUpdate"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="lastUpdate" type="long"/>
      <doc>
      <![CDATA[Sets time when this information was accurate.]]>
      </doc>
    </method>
    <method name="setXceiverCount"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="xceiverCount" type="int"/>
      <doc>
      <![CDATA[Sets number of active connections]]>
      </doc>
    </method>
    <method name="getNetworkLocation" return="java.lang.String"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[rack name]]>
      </doc>
    </method>
    <method name="setNetworkLocation"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="location" type="java.lang.String"/>
      <doc>
      <![CDATA[Sets the rack name]]>
      </doc>
    </method>
    <method name="getHostName" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="setHostName"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="host" type="java.lang.String"/>
    </method>
    <method name="getDatanodeReport" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[A formatted string for reporting the status of the DataNode.]]>
      </doc>
    </method>
    <method name="dumpDatanode" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[A formatted string for printing the status of the DataNode.]]>
      </doc>
    </method>
    <method name="startDecommission"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Start decommissioning a node.
 old state.]]>
      </doc>
    </method>
    <method name="stopDecommission"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Stop decommissioning a node.
 old state.]]>
      </doc>
    </method>
    <method name="isDecommissionInProgress" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Returns true if the node is in the process of being decommissioned]]>
      </doc>
    </method>
    <method name="isDecommissioned" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Returns true if the node has been decommissioned.]]>
      </doc>
    </method>
    <method name="setDecommissioned"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Sets the admin state to indicate that decommission is complete.]]>
      </doc>
    </method>
    <method name="setAdminState"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
      <param name="newState" type="org.apache.hadoop.hdfs.protocol.DatanodeInfo.AdminStates"/>
      <doc>
      <![CDATA[Sets the admin state of this node.]]>
      </doc>
    </method>
    <method name="getParent" return="org.apache.hadoop.net.Node"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Return this node's parent]]>
      </doc>
    </method>
    <method name="setParent"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="parent" type="org.apache.hadoop.net.Node"/>
    </method>
    <method name="getLevel" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Return this node's level in the tree.
 E.g. the root of a tree returns 0 and its children return 1]]>
      </doc>
    </method>
    <method name="setLevel"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="level" type="int"/>
    </method>
    <method name="write"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="out" type="java.io.DataOutput"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[{@inheritDoc}]]>
      </doc>
    </method>
    <method name="readFields"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="in" type="java.io.DataInput"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[{@inheritDoc}]]>
      </doc>
    </method>
    <method name="read" return="org.apache.hadoop.hdfs.protocol.DatanodeInfo"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="in" type="java.io.DataInput"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Read a DatanodeInfo]]>
      </doc>
    </method>
    <method name="hashCode" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="equals" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="obj" type="java.lang.Object"/>
    </method>
    <field name="capacity" type="long"
      transient="false" volatile="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
    </field>
    <field name="dfsUsed" type="long"
      transient="false" volatile="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
    </field>
    <field name="remaining" type="long"
      transient="false" volatile="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
    </field>
    <field name="lastUpdate" type="long"
      transient="false" volatile="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
    </field>
    <field name="xceiverCount" type="int"
      transient="false" volatile="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
    </field>
    <field name="location" type="java.lang.String"
      transient="false" volatile="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
    </field>
    <field name="hostName" type="java.lang.String"
      transient="false" volatile="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
      <doc>
      <![CDATA[HostName as supplied by the datanode during registration as its 
 name. Namenode uses datanode IP address as the name.]]>
      </doc>
    </field>
    <field name="adminState" type="org.apache.hadoop.hdfs.protocol.DatanodeInfo.AdminStates"
      transient="false" volatile="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
    </field>
    <doc>
    <![CDATA[DatanodeInfo represents the status of a DataNode.
 This object is used for communication in the
 Datanode Protocol and the Client Protocol.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.protocol.DatanodeInfo -->
  <!-- start class org.apache.hadoop.hdfs.protocol.DatanodeInfo.AdminStates -->
  <class name="DatanodeInfo.AdminStates" extends="java.lang.Enum"
    abstract="false"
    static="true" final="true" visibility="public"
    deprecated="not deprecated">
    <method name="values" return="org.apache.hadoop.hdfs.protocol.DatanodeInfo.AdminStates[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="valueOf" return="org.apache.hadoop.hdfs.protocol.DatanodeInfo.AdminStates"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="name" type="java.lang.String"/>
    </method>
    <field name="NORMAL" type="org.apache.hadoop.hdfs.protocol.DatanodeInfo.AdminStates"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DECOMMISSION_INPROGRESS" type="org.apache.hadoop.hdfs.protocol.DatanodeInfo.AdminStates"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DECOMMISSIONED" type="org.apache.hadoop.hdfs.protocol.DatanodeInfo.AdminStates"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
  </class>
  <!-- end class org.apache.hadoop.hdfs.protocol.DatanodeInfo.AdminStates -->
  <!-- start interface org.apache.hadoop.hdfs.protocol.DataTransferProtocol -->
  <interface name="DataTransferProtocol"    abstract="true"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <field name="DATA_TRANSFER_VERSION" type="int"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Version for data transfers between clients and datanodes
 This should change when serialization of DatanodeInfo, not just
 when protocol changes. It is not very obvious.]]>
      </doc>
    </field>
    <field name="OP_WRITE_BLOCK" type="byte"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="Deprecated at 0.21.  Use Op.WRITE_BLOCK instead.">
      <doc>
      <![CDATA[@deprecated Deprecated at 0.21.  Use Op.WRITE_BLOCK instead.]]>
      </doc>
    </field>
    <field name="OP_READ_BLOCK" type="byte"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="Deprecated at 0.21.  Use Op.READ_BLOCK instead.">
      <doc>
      <![CDATA[@deprecated Deprecated at 0.21.  Use Op.READ_BLOCK instead.]]>
      </doc>
    </field>
    <field name="OP_READ_METADATA" type="byte"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="As of version 15, OP_READ_METADATA is no longer supported.">
      <doc>
      <![CDATA[@deprecated As of version 15, OP_READ_METADATA is no longer supported.]]>
      </doc>
    </field>
    <field name="OP_REPLACE_BLOCK" type="byte"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="Deprecated at 0.21.  Use Op.REPLACE_BLOCK instead.">
      <doc>
      <![CDATA[@deprecated Deprecated at 0.21.  Use Op.REPLACE_BLOCK instead.]]>
      </doc>
    </field>
    <field name="OP_COPY_BLOCK" type="byte"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="Deprecated at 0.21.  Use Op.COPY_BLOCK instead.">
      <doc>
      <![CDATA[@deprecated Deprecated at 0.21.  Use Op.COPY_BLOCK instead.]]>
      </doc>
    </field>
    <field name="OP_BLOCK_CHECKSUM" type="byte"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="Deprecated at 0.21.  Use Op.BLOCK_CHECKSUM instead.">
      <doc>
      <![CDATA[@deprecated Deprecated at 0.21.  Use Op.BLOCK_CHECKSUM instead.]]>
      </doc>
    </field>
    <field name="OP_STATUS_SUCCESS" type="int"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="Deprecated at 0.21.  Use Status.SUCCESS instead.">
      <doc>
      <![CDATA[@deprecated Deprecated at 0.21.  Use Status.SUCCESS instead.]]>
      </doc>
    </field>
    <field name=